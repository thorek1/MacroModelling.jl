using MacroModelling
import LinearAlgebra as â„’
using SpeedMapping
import ForwardDiff
using DifferentiationInterface
# using SparseConnectivityTracer: TracerSparsityDetector
# using SparseMatrixColorings
pwd()
include("../models/Smets_Wouters_2007.jl")

ğ“‚ = Smets_Wouters_2007
T = ğ“‚.timings

SS_and_pars, (solution_error, iters) = ğ“‚.solution.outdated_NSSS ? get_NSSS_and_parameters(ğ“‚, ğ“‚.parameter_values, verbose = verbose) : (ğ“‚.solution.non_stochastic_steady_state, (eps(), 0))

âˆ‡â‚ = calculate_jacobian(ğ“‚.parameter_values, SS_and_pars, ğ“‚)#|> Matrix

expand = @views [â„’.I(T.nVars)[T.future_not_past_and_mixed_idx,:],
â„’.I(T.nVars)[T.past_not_future_and_mixed_idx,:]] 

âˆ‡â‚Š = @views âˆ‡â‚[:,1:T.nFuture_not_past_and_mixed] * expand[1]
âˆ‡â‚€ = @views âˆ‡â‚[:,T.nFuture_not_past_and_mixed .+ range(1,T.nVars)]
âˆ‡â‚‹ = @views âˆ‡â‚[:,T.nFuture_not_past_and_mixed + T.nVars .+ range(1,T.nPast_not_future_and_mixed)] * expand[2]
âˆ‡â‚‘ = @views âˆ‡â‚[:,(T.nFuture_not_past_and_mixed + T.nVars + T.nPast_not_future_and_mixed + 1):end]


âˆ‡Ì‚â‚€ =  â„’.lu(âˆ‡â‚€)
    
A = âˆ‡Ì‚â‚€ \ âˆ‡â‚‹
B = âˆ‡Ì‚â‚€ \ âˆ‡â‚Š

C = similar(A)
CÌ„ = similar(A)

E = similar(C)

sol = speedmapping(zero(A); m! = (CÌ„, C) -> begin 
                                            â„’.mul!(E, C, C)
                                            â„’.mul!(CÌ„, B, E)
                                            â„’.axpy!(1, A, CÌ„)
                                        end,
                                        # CÌ„ .=  A + B * C^2, 
    tol = eps(), maps_limit = 10000)


X = -sol.minimizer

â„’.norm(âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)
â„’.norm(A + B * X^2 + X)
# sparse_first_order_backend = AutoSparse(
#     AutoForwardDiff();
#     sparsity_detector=TracerSparsityDetector(),
#     coloring_algorithm=GreedyColoringAlgorithm(),
# )


X = zeros(T.nVars, T.nVars)
for i in 1:100
    jac = DifferentiationInterface.jacobian(X -> âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹, AutoForwardDiff(), X) |> sparse

    res = âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹

    change = reshape(jac \ vec(res),size(X))

    println(â„’.norm(change))

    X -= change
    if â„’.norm(change) < 1e-11
        println("Converged in step $i")
        break 
    end
end


â„’.norm(X)


X = zeros(T.nVars, T.nVars)
for i in 1:100
    jac = DifferentiationInterface.jacobian(X -> A + B * X^2 + X, AutoForwardDiff(), X) |> sparse

    res = A + B * X^2 + X

    change = reshape(jac \ vec(res),size(X))

    println(â„’.norm(change))

    X -= change
    if â„’.norm(change) < 1e-11
        println("Converged in step $i")
        break 
    end
end




X = zeros(T.nVars, T.nVars)

jac = DifferentiationInterface.jacobian(X -> âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹, AutoForwardDiff(), X) |> sparse

res = âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹

Î”X = reshape(jac \ vec(res),size(X))

âˆ‡â‚Š * Î”X * X + (âˆ‡â‚Š * X + âˆ‡â‚€) * Î”X - (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹) |> â„’.norm

A * Î”X * B + C * Î”X - D
using MatrixEquations
using BenchmarkTools
# AXB +CXÎ´ = E.


X = zeros(T.nVars, T.nVars)

Î”X = gsylv(âˆ‡â‚Š, X, âˆ‡â‚Š * X + âˆ‡â‚€, 1, (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹))

âˆ‡â‚Š * Î”X * X + (âˆ‡â‚Š * X + âˆ‡â‚€) * Î”X - (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹) |> â„’.norm


@profview for i in 1:100 calculate_first_order_solution(âˆ‡â‚, T = T) end
@benchmark calculate_first_order_solution(âˆ‡â‚, T = T)
@benchmark calculate_linear_time_iteration_solution(âˆ‡â‚, T = T)
@benchmark calculate_quadratic_iteration_solution(âˆ‡â‚, T = T)

@benchmark begin
# @profview  begin
X = zeros(T.nVars, T.nVars)
XÂ² = similar(X)
C = similar(X)
E = similar(X)

for i in 1:10
    copy!(C, âˆ‡â‚€)
    â„’.mul!(C, âˆ‡â‚Š, X, 1, 1)

    copy!(E, âˆ‡â‚‹)
    â„’.mul!(E, âˆ‡â‚€, X, 1, 1)
    â„’.mul!(XÂ², X, X)
    â„’.mul!(E, âˆ‡â‚Š, XÂ², 1, 1)

    Î”X = gsylv(âˆ‡â‚Š, X, C, 1, E)

    â„’.axpy!(-1, Î”X, X)

    if â„’.norm(Î”X) < 1e-11
        println("Converged in step $i")
        break 
    end
end
end


âˆ‡â‚Š * Î”X * X + (âˆ‡â‚Š * X + âˆ‡â‚€) * Î”X - (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)

import LinearOperators, Krylov

X = zeros(T.nVars, T.nVars)
tmpÌ„ = zero(X)
tmpÌ‚ = zero(X)
Î”X = zero(X)
A = âˆ‡â‚Š
B = X
C = âˆ‡â‚Š * X + âˆ‡â‚€
E = (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)

function sylvester!(sol,ğ±)
    copyto!(Î”X, ğ±)

    â„’.mul!(tmpÌ„, A, Î”X)
    â„’.mul!(tmpÌ‚, tmpÌ„, B)

    â„’.mul!(tmpÌ‚, C, Î”X, 1, 1)

    copyto!(sol, tmpÌ‚)
end

sylvester = LinearOperators.LinearOperator(Float64, length(C), length(C), false, false, sylvester!)

# @benchmark begin

Î”x, info = Krylov.gmres(sylvester, [vec(E);], rtol = 1e-14, atol = 1e-14)

Î”x = reshape(Î”x, size(X))


# end

# sylvester!(vec(Î”X),vec(X))

âˆ‡â‚Š * Î”x * X + (âˆ‡â‚Š * X + âˆ‡â‚€) * Î”x - (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹) |> â„’.norm

(âˆ‡â‚Š * X + âˆ‡â‚€) \ âˆ‡â‚Š * Î”x * X + Î”x - (âˆ‡â‚Š * X + âˆ‡â‚€) \ (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹) |> â„’.norm


# A = âˆ‡Ì‚â‚€ \ âˆ‡â‚‹
# B = âˆ‡Ì‚â‚€ \ âˆ‡â‚Š

# C = similar(A)
# CÌ„ = similar(A)

# E = similar(C)

# sol = @suppress begin
#     speedmapping(zero(A); m! = (CÌ„, C) -> begin 
#                                             â„’.mul!(E, C, C)
#                                             â„’.mul!(CÌ„, B, E)
#                                             â„’.axpy!(1, A, CÌ„)
#                                         end,
#                                         # CÌ„ .=  A + B * C^2, 
#     tol = tol, maps_limit = 10000)
# end

X = zeros(T.nVars, T.nVars)
# tmpÌ„ = zero(X)
# tmpÌ‚ = zero(X)
import MacroModelling: solve_sylvester_equation, calculate_linear_time_iteration_solution, calculate_quadratic_iteration_solution
# Î”X = zero(X)
A = (âˆ‡â‚Š * X + âˆ‡â‚€) \ âˆ‡â‚Š
B = X
C = (âˆ‡â‚Š * X + âˆ‡â‚€) \ (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)

@benchmark begin
Î”x,_ = solve_sylvester_equation(-A,B,C, verbose = true)
# Î”x *= -1
end

âˆ‡â‚Š * Î”x * X + (âˆ‡â‚Š * X + âˆ‡â‚€) * Î”x - (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹) |> â„’.norm

@benchmark begin
    âˆ‡â‚Š = @view âˆ‡â‚[:,1:T.nFuture_not_past_and_mixed]
    âˆ‡â‚€ = âˆ‡â‚[:,T.nFuture_not_past_and_mixed .+ range(1, T.nVars)]
    âˆ‡â‚‹ = @view âˆ‡â‚[:,T.nFuture_not_past_and_mixed + T.nVars .+ range(1, T.nPast_not_future_and_mixed)]

    Q    = â„’.qr!(âˆ‡â‚€[:,T.present_only_idx])
    Q    = @views â„’.factorize(âˆ‡â‚€[:,T.present_only_idx])

    â„’.ldiv!(Q, âˆ‡â‚Š)
    â„’.ldiv!(Q, âˆ‡â‚€)
    â„’.ldiv!(Q, âˆ‡â‚‹)
end


nâ‚€â‚Š = zeros(T.nVars, T.nFuture_not_past_and_mixed)
nâ‚€â‚€ = zeros(T.nVars, T.nVars)
nâ‚€â‚‹ = zeros(T.nVars, T.nPast_not_future_and_mixed)

@benchmark begin
    âˆ‡â‚Š = @view âˆ‡â‚[:,1:T.nFuture_not_past_and_mixed]
    âˆ‡â‚€ = âˆ‡â‚[:,T.nFuture_not_past_and_mixed .+ range(1, T.nVars)]
    âˆ‡â‚‹ = @view âˆ‡â‚[:,T.nFuture_not_past_and_mixed + T.nVars .+ range(1, T.nPast_not_future_and_mixed)]

    # Q    = â„’.qr!(âˆ‡â‚€[:,T.present_only_idx])
    Q    = @views â„’.factorize(âˆ‡â‚€[:,T.present_only_idx])

    Qinv = Q.Q'

    â„’.mul!(nâ‚€â‚Š, Qinv, âˆ‡â‚Š)
    â„’.mul!(nâ‚€â‚€, Qinv, âˆ‡â‚€)
    â„’.mul!(nâ‚€â‚‹, Qinv, âˆ‡â‚‹)
end

    
# @benchmark begin
    @profview  begin
    X = zeros(T.nVars, T.nVars)
    XÂ² = similar(X)
    A = similar(X)
    B = similar(X)
    C = similar(X)
    E = similar(X)
    
    for i in 1:100
        copy!(C, âˆ‡â‚€)
        â„’.mul!(C, âˆ‡â‚Š, X, 1, 1)
        CÌ‚ = â„’.lu(C)
        â„’.ldiv!(A, CÌ‚, âˆ‡â‚Š)

        copy!(E, âˆ‡â‚‹)
        â„’.mul!(E, âˆ‡â‚€, X, 1, 1)
        â„’.mul!(XÂ², X, X)
        â„’.mul!(E, âˆ‡â‚Š, XÂ², -1, -1)
        â„’.ldiv!(CÌ‚, E)
    
        # Î”X = gsylv(âˆ‡â‚Š, X, C, 1, E)
        Î”X = sylvd(A,X,E)
        # Î”X,_ = solve_sylvester_equation(-A,X,E, sylvester_algorithm = :sylvester, verbose = true)


        â„’.axpy!(1, Î”X, X)
    
        if â„’.norm(Î”X) < 1e-11
            # println("Converged in step $i")
            break 
        end
    end
    end

A = (âˆ‡â‚Š * X + âˆ‡â‚€) \ âˆ‡â‚Š
B = X
C = (âˆ‡â‚Š * X + âˆ‡â‚€) \ (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)

Î”x,_ = solve_sylvester_equation(-A,B,C, verbose = true)




copyto!(Î”X, vec(X))

    â„’.mul!(tmpÌ„, A, Î”X)
    â„’.mul!(tmpÌ‚, tmpÌ„, B)

    â„’.mul!(tmpÌ‚, C, Î”X, 1, 1)

    â„’.axpy!(1, E, tmpÌ‚)
    
    copyto!(sol, tmpÌ‚)

â„’.mul!(tmpÌ„, A, Î”X)
â„’.mul!(sol, tmpÌ„, B)

â„’.mul!(sol, C, Î”X, 1, 1)

â„’.axpy!(1, E, sol)



X = zeros(T.nVars, T.nVars)

ğ€ = âˆ‡â‚Š / (âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹)
ğ = X
ğ‚ = âˆ‡â‚€ + âˆ‡â‚Š * X
ğ‚Â¹ = copy(ğ‚)
ğƒ = âˆ‡â‚Š * X^2 + âˆ‡â‚€ * X + âˆ‡â‚‹

for i in 1:100
    ğ‚Â¹ = ğ€ * ğ‚ * ğ + ğ‚

    ğ€ = ğ€^2
    ğ = ğ^2
    # ğƒ = ğƒ^2

    # droptol!(ğ€, eps())
    # droptol!(ğ, eps())

    if i > 10# && i % 2 == 0
        if isapprox(ğ‚Â¹, ğ‚, rtol = 1e-12)
            iters = i
            break 
        end
    end
println(â„’.norm(ğ‚))
    ğ‚ = ğ‚Â¹
end

ğ‚Â¹ = ğ€ * ğ‚ * ğ + ğƒ * ğ‚

Î”X = ğ‚Â¹
