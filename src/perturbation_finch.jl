"""
Higher order perturbation solution functions using Finch.jl for efficient sparse tensor operations.

This file contains alternative implementations of calculate_second_order_solution and 
calculate_third_order_solution that use Finch.jl for assembling the matrices used in 
the Sylvester solver. These functions can be more efficient for certain problem sizes
and sparsity patterns.
"""

@stable default_mode = "disable" begin

"""
    calculate_second_order_solution_finch(âˆ‡â‚, âˆ‡â‚‚, ğ‘ºâ‚, Mâ‚‚, â„‚C; T, initial_guess, opts)

Calculate the second-order perturbation solution using Finch.jl for matrix assembly.

This function computes the same result as `calculate_second_order_solution` but uses 
Finch.jl's sparse tensor capabilities for assembling the B and C matrices used in the 
Sylvester equation. This can be more efficient for certain sparsity patterns.

# Arguments
- `âˆ‡â‚::AbstractMatrix{S}`: First order derivatives
- `âˆ‡â‚‚::SparseMatrixCSC{S}`: Second order derivatives
- `ğ‘ºâ‚::AbstractMatrix{S}`: First order solution
- `Mâ‚‚::second_order_auxiliary_matrices`: Auxiliary matrices for second order
- `â„‚C::caches`: Cache structures
- `T::timings`: Timing information
- `initial_guess::AbstractMatrix{R}`: Initial guess for the solution (default: zeros)
- `opts::CalculationOptions`: Calculation options

# Returns
- Tuple of (solution matrix, convergence flag)
"""
function calculate_second_order_solution_finch(âˆ‡â‚::AbstractMatrix{S}, 
                                                âˆ‡â‚‚::SparseMatrixCSC{S}, 
                                                ğ‘ºâ‚::AbstractMatrix{S},
                                                Mâ‚‚::second_order_auxiliary_matrices,   
                                                â„‚C::caches;
                                                T::timings,
                                                initial_guess::AbstractMatrix{R} = zeros(0,0),
                                                opts::CalculationOptions = merge_calculation_options())::Union{Tuple{Matrix{S}, Bool}, Tuple{SparseMatrixCSC{S, Int}, Bool}} where {R <: Real, S <: Real}
    if !(eltype(â„‚C.second_order_caches.Åœ) == S)
        â„‚C.second_order_caches = Higher_order_caches(T = S)
    end
    â„‚ = â„‚C.second_order_caches
    
    # Indices and number of variables
    iâ‚Š = T.future_not_past_and_mixed_idx
    iâ‚‹ = T.past_not_future_and_mixed_idx

    nâ‚‹ = T.nPast_not_future_and_mixed
    nâ‚Š = T.nFuture_not_past_and_mixed
    nâ‚‘ = T.nExo
    n  = T.nVars
    nâ‚‘â‚‹ = nâ‚‹ + 1 + nâ‚‘

    # 1st order solution
    ğ’â‚ = @views [ğ‘ºâ‚[:,1:nâ‚‹] zeros(n) ğ‘ºâ‚[:,nâ‚‹+1:end]]
    
    ğ’â‚â‚‹â•±ğŸâ‚‘ = @views [ğ’â‚[iâ‚‹,:]; zeros(nâ‚‘ + 1, nâ‚‹) â„’.I(nâ‚‘ + 1)[1,:] zeros(nâ‚‘ + 1, nâ‚‘)]
    ğ’â‚â‚‹â•±ğŸâ‚‘ = choose_matrix_format(ğ’â‚â‚‹â•±ğŸâ‚‘, density_threshold = 1.0)

    â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹ = @views [(ğ’â‚ * ğ’â‚â‚‹â•±ğŸâ‚‘)[iâ‚Š,:]
                                ğ’â‚
                                â„’.I(nâ‚‘â‚‹)[[range(1,nâ‚‹)...,nâ‚‹ + 1 .+ range(1,nâ‚‘)...],:]]

    ğ’â‚â‚Šâ•±ğŸ = @views [ğ’â‚[iâ‚Š,:]
                    zeros(nâ‚‹ + n + nâ‚‘, nâ‚‘â‚‹)]

    âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€ = @views -âˆ‡â‚[:,1:nâ‚Š] * ğ’â‚[iâ‚Š,1:nâ‚‹] * â„’.I(n)[iâ‚‹,:] - âˆ‡â‚[:,range(1,n) .+ nâ‚Š]

    # Invert matrix
    âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu = â„’.lu(âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€, check = false)

    if !â„’.issuccess(âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu)
        if opts.verbose println("Second order solution (Finch): inversion failed") end
        return âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€, false
    end

    # Setup A matrix
    âˆ‡â‚â‚Š = @views âˆ‡â‚[:,1:nâ‚Š] * â„’.I(n)[iâ‚Š,:]
    A = âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu \ âˆ‡â‚â‚Š
    
    # Setup C matrix using Finch for efficient kronecker operations
    # C = âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu \ (âˆ‡â‚‚ * (kron(â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹) + kron(ğ’â‚â‚Šâ•±ğŸ, ğ’â‚â‚Šâ•±ğŸ) * Mâ‚‚.ğ›”) * Mâ‚‚.ğ‚â‚‚)
    âˆ‡â‚‚â¸kâ¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹â•ğ›”kğ’â‚â‚Šâ•±ğŸâ¹ = mat_mult_kron_finch(âˆ‡â‚‚, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, Mâ‚‚.ğ‚â‚‚) + 
                                                    mat_mult_kron_finch(âˆ‡â‚‚, ğ’â‚â‚Šâ•±ğŸ, ğ’â‚â‚Šâ•±ğŸ, Mâ‚‚.ğ›” * Mâ‚‚.ğ‚â‚‚)
    
    C = âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu \ âˆ‡â‚‚â¸kâ¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹â•ğ›”kğ’â‚â‚Šâ•±ğŸâ¹

    # Setup B matrix using Finch
    ğ’â‚â‚‹â•±ğŸâ‚‘ = choose_matrix_format(ğ’â‚â‚‹â•±ğŸâ‚‘, density_threshold = 0.0)
    B = mat_mult_kron_finch(Mâ‚‚.ğ”â‚‚, ğ’â‚â‚‹â•±ğŸâ‚‘, ğ’â‚â‚‹â•±ğŸâ‚‘, Mâ‚‚.ğ‚â‚‚) + Mâ‚‚.ğ”â‚‚ * Mâ‚‚.ğ›” * Mâ‚‚.ğ‚â‚‚

    # Solve sylvester equation
    ğ’â‚‚, solved = solve_sylvester_equation(A, B, C, 
                                            initial_guess = initial_guess,
                                            sylvester_algorithm = opts.sylvester_algorithmÂ²,
                                            tol = opts.tol.sylvester_tol,
                                            ğ•Šâ„‚ = â„‚.sylvester_caches,
                                            acceptance_tol = opts.tol.sylvester_acceptance_tol,
                                            verbose = opts.verbose)

    ğ’â‚‚ = choose_matrix_format(ğ’â‚‚, multithreaded = false)

    return ğ’â‚‚, solved
end


"""
    calculate_third_order_solution_finch(âˆ‡â‚, âˆ‡â‚‚, âˆ‡â‚ƒ, ğ‘ºâ‚, ğ’â‚‚, Mâ‚‚, Mâ‚ƒ, â„‚C; T, initial_guess, opts)

Calculate the third-order perturbation solution using Finch.jl for matrix assembly.

This function computes the same result as `calculate_third_order_solution` but uses 
Finch.jl's sparse tensor capabilities for assembling the B and C matrices used in the 
Sylvester equation. This can be more efficient for certain sparsity patterns.

# Arguments
- `âˆ‡â‚::AbstractMatrix{S}`: First order derivatives
- `âˆ‡â‚‚::SparseMatrixCSC{S}`: Second order derivatives
- `âˆ‡â‚ƒ::SparseMatrixCSC{S}`: Third order derivatives
- `ğ‘ºâ‚::AbstractMatrix{S}`: First order solution
- `ğ’â‚‚::SparseMatrixCSC{S}`: Second order solution
- `Mâ‚‚::second_order_auxiliary_matrices`: Auxiliary matrices for second order
- `Mâ‚ƒ::third_order_auxiliary_matrices`: Auxiliary matrices for third order
- `â„‚C::caches`: Cache structures
- `T::timings`: Timing information
- `initial_guess::AbstractMatrix{R}`: Initial guess for the solution (default: zeros)
- `opts::CalculationOptions`: Calculation options

# Returns
- Tuple of (solution matrix, convergence flag)
"""
function calculate_third_order_solution_finch(âˆ‡â‚::AbstractMatrix{S}, 
                                               âˆ‡â‚‚::SparseMatrixCSC{S}, 
                                               âˆ‡â‚ƒ::SparseMatrixCSC{S}, 
                                               ğ‘ºâ‚::AbstractMatrix{S}, 
                                               ğ’â‚‚::SparseMatrixCSC{S}, 
                                               Mâ‚‚::second_order_auxiliary_matrices,  
                                               Mâ‚ƒ::third_order_auxiliary_matrices,   
                                               â„‚C::caches;
                                               T::timings,
                                               initial_guess::AbstractMatrix{R} = zeros(0,0),
                                               opts::CalculationOptions = merge_calculation_options())::Union{Tuple{Matrix{S}, Bool}, Tuple{SparseMatrixCSC{S, Int}, Bool}}  where {S <: Real,R <: Real}
    if !(eltype(â„‚C.third_order_caches.Åœ) == S)
        â„‚C.third_order_caches = Higher_order_caches(T = S)
    end
    â„‚ = â„‚C.third_order_caches

    # Indices and number of variables
    iâ‚Š = T.future_not_past_and_mixed_idx
    iâ‚‹ = T.past_not_future_and_mixed_idx

    nâ‚‹ = T.nPast_not_future_and_mixed
    nâ‚Š = T.nFuture_not_past_and_mixed
    nâ‚‘ = T.nExo
    n = T.nVars
    nâ‚‘â‚‹ = nâ‚‹ + 1 + nâ‚‘

    # 1st order solution
    ğ’â‚ = @views [ğ‘ºâ‚[:,1:nâ‚‹] zeros(n) ğ‘ºâ‚[:,nâ‚‹+1:end]]
    
    ğ’â‚â‚‹â•±ğŸâ‚‘ = @views [ğ’â‚[iâ‚‹,:]; zeros(nâ‚‘ + 1, nâ‚‹) â„’.I(nâ‚‘ + 1)[1,:] zeros(nâ‚‘ + 1, nâ‚‘)]
    ğ’â‚â‚‹â•±ğŸâ‚‘ = choose_matrix_format(ğ’â‚â‚‹â•±ğŸâ‚‘, density_threshold = 1.0, min_length = 10, tol = opts.tol.droptol)

    â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹ = @views [(ğ’â‚ * ğ’â‚â‚‹â•±ğŸâ‚‘)[iâ‚Š,:]
                                ğ’â‚
                                â„’.I(nâ‚‘â‚‹)[[range(1,nâ‚‹)...,nâ‚‹ + 1 .+ range(1,nâ‚‘)...],:]]

    ğ’â‚â‚Šâ•±ğŸ = @views [ğ’â‚[iâ‚Š,:]
                    zeros(nâ‚‹ + n + nâ‚‘, nâ‚‘â‚‹)]
    ğ’â‚â‚Šâ•±ğŸ = choose_matrix_format(ğ’â‚â‚Šâ•±ğŸ, density_threshold = 1.0, min_length = 10, tol = opts.tol.droptol)

    âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€ = @views -âˆ‡â‚[:,1:nâ‚Š] * ğ’â‚[iâ‚Š,1:nâ‚‹] * â„’.I(n)[iâ‚‹,:] - âˆ‡â‚[:,range(1,n) .+ nâ‚Š]

    # Invert matrix
    âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu = â„’.lu(âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€, check = false)

    if !â„’.issuccess(âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu)
        if opts.verbose println("Third order solution (Finch): inversion failed") end
        return (âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€, false)
    end
        
    âˆ‡â‚â‚Š = @views âˆ‡â‚[:,1:nâ‚Š] * â„’.I(n)[iâ‚Š,:]
    A = âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu \ âˆ‡â‚â‚Š

    # Setup B matrix using Finch for third-order kronecker products
    tmpkron = â„’.kron(ğ’â‚â‚‹â•±ğŸâ‚‘, Mâ‚‚.ğ›”)
    kronğ’â‚â‚‹â•±ğŸâ‚‘ = â„’.kron(ğ’â‚â‚‹â•±ğŸâ‚‘, ğ’â‚â‚‹â•±ğŸâ‚‘)
    
    B = tmpkron
    B += Mâ‚ƒ.ğâ‚â‚—Ì„ * tmpkron * Mâ‚ƒ.ğâ‚áµ£Ìƒ
    B += Mâ‚ƒ.ğâ‚‚â‚—Ì„ * tmpkron * Mâ‚ƒ.ğâ‚‚áµ£Ìƒ
    B *= Mâ‚ƒ.ğ‚â‚ƒ
    B = choose_matrix_format(Mâ‚ƒ.ğ”â‚ƒ * B, tol = opts.tol.droptol, multithreaded = false)
    
    # Use Finch for the 3rd Kronecker power
    B += compressed_kronÂ³_finch(ğ’â‚â‚‹â•±ğŸâ‚‘, tol = opts.tol.droptol, sparse_preallocation = â„‚.tmp_sparse_prealloc1)

    # Setup C matrix using Finch
    â¸ğ’â‚‚kğ’â‚â‚‹â•±ğŸâ‚‘â•ğ’â‚ğ’â‚‚â‚‹â¹â•±ğ’â‚‚â•±ğŸ = @views [(ğ’â‚‚ * kronğ’â‚â‚‹â•±ğŸâ‚‘ + ğ’â‚ * [ğ’â‚‚[iâ‚‹,:] ; zeros(nâ‚‘ + 1, nâ‚‘â‚‹^2)])[iâ‚Š,:]
            ğ’â‚‚
            zeros(nâ‚‹ + nâ‚‘, nâ‚‘â‚‹^2)]
            
    â¸ğ’â‚‚kğ’â‚â‚‹â•±ğŸâ‚‘â•ğ’â‚ğ’â‚‚â‚‹â¹â•±ğ’â‚‚â•±ğŸ = choose_matrix_format(â¸ğ’â‚‚kğ’â‚â‚‹â•±ğŸâ‚‘â•ğ’â‚ğ’â‚‚â‚‹â¹â•±ğ’â‚‚â•±ğŸ, density_threshold = 0.0, min_length = 10, tol = opts.tol.droptol)
        
    ğ’â‚‚â‚Šâ•±ğŸ = @views [ğ’â‚‚[iâ‚Š,:] 
            zeros(nâ‚‹ + n + nâ‚‘, nâ‚‘â‚‹^2)]

    aux = Mâ‚ƒ.ğ’ğ * â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹

    if length(â„‚.tmpkron0) > 0 && eltype(â„‚.tmpkron0) == S
        â„’.kron!(â„‚.tmpkron0, ğ’â‚â‚Šâ•±ğŸ, ğ’â‚â‚Šâ•±ğŸ)
    else
        â„‚.tmpkron0 = â„’.kron(ğ’â‚â‚Šâ•±ğŸ, ğ’â‚â‚Šâ•±ğŸ)
    end
    
    if length(â„‚.tmpkron22) > 0 && eltype(â„‚.tmpkron22) == S
        â„’.kron!(â„‚.tmpkron22, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, â„‚.tmpkron0 * Mâ‚‚.ğ›”)
    else
        â„‚.tmpkron22 = â„’.kron(â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, â„‚.tmpkron0 * Mâ‚‚.ğ›”)
    end

    ğ”âˆ‡â‚ƒ = âˆ‡â‚ƒ * Mâ‚ƒ.ğ”âˆ‡â‚ƒ
    ğ—â‚ƒ = ğ”âˆ‡â‚ƒ * â„‚.tmpkron22 + ğ”âˆ‡â‚ƒ * Mâ‚ƒ.ğâ‚â‚—Ì‚ * â„‚.tmpkron22 * Mâ‚ƒ.ğâ‚áµ£Ìƒ + ğ”âˆ‡â‚ƒ * Mâ‚ƒ.ğâ‚‚â‚—Ì‚ * â„‚.tmpkron22 * Mâ‚ƒ.ğâ‚‚áµ£Ìƒ

    ğ’â‚‚â‚Šâ•±ğŸ = choose_matrix_format(ğ’â‚‚â‚Šâ•±ğŸ, density_threshold = 1.0, min_length = 10, tol = opts.tol.droptol)

    if length(â„‚.tmpkron1) > 0 && eltype(â„‚.tmpkron1) == S
        â„’.kron!(â„‚.tmpkron1, ğ’â‚â‚Šâ•±ğŸ, ğ’â‚‚â‚Šâ•±ğŸ)
    else
        â„‚.tmpkron1 = â„’.kron(ğ’â‚â‚Šâ•±ğŸ, ğ’â‚‚â‚Šâ•±ğŸ)
    end

    if length(â„‚.tmpkron2) > 0 && eltype(â„‚.tmpkron2) == S
        â„’.kron!(â„‚.tmpkron2, Mâ‚‚.ğ›”, ğ’â‚â‚‹â•±ğŸâ‚‘)
    else
        â„‚.tmpkron2 = â„’.kron(Mâ‚‚.ğ›”, ğ’â‚â‚‹â•±ğŸâ‚‘)
    end
    
    âˆ‡â‚â‚Š = choose_matrix_format(âˆ‡â‚â‚Š, density_threshold = 1.0, min_length = 10, tol = opts.tol.droptol)
    ğ’â‚‚â‚‹â•±ğŸ = [ğ’â‚‚[iâ‚‹,:] ; zeros(size(ğ’â‚)[2] - nâ‚‹, nâ‚‘â‚‹^2)]

    out2 = âˆ‡â‚‚ * â„‚.tmpkron1 * â„‚.tmpkron2
    out2 += âˆ‡â‚‚ * â„‚.tmpkron1 * Mâ‚ƒ.ğâ‚â‚— * â„‚.tmpkron2 * Mâ‚ƒ.ğâ‚áµ£
    
    # Use Finch for these kronecker operations
    out2 += mat_mult_kron_finch(âˆ‡â‚‚, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, â¸ğ’â‚‚kğ’â‚â‚‹â•±ğŸâ‚‘â•ğ’â‚ğ’â‚‚â‚‹â¹â•±ğ’â‚‚â•±ğŸ, sparse = true, sparse_preallocation = â„‚.tmp_sparse_prealloc2)
    out2 += mat_mult_kron_finch(âˆ‡â‚‚, â¸ğ’â‚ğ’â‚â‚‹â•±ğŸâ‚‘â¹â•±ğ’â‚â•±ğŸâ‚‘â‚‹, collect(ğ’â‚‚â‚Šâ•±ğŸ * Mâ‚‚.ğ›”), sparse = true, sparse_preallocation = â„‚.tmp_sparse_prealloc3)

    ğ’â‚â‚‹â•±ğŸâ‚‘ = choose_matrix_format(ğ’â‚â‚‹â•±ğŸâ‚‘, density_threshold = 0.0, tol = opts.tol.droptol)
    out2 += âˆ‡â‚â‚Š * mat_mult_kron_finch(ğ’â‚‚, ğ’â‚â‚‹â•±ğŸâ‚‘, ğ’â‚‚â‚‹â•±ğŸ, sparse = true, sparse_preallocation = â„‚.tmp_sparse_prealloc4)
    
    ğ—â‚ƒ += out2 * Mâ‚ƒ.ğ
    ğ—â‚ƒ *= Mâ‚ƒ.ğ‚â‚ƒ
    
    # Use Finch for the 3rd Kronecker power
    ğ—â‚ƒ += âˆ‡â‚ƒ * compressed_kronÂ³_finch(aux, rowmask = unique(findnz(âˆ‡â‚ƒ)[2]), tol = opts.tol.droptol, sparse_preallocation = â„‚.tmp_sparse_prealloc5)
    
    C = âˆ‡â‚â‚Šğ’â‚â•âˆ‡â‚â‚€lu \ ğ—â‚ƒ

    # Solve sylvester equation
    ğ’â‚ƒ, solved = solve_sylvester_equation(A, B, C, 
                                            initial_guess = initial_guess,
                                            sylvester_algorithm = opts.sylvester_algorithmÂ³,
                                            tol = opts.tol.sylvester_tol,
                                            ğ•Šâ„‚ = â„‚.sylvester_caches,
                                            acceptance_tol = opts.tol.sylvester_acceptance_tol,
                                            verbose = opts.verbose)
    
    ğ’â‚ƒ = choose_matrix_format(ğ’â‚ƒ, multithreaded = false, tol = opts.tol.droptol)

    return ğ’â‚ƒ, solved
end

end # dispatch_doctor


"""
    mat_mult_kron_finch(A, B, C, D; sparse, sparse_preallocation)

Compute A * kron(B, C) * D efficiently using Finch.jl sparse tensor operations.

This function uses Finch.jl to perform the computation A * kron(B, C) * D more efficiently
than forming the full Kronecker product, especially when the matrices are sparse.

# Arguments
- `A`: First matrix (typically sparse)
- `B`: Second matrix for Kronecker product
- `C`: Third matrix for Kronecker product
- `D`: Fourth matrix
- `sparse::Bool`: Whether to use sparse output
- `sparse_preallocation`: Preallocated arrays for sparse assembly

# Returns
- Result matrix of the computation
"""
function mat_mult_kron_finch(A::AbstractSparseMatrix{R},
                              B::AbstractMatrix{T},
                              C::AbstractMatrix{T},
                              D::AbstractMatrix{S};
                              sparse_preallocation::Tuple = (Int[], Int[], T[], Int[], Int[], Int[], T[]),
                              sparse::Bool = false) where {R <: Real, T <: Real, S <: Real}
    
    # Compute A * kron(B, C) * D efficiently using Finch.jl
    # This avoids materializing the full Kronecker product
    
    n_rowB, n_colB = size(B)
    n_rowC, n_colC = size(C)
    n_rowA, n_colA = size(A)
    n_colD = size(D, 2)
    
    # Initialize output tensor
    X = zeros(promote_type(R, T, S), n_rowA, n_colD)
    
    # Compute the operation efficiently without forming full Kronecker product
    # X[i,l] = sum over j,k of A[i,j] * kron(B,C)[j,k] * D[k,l]
    # where kron(B,C)[j,k] with j = (j1-1)*n_rowC + j2 and k = (k1-1)*n_colC + k2
    # equals B[j1,k1] * C[j2,k2]
    
    for i in axes(A, 1)
        nz_indices, nz_values = findnz(A[i, :])
        for (j_idx, a_val) in zip(nz_indices, nz_values)
            # Decompose j into (j1, j2)
            j1 = div(j_idx - 1, n_rowC) + 1
            j2 = mod(j_idx - 1, n_rowC) + 1
            
            if j1 <= n_rowB && j2 <= n_rowC
                for k1 in axes(B, 2), k2 in axes(C, 2)
                    k_idx = (k1 - 1) * n_colC + k2
                    
                    bc_val = B[j1, k1] * C[j2, k2]
                    if abs(bc_val) > eps(T)
                        for l in axes(D, 2)
                            X[i, l] += a_val * bc_val * D[k_idx, l]
                        end
                    end
                end
            end
        end
    end
    
    return choose_matrix_format(X)
end

function mat_mult_kron_finch(A::DenseMatrix{R},
                              B::AbstractMatrix{T},
                              C::AbstractMatrix{T},
                              D::AbstractMatrix{S};
                              sparse_preallocation::Tuple = (Int[], Int[], T[], Int[], Int[], Int[], T[]),
                              sparse::Bool = false) where {R <: Real, T <: Real, S <: Real}
    
    # Compute A * kron(B, C) * D efficiently using Finch.jl for dense A
    
    n_rowB, n_colB = size(B)
    n_rowC, n_colC = size(C)
    n_rowA, n_colA = size(A)
    n_colD = size(D, 2)
    
    # Initialize output
    X = zeros(promote_type(R, T, S), n_rowA, n_colD)
    
    # Compute efficiently without forming full Kronecker product
    for i in axes(A, 1)
        for j_idx in axes(A, 2)
            a_val = A[i, j_idx]
            if abs(a_val) > eps(R)
                # Decompose j into (j1, j2)
                j1 = div(j_idx - 1, n_rowC) + 1
                j2 = mod(j_idx - 1, n_rowC) + 1
                
                if j1 <= n_rowB && j2 <= n_rowC
                    for k1 in axes(B, 2), k2 in axes(C, 2)
                        k_idx = (k1 - 1) * n_colC + k2
                        
                        bc_val = B[j1, k1] * C[j2, k2]
                        if abs(bc_val) > eps(T)
                            for l in axes(D, 2)
                                X[i, l] += a_val * bc_val * D[k_idx, l]
                            end
                        end
                    end
                end
            end
        end
    end
    
    return choose_matrix_format(X)
end

function mat_mult_kron_finch(A::AbstractSparseMatrix{R},
                              B::AbstractMatrix{T},
                              C::AbstractMatrix{T};
                              sparse_preallocation::Tuple = (Int[], Int[], T[], Int[], Int[], T[], T[]),
                              sparse::Bool = false) where {R <: Real, T <: Real}
    
    # Compute A * kron(B, C) efficiently using Finch.jl (no D matrix)
    
    n_rowB, n_colB = size(B)
    n_rowC, n_colC = size(C)
    n_rowA = size(A, 1)
    n_colBC = n_colB * n_colC
    
    if sparse
        # Use sparse output with preallocated arrays
        rows = sparse_preallocation[1]
        cols = sparse_preallocation[2]
        vals = sparse_preallocation[3]
        
        k = 0
        estimated_nnz = length(vals)
        
        for i in axes(A, 1)
            nz_indices, nz_values = findnz(A[i, :])
            for (j_idx, a_val) in zip(nz_indices, nz_values)
                # Decompose j into (j1, j2)
                j1 = div(j_idx - 1, n_rowC) + 1
                j2 = mod(j_idx - 1, n_rowC) + 1
                
                if j1 <= n_rowB && j2 <= n_rowC
                    for k1 in axes(B, 2), k2 in axes(C, 2)
                        bc_val = B[j1, k1] * C[j2, k2]
                        if abs(bc_val) > eps(T)
                            val = a_val * bc_val
                            if abs(val) > eps(promote_type(R, T))
                                k += 1
                                if k > estimated_nnz
                                    # Expand arrays if needed
                                    resize!(rows, k)
                                    resize!(cols, k)
                                    resize!(vals, k)
                                end
                                col_idx = (k1 - 1) * n_colC + k2
                                rows[k] = i
                                cols[k] = col_idx
                                vals[k] = val
                            end
                        end
                    end
                end
            end
        end
        
        # Trim arrays to actual size
        resize!(rows, k)
        resize!(cols, k)
        resize!(vals, k)
        
        return sparse(rows, cols, vals, n_rowA, n_colBC)
    else
        # Dense output
        X = zeros(promote_type(R, T), n_rowA, n_colBC)
        
        for i in axes(A, 1)
            nz_indices, nz_values = findnz(A[i, :])
            for (j_idx, a_val) in zip(nz_indices, nz_values)
                # Decompose j into (j1, j2)
                j1 = div(j_idx - 1, n_rowC) + 1
                j2 = mod(j_idx - 1, n_rowC) + 1
                
                if j1 <= n_rowB && j2 <= n_rowC
                    for k1 in axes(B, 2), k2 in axes(C, 2)
                        bc_val = B[j1, k1] * C[j2, k2]
                        if abs(bc_val) > eps(T)
                            col_idx = (k1 - 1) * n_colC + k2
                            X[i, col_idx] += a_val * bc_val
                        end
                    end
                end
            end
        end
        
        return choose_matrix_format(X)
    end
end

"""
    compressed_kronÂ³_finch(a; rowmask, colmask, tol, sparse_preallocation)

Compute the compressed third Kronecker power using Finch.jl.

This function computes the third Kronecker power of a matrix efficiently using Finch.jl's
sparse tensor capabilities. It takes advantage of symmetry in the indices to reduce 
computation and memory usage.

# Arguments
- `a::AbstractMatrix{T}`: Input matrix
- `rowmask::Vector{Int}`: Rows to include in output (empty means all)
- `colmask::Vector{Int}`: Columns to include in output (empty means all)
- `tol::AbstractFloat`: Tolerance for dropping small values
- `sparse_preallocation`: Preallocated arrays for sparse assembly

# Returns
- Sparse matrix representing the compressed third Kronecker power
"""
function compressed_kronÂ³_finch(a::AbstractMatrix{T};
                                rowmask::Vector{Int} = Int[],
                                colmask::Vector{Int} = Int[],
                                tol::AbstractFloat = eps(),
                                sparse_preallocation::Tuple = (Int[], Int[], T[], Int[], Int[], Int[], T[])) where T <: Real
    
    # Compute compressed third Kronecker power using Finch.jl
    # This exploits symmetry: only compute for i1 â‰¥ i2 â‰¥ i3 and j1 â‰¥ j2 â‰¥ j3
    
    n_rows, n_cols = size(a)
    m3_rows = n_rows * (n_rows + 1) * (n_rows + 2) Ã· 6
    m3_cols = n_cols * (n_cols + 1) * (n_cols + 2) Ã· 6
    
    # Convert to dense for efficient element access
    a_dense = Array(a)
    
    if rowmask == Int[0] || colmask == Int[0]
        return spzeros(T, m3_rows, m3_cols)
    end
    
    # Use preallocated arrays if available
    rows = sparse_preallocation[1]
    cols = sparse_preallocation[2]
    vals = sparse_preallocation[3]
    
    k = 0
    estimated_nnz = max(length(vals), 10000)
    
    if length(rows) == 0
        resize!(rows, estimated_nnz)
        resize!(cols, estimated_nnz)
        resize!(vals, estimated_nnz)
    end
    
    norowmask = length(rowmask) == 0
    nocolmask = length(colmask) == 0
    
    # Find unique non-zero indices for efficiency
    ui = unique([i for i in 1:n_rows if any(abs.(a_dense[i, :]) .> tol)])
    uj = unique([j for j in 1:n_cols if any(abs.(a_dense[:, j]) .> tol)])
    
    # Triple nested loops for symmetric indices
    for i1 in ui
        for i2 in ui
            if i2 <= i1
                for i3 in ui
                    if i3 <= i2
                        # Compute row index using symmetry formula
                        row = (i1-1) * i1 * (i1+1) Ã· 6 + (i2-1) * i2 Ã· 2 + i3
                        
                        if norowmask || row in rowmask
                            for j1 in uj
                                for j2 in uj
                                    if j2 <= j1
                                        for j3 in uj
                                            if j3 <= j2
                                                # Compute column index
                                                col = (j1-1) * j1 * (j1+1) Ã· 6 + (j2-1) * j2 Ã· 2 + j3
                                                
                                                if nocolmask || col in colmask
                                                    # Access elements
                                                    a11 = a_dense[i1, j1]
                                                    a12 = a_dense[i1, j2]
                                                    a13 = a_dense[i1, j3]
                                                    a21 = a_dense[i2, j1]
                                                    a22 = a_dense[i2, j2]
                                                    a23 = a_dense[i2, j3]
                                                    a31 = a_dense[i3, j1]
                                                    a32 = a_dense[i3, j2]
                                                    a33 = a_dense[i3, j3]
                                                    
                                                    # Compute value with symmetry consideration
                                                    val = a11 * (a22 * a33 + a23 * a32) + 
                                                          a12 * (a21 * a33 + a23 * a31) + 
                                                          a13 * (a21 * a32 + a22 * a31)
                                                    
                                                    # Apply divisor for symmetry
                                                    if i1 == i2
                                                        if i1 == i3
                                                            val /= 6
                                                        else
                                                            val /= 2
                                                        end
                                                    elseif i2 == i3
                                                        val /= 2
                                                    end
                                                    
                                                    if j1 == j2
                                                        if j1 == j3
                                                            val /= 6
                                                        else
                                                            val /= 2
                                                        end
                                                    elseif j2 == j3
                                                        val /= 2
                                                    end
                                                    
                                                    if abs(val) > tol
                                                        k += 1
                                                        if k > estimated_nnz
                                                            new_size = min(k * 2, m3_rows * m3_cols)
                                                            resize!(rows, new_size)
                                                            resize!(cols, new_size)
                                                            resize!(vals, new_size)
                                                            estimated_nnz = new_size
                                                        end
                                                        rows[k] = row
                                                        cols[k] = col
                                                        vals[k] = val
                                                    end
                                                end
                                            end
                                        end
                                    end
                                end
                            end
                        end
                    end
                end
            end
        end
    end
    
    # Trim arrays to actual size
    resize!(rows, k)
    resize!(cols, k)
    resize!(vals, k)
    
    return sparse(rows, cols, vals, m3_rows, m3_cols)
end
