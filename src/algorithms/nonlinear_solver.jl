@stable default_mode = "disable" begin

function levenberg_marquardt(
    fnj::function_and_jacobian,
    # f::Function, 
    initial_guess::Array{T,1}, 
    parameters_and_solved_vars::Array{T,1},
    lower_bounds::Array{T,1}, 
    upper_bounds::Array{T,1},
    parameters::solver_parameters;
    tol::Tolerances = Tolerances()
    )::Tuple{Vector{T}, Tuple{Int, Int, T, T}} where {T <: AbstractFloat}
    # issues with optimization: https://www.gurobi.com/documentation/8.1/refman/numerics_gurobi_guidelines.html

    xtol = tol.NSSS_xtol
    ftol = tol.NSSS_ftol
    rel_xtol = tol.NSSS_rel_xtol

    iterations = 250
    
    œïÃÑ = parameters.œïÃÑ
    œïÃÇ = parameters.œïÃÇ
    ŒºÃÑ¬π = parameters.ŒºÃÑ¬π
    ŒºÃÑ¬≤ = parameters.ŒºÃÑ¬≤
    pÃÑ¬π = parameters.pÃÑ¬π
    pÃÑ¬≤ = parameters.pÃÑ¬≤
    œÅ = parameters.œÅ
    œÅ¬π = parameters.œÅ¬π
    œÅ¬≤ = parameters.œÅ¬≤
    œÅ¬≥ = parameters.œÅ¬≥
    ŒΩ = parameters.ŒΩ
    Œª¬π = parameters.Œª¬π
    Œª¬≤ = parameters.Œª¬≤
    ŒªÃÇ¬π = parameters.ŒªÃÇ¬π
    ŒªÃÇ¬≤ = parameters.ŒªÃÇ¬≤
    ŒªÃÖ¬π = parameters.ŒªÃÖ¬π
    ŒªÃÖ¬≤ = parameters.ŒªÃÖ¬≤
    ŒªÃÇÃÖ¬π = parameters.ŒªÃÇÃÖ¬π
    ŒªÃÇÃÖ¬≤ = parameters.ŒªÃÇÃÖ¬≤
    transformation_level = parameters.transformation_level
    shift = parameters.shift
    backtracking_order = parameters.backtracking_order

    @assert size(lower_bounds) == size(upper_bounds) == size(initial_guess)
    @assert all(lower_bounds .< upper_bounds)
    @assert backtracking_order ‚àà [2,3] "Backtracking order can only be quadratic (2) or cubic (3)."

    max_linesearch_iterations = 600

    # function fÃÇ(x) 
    #     f(undo_transform(x,transformation_level))  
    # #     # f(undo_transform(x,transformation_level,shift))  
    # end

    upper_bounds  = transform(upper_bounds,transformation_level)
    # upper_bounds  = transform(upper_bounds,transformation_level,shift)
    lower_bounds  = transform(lower_bounds,transformation_level)
    # lower_bounds  = transform(lower_bounds,transformation_level,shift)

    current_guess = copy(transform(initial_guess,transformation_level))
    current_guess_untransformed = copy(transform(initial_guess,transformation_level))
    # current_guess = copy(transform(initial_guess,transformation_level,shift))
    previous_guess = similar(current_guess)
    previous_guess_untransformed = similar(current_guess)
    guess_update = similar(current_guess)
    factor = similar(current_guess)
    # ‚àá = Array{T,2}(undef, length(initial_guess), length(initial_guess))
    ‚àá = fnj.jac_buffer
    # ‚àáÃÇ = similar(fnj.jac_buffer)
    ‚àáÃÑ = similar(fnj.jac_buffer)

    ‚àáÃÇ = choose_matrix_format(‚àá' * ‚àá, multithreaded = false)
    
    if ‚àáÃÇ isa SparseMatrixCSC
        prob = ùíÆ.LinearProblem(‚àáÃÇ, guess_update, ùíÆ.UMFPACKFactorization())
    else
        prob = ùíÆ.LinearProblem(‚àáÃÇ, guess_update)#, ùíÆ.CholeskyFactorization)
    end

    sol_cache = ùíÆ.init(prob)
    
    # prep = ùíü.prepare_jacobian(fÃÇ, backend, current_guess)

    largest_step = T(1.0)
    largest_residual = T(1.0)
    largest_relative_step = T(1.0)

    Œº¬π = ŒºÃÑ¬π
    Œº¬≤ = ŒºÃÑ¬≤

    p¬π = pÃÑ¬π
    p¬≤ = pÃÑ¬≤

    grad_iter = 0
    func_iter = 0

    for iter in 1:iterations
        # make the jacobian and f calls nonallocating
        copy!(current_guess_untransformed, current_guess)
        
        if transformation_level > 0
            factor .= 1
            for _ in 1:transformation_level
                factor .*= cosh.(current_guess_untransformed)
                current_guess_untransformed .= sinh.(current_guess_untransformed)
            end
        end

        fnj.jac(‚àá, current_guess_untransformed, parameters_and_solved_vars)
        # ùíü.jacobian!(fÃÇ, ‚àá, prep, backend, current_guess)

        if transformation_level > 0
            if ‚àá isa SparseMatrixCSC
                # ‚àáÃÑ = ‚àá .* factor'
                copy!(‚àáÃÑ.nzval, ‚àá.nzval)
                @inbounds for j in 1:size(‚àá, 2)
                    col_start = ‚àáÃÑ.colptr[j]
                    col_end = ‚àáÃÑ.colptr[j+1] - 1
                    for k in col_start:col_end
                        ‚àáÃÑ.nzval[k] *= factor[j]
                    end
                end
            else
                # ‚Ñí.mul!(‚àáÃÑ, ‚àá, factor')
                @. ‚àáÃÑ = ‚àá * factor'
                # ‚àá .*= factor'
            end
        end

        grad_iter += 1

        previous_guess .= current_guess

        # ‚àáÃÇ .= ‚àá' * ‚àá
        if ‚àáÃÑ isa SparseMatrixCSC && ‚àáÃÇ isa SparseMatrixCSC
            ‚àáÃÇ = ‚àáÃÑ' * ‚àáÃÑ
        else
            ‚Ñí.mul!(‚àáÃÇ, ‚àáÃÑ', ‚àáÃÑ)
        end

        fnj.func(fnj.func_buffer, current_guess_untransformed, parameters_and_solved_vars)

        Œº¬πs = Œº¬π * sum(abs2, fnj.func_buffer)^p¬π
        # Œº¬πs = Œº¬π * sum(abs2, fÃÇ(current_guess))^p¬π
        func_iter += 1

        for i in 1:size(‚àáÃÇ,1)
            ‚àáÃÇ[i,i] += Œº¬πs
            ‚àáÃÇ[i,i] += Œº¬≤ * ‚àáÃÇ[i,i]^p¬≤
        end
        # ‚àáÃÇ .+= Œº¬π * sum(abs2, fÃÇ(current_guess))^p¬π * ‚Ñí.I + Œº¬≤ * ‚Ñí.Diagonal(‚àáÃÇ).^p¬≤

        if !all(isfinite, ‚àáÃÇ)
            largest_relative_step = 1.0
            largest_residual = 1.0
            break
        end

        fnj.func(fnj.func_buffer, current_guess_untransformed, parameters_and_solved_vars)

        ‚Ñí.mul!(guess_update, ‚àáÃÑ', fnj.func_buffer)

        sol_cache.A = ‚àáÃÇ
        sol_cache.b = guess_update
        ùíÆ.solve!(sol_cache)
        copy!(guess_update, sol_cache.u)

        if !isfinite(sum(guess_update))
            largest_relative_step = 1.0
            largest_residual = 1.0
            break
        end

        ‚Ñí.axpy!(-1, guess_update, current_guess)
        # current_guess .-= ‚àáÃÑ \ ‚àá' * fÃÇ(current_guess)

        minmax!(current_guess, lower_bounds, upper_bounds)

        copy!(previous_guess_untransformed, previous_guess)

        for _ in 1:transformation_level
            previous_guess_untransformed .= sinh.(previous_guess_untransformed)
        end
        
        fnj.func(fnj.func_buffer, previous_guess_untransformed, parameters_and_solved_vars)

        P = sum(abs2, fnj.func_buffer)
        # P = sum(abs2, fÃÇ(previous_guess))
        PÃÉ = P
        
        copy!(current_guess_untransformed, current_guess)

        for _ in 1:transformation_level
            current_guess_untransformed .= sinh.(current_guess_untransformed)
        end

        fnj.func(fnj.func_buffer, current_guess_untransformed, parameters_and_solved_vars)
      
        PÃã = sum(abs2, fnj.func_buffer)
        # PÃã = sum(abs2, fÃÇ(current_guess))

        func_iter += 3

        Œ± = 1.0
        Œ±ÃÑ = 1.0

        ŒΩÃÇ = ŒΩ

        guess_update .= current_guess - previous_guess

        fnj.func(fnj.func_buffer, previous_guess_untransformed, parameters_and_solved_vars)

        g = fnj.func_buffer' * ‚àáÃÑ * guess_update
        # g = fÃÇ(previous_guess)' * ‚àá * guess_update
        U = sum(abs2,guess_update)
        func_iter += 1

        if PÃã > œÅ * P 
            linesearch_iterations = 0
            while PÃã > (1 + ŒΩÃÇ - œÅ¬π * Œ±^2) * PÃÉ + œÅ¬≤ * Œ±^2 * g - œÅ¬≥ * Œ±^2 * U && linesearch_iterations < max_linesearch_iterations
                if backtracking_order == 2
                    # Quadratic backtracking line search
                    Œ±ÃÇ = -g * Œ±^2 / (2 * (PÃã - PÃÉ - g * Œ±))
                elseif backtracking_order == 3
                    # Cubic backtracking line search
                    a = (Œ±ÃÑ^2 * (PÃã - PÃÉ - g * Œ±) - Œ±^2 * (P - PÃÉ - g * Œ±ÃÑ)) / (Œ±ÃÑ^2 * Œ±^2 * (Œ± - Œ±ÃÑ))
                    b = (Œ±^3 * (P - PÃÉ - g * Œ±ÃÑ) - Œ±ÃÑ^3 * (PÃã - PÃÉ - g * Œ±)) / (Œ±ÃÑ^2 * Œ±^2 * (Œ± - Œ±ÃÑ))

                    if isapprox(a, zero(a), atol=eps())
                        Œ±ÃÇ = g / (2 * b)
                    else
                        # discriminant
                        d = max(b^2 - 3 * a * g, 0)
                        # quadratic equation root
                        Œ±ÃÇ = (sqrt(d) - b) / (3 * a)
                    end

                    Œ±ÃÑ = Œ±
                end

                Œ±ÃÇ = min(Œ±ÃÇ, œïÃÑ * Œ±)
                Œ± = max(Œ±ÃÇ, œïÃÇ * Œ±)
                
                copy!(current_guess, previous_guess)
                ‚Ñí.axpy!(Œ±, guess_update, current_guess)
                # current_guess .= previous_guess + Œ± * guess_update
                minmax!(current_guess, lower_bounds, upper_bounds)
                
                P = PÃã

                copy!(current_guess_untransformed, current_guess)

                for _ in 1:transformation_level
                    current_guess_untransformed .= sinh.(current_guess_untransformed)
                end

                fnj.func(fnj.func_buffer, current_guess_untransformed, parameters_and_solved_vars)

                PÃã = sum(abs2, fnj.func_buffer)
                # PÃã = sum(abs2, fÃÇ(current_guess))
                func_iter += 1

                ŒΩÃÇ *= Œ±

                linesearch_iterations += 1
            end

            Œº¬π *= ŒªÃÖ¬π
            Œº¬≤ *= ŒªÃÖ¬≤

            p¬π *= ŒªÃÇÃÖ¬π
            p¬≤ *= ŒªÃÇÃÖ¬≤
        else
            Œº¬π = min(Œº¬π / Œª¬π, ŒºÃÑ¬π)
            Œº¬≤ = min(Œº¬≤ / Œª¬≤, ŒºÃÑ¬≤)

            p¬π = min(p¬π / ŒªÃÇ¬π, pÃÑ¬π)
            p¬≤ = min(p¬≤ / ŒªÃÇ¬≤, pÃÑ¬≤)
        end

        best_previous_guess = undo_transform(previous_guess, transformation_level)
        best_current_guess = undo_transform(current_guess, transformation_level)

        largest_step = ‚Ñí.norm(best_previous_guess - best_current_guess) # maximum(abs, previous_guess - current_guess)
        largest_relative_step = largest_step / max(‚Ñí.norm(best_previous_guess), ‚Ñí.norm(best_current_guess)) # maximum(abs, (previous_guess - current_guess) ./ previous_guess)
        
        copy!(current_guess_untransformed, current_guess)

        for _ in 1:transformation_level
            current_guess_untransformed .= sinh.(current_guess_untransformed)
        end

        fnj.func(fnj.func_buffer, current_guess_untransformed, parameters_and_solved_vars)

        largest_residual = ‚Ñí.norm(fnj.func_buffer)    
        # largest_residual = ‚Ñí.norm(fÃÇ(current_guess)) # maximum(abs, f(undo_transform(current_guess,transformation_level)))
        # largest_residual = maximum(abs, f(undo_transform(current_guess,transformation_level,shift)))

        # allow for norm increases (in both measures) as this can lead to the solution
        
        if largest_residual <= ftol || largest_step <= xtol || largest_relative_step <= rel_xtol
            # println("LM Iteration: $iter; xtol ($xtol): $largest_step; ftol ($ftol): $largest_residual; rel_xtol ($rel_xtol): $largest_relative_step")
            break
            # else
            # end
        end
    end
    
    best_guess = undo_transform(current_guess, transformation_level)

    return best_guess, (grad_iter, func_iter, largest_relative_step, largest_residual)#, f(best_guess))
end


function newton(
    # f::Function, 
    fnj::function_and_jacobian, 
    initial_guess::Array{T,1}, 
    parameters_and_solved_vars::Array{T,1},
    lower_bounds::Array{T,1}, 
    upper_bounds::Array{T,1},
    parameters::solver_parameters;
    tol::Tolerances = Tolerances()
    )::Tuple{Vector{T}, Tuple{Int, Int, T, T}} where {T <: AbstractFloat}
    # issues with optimization: https://www.gurobi.com/documentation/8.1/refman/numerics_gurobi_guidelines.html

    xtol = tol.NSSS_xtol
    ftol = tol.NSSS_ftol
    rel_xtol = tol.NSSS_rel_xtol

    iterations = 250
    transformation_level = 0 # parameters.transformation_level

    @assert size(lower_bounds) == size(upper_bounds) == size(initial_guess)
    @assert all(lower_bounds .< upper_bounds)

    # function fÃÇ(x) 
    #     f(undo_transform(x,transformation_level))  
    # end

    # upper_bounds  = transform(upper_bounds,transformation_level)
    # lower_bounds  = transform(lower_bounds,transformation_level)

    # new_guess = copy(transform(initial_guess,transformation_level))

    new_guess = copy(initial_guess)
    guess_update = copy(initial_guess)

    fnj.func(fnj.func_buffer, new_guess, parameters_and_solved_vars)

    new_residuals = fnj.func_buffer
    # new_residuals = f(new_guess)

    ‚àá = copy(fnj.jac_buffer)

    if ‚àá isa SparseMatrixCSC
        prob = ùíÆ.LinearProblem(‚àá, new_guess, ùíÆ.UMFPACKFactorization())
    else
        prob = ùíÆ.LinearProblem(‚àá, new_guess)#, ùíÆ.CholeskyFactorization)
    end

    sol_cache = ùíÆ.init(prob)

    # ‚àá = Array{T,2}(undef, length(new_guess), length(new_guess))

    # prep = ùíü.prepare_jacobian(f, backend, new_guess)

    # largest_step = zero(T) + 1
    # largest_residual = zero(T) + 1

    rel_xtol_reached = 1.0
    rel_ftol_reached = 1.0
    new_residuals_norm = 1.0
    guess_update_norm = 1.0
    # init_residuals_norm = ‚Ñí.norm(new_residuals)
    iters = [0,0]
    # resnorm = 1.0
    # relresnorm = 1.0

    for iter in 1:iterations
    # while iter < iterations
        fnj.jac(fnj.jac_buffer, new_guess, parameters_and_solved_vars)

        if ‚àá isa SparseMatrixCSC
            copy!(‚àá.nzval, fnj.jac_buffer.nzval)
        else
            copy!(‚àá, fnj.jac_buffer)
        end
        # ùíü.jacobian!(f, ‚àá, prep, backend, new_guess)

        # old_residuals_norm = ‚Ñí.norm(new_residuals)

        # old_residuals = copy(new_residuals)

        fnj.func(fnj.func_buffer, new_guess, parameters_and_solved_vars)

        copy!(new_residuals, fnj.func_buffer)
        # new_residuals = f(new_guess)

        if !all(isfinite,new_residuals) 
            # println("GN not finite after $iter iteration; - rel_xtol: $rel_xtol_reached; ftol: $new_residuals_norm")  # rel_ftol: $rel_ftol_reached; 
            rel_xtol_reached = 1.0
            rel_ftol_reached = 1.0
            new_residuals_norm = 1.0
            break 
        end
        
        if new_residuals_norm < ftol || rel_xtol_reached < rel_xtol || guess_update_norm < xtol # || rel_ftol_reached < rel_ftol
            new_guess_norm = ‚Ñí.norm(new_guess)

            old_residuals_norm = new_residuals_norm

            new_residuals_norm = ‚Ñí.norm(new_residuals)
        
            sol_cache.A = ‚àá
            sol_cache.b = new_residuals
            ùíÆ.solve!(sol_cache)

            guess_update_norm = ‚Ñí.norm(sol_cache.u)
    
            ‚Ñí.axpy!(-1, sol_cache.u, new_guess)
    
            iters[1] += 1
            iters[2] += 1

            # println("GN worked with $(iter+1) iterations - xtol ($xtol): $guess_update_norm; ftol ($ftol): $new_residuals_norm; rel_xtol ($rel_xtol): $rel_xtol_reached")# rel_ftol: $rel_ftol_reached")
            break
        end

        new_guess_norm = ‚Ñí.norm(new_guess)

        old_residuals_norm = new_residuals_norm

        new_residuals_norm = ‚Ñí.norm(new_residuals)
        
        if iter > 5 && ‚Ñí.norm(rel_xtol_reached) > sqrt(rel_xtol) && new_residuals_norm > old_residuals_norm
            # println("GN: $iter, Norm increase")
            break
        end
        # if resnorm < ftol # && iter > 4
        #     println("GN worked with $iter iterations - norm: $resnorm; relative norm: $relresnorm")
        #     return undo_transform(new_guess,transformation_level), (iter, zero(T), zero(T), resnorm) # f(undo_transform(new_guess,transformation_level)))
        # end

        sol_cache.A = ‚àá
        sol_cache.b = new_residuals
        ùíÆ.solve!(sol_cache)
        copy!(guess_update, sol_cache.u)

        guess_update_norm = ‚Ñí.norm(guess_update)

        ‚Ñí.axpy!(-1, guess_update, new_guess)

        if !all(isfinite,new_guess) 
            # println("GN not finite after $iter iteration; - rel_xtol: $rel_xtol_reached; ftol: $new_residuals_norm")  # rel_ftol: $rel_ftol_reached; 
            rel_xtol_reached = 1.0
            rel_ftol_reached = 1.0
            new_residuals_norm = 1.0
            # iters = [iter,iter]
            break 
        end
        
        minmax!(new_guess, lower_bounds, upper_bounds)

        rel_xtol_reached = guess_update_norm / max(new_guess_norm, ‚Ñí.norm(new_guess))
        # rel_ftol_reached = new_residuals_norm / max(eps(),init_residuals_norm)
        
        iters[1] += 1
        iters[2] += 1

        # println("GN: $(iters[1]) iterations - rel_xtol: $rel_xtol_reached; ftol: $new_residuals_norm")
    end

    # if iters[1] == iterations
    #     println("GN failed to converge - rel_xtol: $rel_xtol_reached; ftol: $new_residuals_norm")#; rel_ftol: $rel_ftol_reached")
    # else
    #     println("GN converged after $(iters[1]) iterations - rel_xtol: $rel_xtol_reached; ftol: $new_residuals_norm")
    # end

    # best_guess = undo_transform(new_guess,transformation_level)
    
    return new_guess, (iters[1], iters[2], rel_xtol_reached, new_residuals_norm)
end



function minmax!(x::Vector{Float64},lb::Vector{Float64},ub::Vector{Float64})
    @inbounds for i in eachindex(x)
        x[i] = max(lb[i], min(x[i], ub[i]))
    end
end



# transformation of NSSS problem
function transform(x::Vector{T}, option::Int, shift::AbstractFloat)::Vector{T} where T <: Real
    if option == 4
        return asinh.(asinh.(asinh.(asinh.(x .+ shift))))
    elseif option == 3
        return asinh.(asinh.(asinh.(x .+ shift)))
    elseif option == 2
        return asinh.(asinh.(x .+ shift))
    elseif option == 1
        return asinh.(x .+ shift)
    else # if option == 0
        return x .+ shift
    end
end

function transform(x::Vector{T}, option::Int)::Vector{T} where T <: Real
    if option == 4
        return asinh.(asinh.(asinh.(asinh.(x))))
    elseif option == 3
        return asinh.(asinh.(asinh.(x)))
    elseif option == 2
        return asinh.(asinh.(x))
    elseif option == 1
        return asinh.(x)
    else # if option == 0
        return x
    end
end

function undo_transform(x::Vector{T}, option::R, shift::AbstractFloat)::Vector{T} where {T,R}
    if option == 4
        return sinh.(sinh.(sinh.(sinh.(x)))) .- shift
    elseif option == 3
        return sinh.(sinh.(sinh.(x))) .- shift
    elseif option == 2
        return sinh.(sinh.(x)) .- shift
    elseif option == 1
        return sinh.(x) .- shift
    else # if option == 0
        return x .- shift
    end
end

function undo_transform(x::Vector{T}, option::R)::Vector{T} where {T,R}
    if option == 4
        return sinh.(sinh.(sinh.(sinh.(x))))
    elseif option == 3
        return sinh.(sinh.(sinh.(x)))
    elseif option == 2
        return sinh.(sinh.(x))
    elseif option == 1
        return sinh.(x)
    else # if option == 0
        return x
    end
end

function undo_transform(x::T, option::R)::T where {T,R}

    x = ifelse(option == 1, 
            sinh(x), 
            ifelse(option == 2, 
                sinh(sinh(x)), 
                ifelse(option == 3, 
                    sinh(sinh(sinh(x))), 
                    ifelse(option == 4, 
                        sinh(sinh(sinh(sinh(x)))), 
                        x
                    )
                )
            )
        )
    return x
end

end # dispatch_doctor