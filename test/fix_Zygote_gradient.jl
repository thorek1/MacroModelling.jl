using SparseArrays
using MacroModelling
import MacroModelling: timings
using ForwardDiff
import LinearAlgebra as â„’
using FiniteDifferences, Zygote
import Optim, LineSearches
using Test, Random

# add FiniteDifferences, Zygote, Optim, LineSearches, Turing

@model RBC_CME begin
    y[0]=A[0]*k[-1]^alpha
    1/c[0]=beta*1/c[1]*(alpha*A[1]*k[0]^(alpha-1)+(1-delta))
    1/c[0]=beta*1/c[1]*(R[0]/Pi[+1])
    R[0] * beta =(Pi[0]/Pibar)^phi_pi
    A[0]*k[-1]^alpha=c[0]+k[0]-(1-delta*z_delta[0])*k[-1]
    z_delta[0] = 1 - rho_z_delta + rho_z_delta * z_delta[-1] + std_z_delta * delta_eps[x]
    A[0] = 1 - rhoz + rhoz * A[-1]  + std_eps * eps_z[x]
end


@parameters RBC_CME verbose = true begin
    # alpha | k[ss] / (4 * y[ss]) = cap_share
    # cap_share = 1.66
    alpha = .157

    # beta | R[ss] = R_ss
    # R_ss = 1.0035
    beta = .999

    # delta | c[ss]/y[ss] = 1 - I_K_ratio
    # delta | delta * k[ss]/y[ss] = I_K_ratio #check why this doesnt solve for y
    # I_K_ratio = .15
    delta = .0226

    # Pibar | Pi[ss] = Pi_ss
    # Pi_ss = 1.0025
    Pibar = 1.0008

    phi_pi = 1.5
    rhoz = .9
    std_eps = .0068
    rho_z_delta = .9
    std_z_delta = .005
end

get_solution(RBC_CME)

get_irf(RBC_CME; parameters = RBC_CME.parameter_values)


Random.seed!(3)

data = simulate(RBC_CME)[:,:,1]
observables = [:c,:k]
# @test isapprox(425.7689804539224, get_loglikelihood(RBC_CME, data(observables), RBC_CME.parameter_values),rtol = 1e-5)

forw_grad = ForwardDiff.gradient(x -> get_loglikelihood(RBC_CME, data(observables), x), Float64.(RBC_CME.parameter_values))
reverse_grad = Zygote.gradient(x -> get_loglikelihood(RBC_CME, data(observables), x), Float64.(RBC_CME.parameter_values))[1]

fin_grad = FiniteDifferences.grad(central_fdm(4,1),x -> get_loglikelihood(RBC_CME, data(observables), x), RBC_CME.parameter_values)[1]

@test isapprox(fin_grad, reverse_grad, rtol = 1.0e-6)
# @test isapprox(forw_grad, reverse_grad, rtol = 1.0e-6)
# @test isapprox(fin_grad, forw_grad, rtol = 1.0e-6)

# calc the individual gradients
import MacroModelling: get_and_check_observables, get_relevant_steady_state_and_state_update, calculate_loglikelihood, check_bounds, get_initial_covariance, run_kalman_iterations
ğ“‚ = RBC_CME
data = data(observables)
parameter_values = RBC_CME.parameter_values
algorithm = :first_order
filter = :kalman
warmup_iterations = 0
presample_periods = 0
initial_covariance = :theoretical
tol = 1e-12
verbose = false
T = ğ“‚.timings
# checks to avoid errors further down the line and inform the user
@assert filter âˆˆ [:kalman, :inversion] "Currently only the Kalman filter (:kalman) for linear models and the inversion filter (:inversion) for linear and nonlinear models are supported."

# checks to avoid errors further down the line and inform the user
@assert initial_covariance âˆˆ [:theoretical, :diagonal] "Invalid method to initialise the Kalman filters covariance matrix. Supported methods are: the theoretical long run values (option `:theoretical`) or large values (10.0) along the diagonal (option `:diagonal`)."

if algorithm âˆˆ [:second_order,:pruned_second_order,:third_order,:pruned_third_order]
    filter = :inversion
end

observables = get_and_check_observables(ğ“‚, data)

solve!(ğ“‚, verbose = verbose, algorithm = algorithm)

bounds_violated = check_bounds(parameter_values, ğ“‚)

NSSS_labels = [sort(union(ğ“‚.exo_present, ğ“‚.var))..., ğ“‚.calibration_equations_parameters...]

obs_indices = convert(Vector{Int}, indexin(observables, NSSS_labels))

T, SS_and_pars, ğ’, state, solved = get_relevant_steady_state_and_state_update(Val(algorithm), parameter_values, ğ“‚, tol)

# prepare data
data_in_deviations = collect(data(observables)) .- SS_and_pars[obs_indices]

observables_index = convert(Vector{Int},indexin(observables,sort(union(T.aux,T.var,T.exo_present))))

observables_and_states = sort(union(T.past_not_future_and_mixed_idx,observables_index))

A = ğ’[observables_and_states,1:T.nPast_not_future_and_mixed] * â„’.diagm(ones(length(observables_and_states)))[(indexin(T.past_not_future_and_mixed_idx,observables_and_states)),:]
B = ğ’[observables_and_states,T.nPast_not_future_and_mixed+1:end]

C = â„’.diagm(ones(length(observables_and_states)))[(indexin(sort(observables_index), observables_and_states)),:]

ğ = B * B'

# Gaussian Prior
coordinates = Tuple{Vector{Int}, Vector{Int}}[]

dimensions = [size(A),size(ğ)]

values = vcat(vec(A), vec(collect(-ğ)))

P = get_initial_covariance(Val(initial_covariance), values, coordinates, dimensions)




fin_A = FiniteDifferences.grad(central_fdm(3,1),
A -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), A)[1]

for_A = ForwardDiff.gradient(A -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), A)
bac_A = Zygote.gradient(A -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), A)[1]
isapprox(for_A, bac_A, rtol = 1e-6)

fin_ğ = FiniteDifferences.grad(central_fdm(4,1),
ğ -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), ğ)[1]

for_ğ = ForwardDiff.gradient(ğ -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), ğ)
bac_ğ = Zygote.gradient(ğ -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), ğ)[1]
isapprox(for_ğ, bac_ğ, rtol = 1e-6)

fin_P = FiniteDifferences.grad(central_fdm(2,1),
P -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), P)[1]

for_P = ForwardDiff.gradient(P -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), P)
bac_P = Zygote.gradient(P -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), P)[1]
isapprox(for_P, bac_P, rtol = 1e-6)

fin_data_in_deviations = FiniteDifferences.grad(central_fdm(3,1),
data_in_deviations -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), data_in_deviations)[1]

for_data_in_deviations = ForwardDiff.gradient(data_in_deviations -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), data_in_deviations)
bac_data_in_deviations = Zygote.gradient(data_in_deviations -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), data_in_deviations)[1]

isapprox(for_data_in_deviations, bac_data_in_deviations, rtol = 1e-6)


Zygote.withgradient(data_in_deviations -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), data_in_deviations)[1]


import LinearAlgebra: mul!, logdet
import RecursiveFactorization as RF

P = get_initial_covariance(Val(initial_covariance), values, coordinates, dimensions)

âˆ‚llh = 1


T = size(data_in_deviations, 2) + 1

z = zeros(size(data_in_deviations, 1))

uÌ„ = zeros(size(C,2))

PÌ„ = deepcopy(P) 

temp_N_N = similar(P)

PCtmp = similar(C')

F = similar(C * C')

u = [similar(uÌ„) for _ in 1:T] # used in backward pass

P = [deepcopy(PÌ„) for _ in 1:T] # used in backward pass

CP = [zero(C) for _ in 1:T] # used in backward pass

K = [similar(C') for _ in 1:T] # used in backward pass

invF = [similar(F) for _ in 1:T] # used in backward pass

v = [zeros(size(data_in_deviations, 1)) for _ in 1:T] # used in backward pass

loglik = 0.0

for t in 2:T
    v[t] .= data_in_deviations[:, t-1] .- z#[t-1]

    # CP[t] .= C * PÌ„[t-1]
    mul!(CP[t], C, PÌ„)#[t-1])

    # F[t] .= CP[t] * C'
    mul!(F, CP[t], C')

    luF = RF.lu(F, check = false)

    if !â„’.issuccess(luF)
        return -Inf, x -> NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent()
    end

    Fdet = â„’.det(luF)

    # Early return if determinant is too small, indicating numerical instability.
    if Fdet < eps(Float64)
        return -Inf, x -> NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent(), NoTangent()
    end
    
    # invF[t] .= inv(luF)
    copy!(invF[t], inv(luF))
    
    if t - 1 > presample_periods
        loglik += log(Fdet) + â„’.dot(v[t], invF[t], v[t])
    end

    # K[t] .= PÌ„[t-1] * C' * invF[t]
    mul!(PCtmp, PÌ„, C')
    mul!(K[t], PCtmp, invF[t])

    # P[t] .= PÌ„[t-1] - K[t] * CP[t]
    mul!(P[t], K[t], CP[t], -1, 0)
    P[t] .+= PÌ„

    # PÌ„[t] .= A * P[t] * A' + ğ
    mul!(temp_N_N, P[t], A')
    mul!(PÌ„, A, temp_N_N)
    PÌ„ .+= ğ

    # u[t] .= K[t] * v[t] + uÌ„[t-1]
    mul!(u[t], K[t], v[t])
    u[t] .+= uÌ„
    
    # uÌ„[t] .= A * u[t]
    mul!(uÌ„, A, u[t])

    # z[t] .= C * uÌ„[t]
    mul!(z, C, uÌ„)
end

llh = -(loglik + ((size(data_in_deviations, 2) - presample_periods) * size(data_in_deviations, 1)) * log(2 * 3.141592653589793)) / 2 

# initialise derivative variables
âˆ‚A = zero(A)
âˆ‚F = zero(F)
âˆ‚Faccum = zero(F)
âˆ‚P = zero(PÌ„)
âˆ‚uÌ„ = zero(uÌ„)
âˆ‚uÌ„âˆ‚v = zero(uÌ„)
âˆ‚ğ = zero(ğ)
âˆ‚data_in_deviations = zero(data_in_deviations)
vtmp = zero(v[1])
Ptmp = zero(P[1])

# pullback
# function kalman_pullback(âˆ‚llh)
â„’.rmul!(âˆ‚A, 0)
â„’.rmul!(âˆ‚Faccum, 0)
â„’.rmul!(âˆ‚P, 0)
â„’.rmul!(âˆ‚uÌ„, 0)
â„’.rmul!(âˆ‚ğ, 0)

# t = T-1
for t in T:-1:2
    if t > presample_periods + 1
        # âˆ‚llhâˆ‚F
        # loglik += logdet(F[t]) + v[t]' * invF[t] * v[t]
        # âˆ‚F = invF[t]' - invF[t]' * v[t] * v[t]' * invF[t]'
        mul!(âˆ‚F, v[t], v[t]')
        mul!(invF[1], invF[t]', âˆ‚F) # using invF[1] as temporary storage
        mul!(âˆ‚F, invF[1], invF[t]')
        â„’.axpby!(1, invF[t]', -1, âˆ‚F)

        # âˆ‚llhâˆ‚uÌ„
        # loglik += logdet(F[t]) + v[t]' * invF[t] * v[t]
        # z[t] .= C * uÌ„[t]
        # âˆ‚uÌ„âˆ‚v = C' * (invF[t]' + invF[t]) * v[t]
        copy!(invF[1], invF[t]' + invF[t]) # using invF[1] as temporary storage
        mul!(v[1], invF[1], v[t]) # using v[1] as temporary storage
        mul!(âˆ‚uÌ„âˆ‚v, C', v[1])
    else
        â„’.rmul!(âˆ‚F, 0)
        â„’.rmul!(âˆ‚uÌ„âˆ‚v, 0)
    end

    # âˆ‚Fâˆ‚P
    # F[t] .= C * PÌ„[t-1] * C'
    # âˆ‚P += C' * (âˆ‚F + âˆ‚Faccum) * C
    â„’.axpy!(1, âˆ‚Faccum, âˆ‚F)
    mul!(PCtmp, C', âˆ‚F) 
    mul!(âˆ‚P, PCtmp, C, 1, 1) 

    # âˆ‚uÌ„âˆ‚P
    # K[t] .= PÌ„[t-1] * C' * invF[t]
    # u[t] .= K[t] * v[t] + uÌ„[t-1]
    # uÌ„[t] .= A * u[t]
    # âˆ‚P += A' * âˆ‚uÌ„ * v[t]' * invF[t]' * C
    mul!(CP[1], invF[t]', C) # using CP[1] as temporary storage
    mul!(PCtmp, âˆ‚uÌ„ , v[t]')
    mul!(P[1], PCtmp , CP[1]) # using P[1] as temporary storage
    mul!(âˆ‚P, A', P[1], 1, 1) 

    # âˆ‚uÌ„âˆ‚data
    # v[t] .= data_in_deviations[:, t-1] .- z
    # z[t] .= C * uÌ„[t]
    âˆ‚data_in_deviations[:,t-1] = C * âˆ‚uÌ„âˆ‚v + K[t]' * A' * âˆ‚uÌ„
    # mul!(vtmp, C, âˆ‚uÌ„)
    # â„’.rmul!(vtmp, -1)
    # âˆ‚data_in_deviations[:,t-1] .= vtmp
    # mul!(âˆ‚data_in_deviations[:,t-1], C, âˆ‚uÌ„, -1, 0) # cannot assign to columns in matrix, must be whole matrix 

    # âˆ‚uÌ„âˆ‚uÌ„
    # z[t] .= C * uÌ„[t]
    # v[t] .= data_in_deviations[:, t-1] .- z
    # K[t] .= PÌ„[t-1] * C' * invF[t]
    # u[t] .= K[t] * v[t] + uÌ„[t-1]
    # uÌ„[t] .= A * u[t]
    # step to next iteration
    âˆ‚uÌ„ = A' * âˆ‚uÌ„ - C' * K[t]' * A' * âˆ‚uÌ„
    # âˆ‚uÌ„ = C' * K[t]' * A' * âˆ‚uÌ„
    # mul!(u[1], A', âˆ‚uÌ„) # using u[1] as temporary storage
    # mul!(v[1], K[t]', u[1]) # using v[1] as temporary storage
    # mul!(u[1], C', v[1], -1, 1)
    # copy!(âˆ‚uÌ„, u[1])

    # âˆ‚llhâˆ‚uÌ„
    # loglik += logdet(F[t]) + v[t]' * invF[t] * v[t]
    # v[t] .= data_in_deviations[:, t-1] .- z
    # z[t] .= C * uÌ„[t]
    # âˆ‚uÌ„ -= âˆ‚uÌ„âˆ‚v
    â„’.axpy!(-1, âˆ‚uÌ„âˆ‚v, âˆ‚uÌ„)


    if t > 2
        # âˆ‚uÌ„âˆ‚A
        # uÌ„[t] .= A * u[t]
        # âˆ‚A += âˆ‚uÌ„ * u[t-1]'
        mul!(âˆ‚A, âˆ‚uÌ„, u[t-1]', 1, 1)

        # âˆ‚PÌ„âˆ‚A and âˆ‚PÌ„âˆ‚ğ
        # PÌ„[t] .= A * P[t] * A' + ğ
        # âˆ‚A += âˆ‚P * A * P[t-1]' + âˆ‚P' * A * P[t-1]
        mul!(P[1], A, P[t-1]')
        mul!(Ptmp ,âˆ‚P, P[1])
        mul!(P[1], A, P[t-1])
        mul!(Ptmp ,âˆ‚P', P[1], 1, 1)
        â„’.axpy!(1, Ptmp, âˆ‚A)

        # âˆ‚ğ += âˆ‚P
        â„’.axpy!(1, âˆ‚P, âˆ‚ğ)

        # âˆ‚Pâˆ‚P
        # P[t] .= PÌ„[t-1] - K[t] * C * PÌ„[t-1]
        # PÌ„[t] .= A * P[t] * A' + ğ
        # step to next iteration
        # âˆ‚P = A' * âˆ‚P * A
        mul!(P[1], âˆ‚P, A) # using P[1] as temporary storage
        mul!(âˆ‚P, A', P[1])

        # âˆ‚PÌ„âˆ‚P
        # K[t] .= PÌ„[t-1] * C' * invF[t]
        # P[t] .= PÌ„[t-1] - K[t] * CP[t]
        # âˆ‚P -= C' * K[t-1]' * âˆ‚P + âˆ‚P * K[t-1] * C 
        mul!(PCtmp, âˆ‚P, K[t-1])
        mul!(CP[1], K[t-1]', âˆ‚P) # using CP[1] as temporary storage
        mul!(âˆ‚P, PCtmp, C, -1, 1)
        mul!(âˆ‚P, C', CP[1], -1, 1)

        # âˆ‚uÌ„âˆ‚F
        # K[t] .= PÌ„[t-1] * C' * invF[t]
        # u[t] .= K[t] * v[t] + uÌ„[t-1]
        # uÌ„[t] .= A * u[t]
        # âˆ‚Faccum = -invF[t-1]' * CP[t-1] * A' * âˆ‚uÌ„ * v[t-1]' * invF[t-1]'
        mul!(u[1], A', âˆ‚uÌ„) # using u[1] as temporary storage
        mul!(v[1], CP[t-1], u[1]) # using v[1] as temporary storage
        mul!(vtmp, invF[t-1]', v[1], -1, 0)
        mul!(invF[1], vtmp, v[t-1]') # using invF[1] as temporary storage
        mul!(âˆ‚Faccum, invF[1], invF[t-1]')

        # âˆ‚Pâˆ‚F
        # K[t] .= PÌ„[t-1] * C' * invF[t]
        # P[t] .= PÌ„[t-1] - K[t] * CP[t]
        # âˆ‚Faccum -= invF[t-1]' * CP[t-1] * âˆ‚P * CP[t-1]' * invF[t-1]'
        mul!(CP[1], invF[t-1]', CP[t-1]) # using CP[1] as temporary storage
        mul!(PCtmp, CP[t-1]', invF[t-1]')
        mul!(K[1], âˆ‚P, PCtmp) # using K[1] as temporary storage
        mul!(âˆ‚Faccum, CP[1], K[1], -1, 1)

    end
end

â„’.rmul!(âˆ‚P, -âˆ‚llh/2)
â„’.rmul!(âˆ‚A, -âˆ‚llh/2)
â„’.rmul!(âˆ‚ğ, -âˆ‚llh/2)
â„’.rmul!(âˆ‚data_in_deviations, -âˆ‚llh/2)

# return NoTangent(), âˆ‚A, âˆ‚ğ, NoTangent(), âˆ‚P, âˆ‚data_in_deviations, NoTangent()
# end



PP = get_initial_covariance(Val(initial_covariance), values, coordinates, dimensions)

observables = data_in_deviations

T = size(observables, 2) + 1

u = [zeros(size(C,2)) for _ in 1:T]

u_mid = deepcopy(u)

z = [zeros(size(observables, 1)) for _ in 1:T]

P_mid = [deepcopy(PP) for _ in 1:T]

temp_N_N = similar(PP)

P = deepcopy(P_mid)

B_prod = ğ
# Ct = collect(C')
CP = [zero(C) for _ in 1:T]

K = [zero(C') for _ in 1:T]

cc = C * C'

V = [zero(cc) for _ in 1:T]

invV = [zero(cc) for _ in 1:T]

V[1] += â„’.I
invV[1] = inv(V[1])

innovation = deepcopy(z)

# V[1] .= C * P[1] * C'

loglik = (0.0)



for t in 2:T
    CP[t] .= C * P_mid[t-1]

    V[t] .= CP[t] * C'

    luV = â„’.lu(V[t], check = false)

    Vdet = â„’.det(luV)
    
    invV[t] .= inv(luV)
    
    innovation[t] .= observables[:, t-1] - z[t-1]
    
    loglik += log(Vdet) + innovation[t]' * invV[t] * innovation[t]

    K[t] .= P_mid[t-1] * C' * invV[t]

    u[t] .= K[t] * innovation[t] + u_mid[t-1]
    
    P[t] .= P_mid[t-1] - K[t] * CP[t]

    u_mid[t] .= A * u[t]

    z[t] .= C * u_mid[t]

    P_mid[t] .= A * P[t] * A' + B_prod
end

llh = -(loglik + ((size(data_in_deviations, 2) - presample_periods) * size(data_in_deviations, 1)) * log(2 * 3.141592653589793)) / 2 


zyggrad = Zygote.gradient(
    x -> begin
        CP2 = C * PP
        V2 = CP2 * C'
        K2 = PP * C' * inv(V2)
        innovation2 = x[:, 1] - z[1]
        u2 = K2 * innovation2 + u_mid[1]
        P2 = PP - K2 * CP2
        u_mid2 = A * u2
        z2 = C * u_mid2
        P_mid2 = A * P2 * A' + B_prod

        CP3 = C * P_mid2
        V3 = CP3 * C'
        innovation3 = x[:, 2] - z2
        K3 = P_mid2 * C' * inv(V3)
        u3 = K3 * innovation3 + u_mid2
        P3 = P_mid2 - K3 * CP3
        u_mid3 = A * u3
        z3 = C * u_mid3
        P_mid3 = A * P3 * A' + B_prod

        CP4 = C * P_mid3
        V4 = CP4 * C'
        innovation4 = x[:, 3] - z3

        # return -1/2*(logdet(V[2]) + innovation2' * inv(V[2]) * innovation2)
        # return -1/2*(logdet(V[3]) + innovation3' * inv(V[3]) * innovation3)
        # return -1/2*(logdet(V[2]) + innovation2' * inv(V[2]) * innovation2 + logdet(V[3]) + innovation3' * inv(V[3]) * innovation3)
        # return -1/2*(logdet(V[4]) + innovation4' * inv(V[4]) * innovation4)
        # return -1/2*(logdet(V4) + innovation4' * inv(V4) * innovation4 + logdet(V3) + innovation3' * inv(V3) * innovation3)
        return -1/2*(logdet(V2) + innovation2' * inv(V2) * innovation2 + logdet(V3) + innovation3' * inv(V3) * innovation3 + logdet(V4) + innovation4' * inv(V4) * innovation4)
    end, 
    observables)[1]




innovation4 = observables[:, 3] - C * A * (K3 * (observables[:, 2] - C * A * (K2 * (x[:, 1] - z[1]) + u_mid[1])) + A * (K2 * (x[:, 1] - z[1]) + u_mid[1]))

innovation4 = - C * A * (K3 * ( - C * A * (K2 * x)))

K[2]' * A' * C' * K[3]' * A' * C' * (invF[4]' + invF[4]) * v[4]


innovation4 = - C * A * A * K2 * x

-K[2]' * A' * A' * C' * (invF[4]' + invF[4]) * v[4]


K[2]' * A' * C' * K[3]' * A' * C' * (invF[4]' + invF[4]) * v[4] - K[2]' * A' * A' * C' * (invF[4]' + invF[4]) * v[4]


(invF[3]' + invF[3]) * v[3]
for_data_in_deviations

P = get_initial_covariance(Val(initial_covariance), values, coordinates, dimensions)

for_data_in_deviations = ForwardDiff.gradient(data_in_deviations -> run_kalman_iterations(A, ğ, C, P, data_in_deviations, presample_periods = presample_periods), data_in_deviations[:,1:2][:,:])
zyggrad


addd = K[t]' * A' * âˆ‚uÌ„âˆ‚v

C * A' * âˆ‚uÌ„âˆ‚v3 + K[t]' * A' * âˆ‚uÌ„âˆ‚v3

for_data_in_deviations[:,1]


zyggrad

t = 4
-(K[t-1]' * A' * C' * (invF[t-1]' + invF[t-1]) * v[t-1] + (invF[t+0]' + invF[t+0]) * v[t+0])/2

âˆ‚uÌ„âˆ‚v4 = C' * (invF[t]' + invF[t]) * v[t]

âˆ‚llh4âˆ‚o2 = K[t]' * A' * âˆ‚uÌ„âˆ‚v4

# âˆ‚llh4âˆ‚o1 = K[t-1]' * A' * C' * âˆ‚llh4âˆ‚o2 - K[t-1]' * A' * A' * C' * (invF[t]' + invF[t]) * v[t]
âˆ‚llh4âˆ‚o1 = K[t-1]' * A' * C' * K[t]' * A' * âˆ‚uÌ„âˆ‚v4 - K[t-1]' * A' * A' * âˆ‚uÌ„âˆ‚v4


# K[t-1]' * A' * C' * invF[t-1] * v[t-1]

# K[t-1]' * A' * C' * invF[t-1] * v[t-1] + (v[t-1]' * invF[t-1] * C * A * K[t-1])

# K[t-1]' * A' * C' * (invF[t-1]' + invF[t-1]) * v[t-1]

t = 4
âˆ‚uÌ„âˆ‚v4 = C' * (invF[t]' + invF[t]) * v[t]
C * âˆ‚uÌ„âˆ‚v4 /-2
âˆ‚uÌ„ = âˆ‚uÌ„âˆ‚v4



-(C*âˆ‚uÌ„âˆ‚v3 - âˆ‚llh4âˆ‚o2)/2

t = 3
# âˆ‚uÌ„ =  C' * K[t]' * A' * âˆ‚uÌ„
âˆ‚uÌ„âˆ‚v3 = C' * (invF[t]' + invF[t]) * v[t]
C * âˆ‚uÌ„âˆ‚v3 - K[t]' * A' * âˆ‚uÌ„
# âˆ‚uÌ„ = A' * âˆ‚uÌ„ - C' * K[t]' * A' * âˆ‚uÌ„
# C * âˆ‚uÌ„âˆ‚v3 /-2
# âˆ‚uÌ„ -= âˆ‚uÌ„âˆ‚v3
-âˆ‚uÌ„/2

t = 2
# âˆ‚uÌ„ = A' * âˆ‚uÌ„ - C' * K[t]' * A' * âˆ‚uÌ„
âˆ‚uÌ„ =  C' * K[t]' * A' * âˆ‚uÌ„
âˆ‚uÌ„âˆ‚v2 = C' * (invF[t]' + invF[t]) * v[t]
âˆ‚uÌ„ -= âˆ‚uÌ„âˆ‚v2

# -(A' * âˆ‚uÌ„âˆ‚v3 - C' * K[t]' * A' * âˆ‚uÌ„âˆ‚v3 - âˆ‚uÌ„âˆ‚v2)/2
# âˆ‚uÌ„âˆ‚v = C' * K[t]' * A' * C' * (invF[t]' + invF[t]) * v[t] - addd

âˆ‚uÌ„/-2



for_data_in_deviations[:,1] - C * âˆ‚uÌ„âˆ‚v2/2


âˆ‚data_in_deviations

zyggrad


# initialise derivative variables
âˆ‚A = zero(A)
âˆ‚F = zero(F)
âˆ‚Faccum = zero(F)
âˆ‚P = zero(PÌ„)
âˆ‚uÌ„ = zero(uÌ„)
âˆ‚v = zero(v[1])
âˆ‚vÌ‚ = zero(v[1])
âˆ‚uÌ‚ = zero(uÌ„)
âˆ‚z = zero(z[1])
âˆ‚uÌ„âˆ‚v = zero(uÌ„)
âˆ‚ğ = zero(ğ)
âˆ‚data_in_deviations = zero(data_in_deviations)
vtmp = zero(v[1])
Ptmp = zero(P[1])


for t in 4:-1:2
    if t > presample_periods + 1
        # âˆ‚F = invF[t]' - invF[t]' * v[t] * v[t]' * invF[t]'
        # âˆ‚uÌ„âˆ‚v = C' * (invF[t]' + invF[t]) * v[t]
        âˆ‚v = (invF[t]' + invF[t]) * v[t]
    else
        # â„’.rmul!(âˆ‚F, 0)
        â„’.rmul!(âˆ‚uÌ„âˆ‚v, 0)
    end

    # âˆ‚z = C' * âˆ‚vÌ‚
    # âˆ‚uÌ„ = A' * âˆ‚z
    # âˆ‚u = K[t] * âˆ‚vÌ‚ + âˆ‚uÌ„
    # âˆ‚P += C' * (âˆ‚F + âˆ‚Faccum) * C
    # âˆ‚P += A' * âˆ‚uÌ„ * v[t]' * invF[t]' * C

    mul!(u[1], A', âˆ‚uÌ„)
    mul!(v[1], K[t]', u[1]) # using v[1] as temporary storage
    â„’.axpy!(1, âˆ‚v, v[1])
    âˆ‚data_in_deviations[:,t-1] .= v[1]
    # âˆ‚data_in_deviations[:,t-1] = K[t]' * A' * âˆ‚uÌ„ + âˆ‚vÌ‚

    âˆ‚uÌ„ = A' * âˆ‚uÌ„ - C' * K[t]' * A' * âˆ‚uÌ„
    âˆ‚uÌ„ -= C' * âˆ‚v


    # âˆ‚uÌ‚ = A' * C' * âˆ‚vÌ‚
    # âˆ‚v = - K[t]' * âˆ‚uÌ‚
    

    if t > 2
        # âˆ‚A += âˆ‚uÌ„ * u[t-1]'
        # âˆ‚A += âˆ‚P * A * P[t-1]' + âˆ‚P' * A * P[t-1]

        # âˆ‚ğ += âˆ‚P

        # âˆ‚P = A' * âˆ‚P * A
        # âˆ‚P -= C' * K[t-1]' * âˆ‚P + âˆ‚P * K[t-1] * C 

        # âˆ‚Faccum = -invF[t-1]' * CP[t-1] * A' * âˆ‚uÌ„ * v[t-1]' * invF[t-1]'
        # âˆ‚Faccum -= invF[t-1]' * CP[t-1] * âˆ‚P * CP[t-1]' * invF[t-1]'
    end
end


â„’.rmul!(âˆ‚P, -âˆ‚llh/2)
â„’.rmul!(âˆ‚A, -âˆ‚llh/2)
â„’.rmul!(âˆ‚ğ, -âˆ‚llh/2)
â„’.rmul!(âˆ‚data_in_deviations, -âˆ‚llh/2)

zyggrad

# obs in t = 1 impact on innovation2
(invF[2]' + invF[2]) * v[2] 

# obs in t = 1 impact on innovation3
-K[2]' * A' * C' * (invF[3]' + invF[3]) * v[3]

# obs in t = 1 impact on innovation4
K[2]' * A' * C' * K[3]' * A' * C' * (invF[4]' + invF[4]) * v[4]    - K[2]' * A' * A' * C' * (invF[4]' + invF[4]) * v[4]

(K[2]' * A' * C' * K[3]' - K[2]' * A') * A' * C' * (invF[4]' + invF[4]) * v[4]

K[2]' * A' * (C' * K[3]' - â„’.I) * A' * C' * (invF[4]' + invF[4]) * v[4]
K[2]' * A' * (C' * K[3]' - â„’.I) * A' * C' * (invF[4]' + invF[4]) * v[4]


(invF[2]' + invF[2]) * v[2]  + -K[2]' * A' * C' * (invF[3]' + invF[3]) * v[3] + K[2]' * A' * C' * K[3]' * A' * C' * (invF[4]' + invF[4]) * v[4] - K[2]' * A' * A' * C' * (invF[4]' + invF[4]) * v[4]