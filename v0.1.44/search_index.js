var documenterSearchIndex = {"docs":
[{"location":"plot_solution/#Policy-Functions","page":"Policy Functions","title":"Policy Functions","text":"The plot_solution function visualizes the solution of the model (mapping of past states to present variables) around the relevant steady state (e.g. higher order perturbation algorithms are centred around the stochastic steady state).\n\nThe relevant steady state is plotted along with the mapping from the chosen past state to one present variable per subplot. All other (non-chosen) states remain in the relevant steady state.\n\nIn the case of pruned higher order solutions there are as many (latent) state vectors as the perturbation order. The first and third order state vectors are the non-stochastic steady state and the second order state vector is the stochastic steady state. Deviations for the chosen state are only added to the first order state. The plot shows the mapping from σ standard deviations (first order) added to the first order non-stochastic steady state and the present variables. Note that there is no unique mapping from the \"pruned\" states and the \"actual\" reported state. Hence, the plots shown are just one realisation of infinitely many possible mappings.\n\nIf the model contains occasionally binding constraints and ignore_obc = false they are enforced using shocks.\n\nFirst, define and load a model:\n\n@model Gali_2015_chapter_3_nonlinear begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0])\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_nonlinear begin\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\nend\n\nCalling plot_solution requires specifying a state variable. By default, it plots all endogenous variables, that do vary for different values of the specified state, as functions of the specified state over a range of ±2 standard deviations:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A)\n\n(Image: Gali 2015 solution)\n\nThe function plots each endogenous variable in period t against the state variable A in t-1. Each subplot shows how the variable changes on the y-axis as A varies within the specified range over the x-axis. The relevant steady state is indicated by a circle of the same color as the line. The title of each subplot indicates the variable name and the title of the overall plot indicates the model name, and page number (if multiple pages are needed). The legend below the plots indicate the solution algorithm used and the nature of the steady state (stochastic or non-stochastic).","category":"section"},{"location":"plot_solution/#Combine-Policy-Functions-with-plot_solution!","page":"Policy Functions","title":"Combine Policy Functions with plot_solution!","text":"The plot_solution! function (note the exclamation mark !) adds additional policy functions to an existing plot created with plot_solution, enabling direct comparison between different scenarios. Any input argument that affects the model's output (such as solution algorithm, parameter values, or occasionally binding constraints) can be varied to compare how these changes influence the policy functions. See the respective subsections below (e.g., Solution Algorithm, Parameter Values, Ignoring Occasionally Binding Constraints) for details on specific arguments.\n\nWhen using plot_solution!, the new policy function is overlaid on the existing plot with a different color. Both the policy function line and the steady state marker (circle) use the same color to make identification easier.\n\nLegend and table behavior:\n\nWhen inputs differ in one dimension (e.g., only the algorithm changes), the legend displays the value of that input dimension for each line (e.g., :first_order, :second_order).\nWhen inputs differ in multiple dimensions (e.g., both algorithm and parameters change), the legend shows sequential numbers (1, 2, 3, ...) and references a table below the plot that details all input differences for each numbered scenario.\nTables below the plot show relevant information such as input differences and steady state values to help identify differences across scenarios.\n\nExample with single input difference:\n\nWhen only one input differs (e.g., the solution algorithm), the legend shows the algorithm names directly:\n\n# Plot first-order solution\nplot_solution(Gali_2015_chapter_3_nonlinear, :A)\n\n# Add second-order solution to the same plot\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    algorithm = :second_order)\n\n(Image: Gali 2015 solution - first and second order)\n\nThe legend will display :first_order and :second_order to identify each policy function.\n\nExample with multiple input differences:\n\nWhen multiple inputs differ (e.g., both algorithm and parameters), the legend shows sequential numbers and a table details the differences:\n\n# Plot with baseline parameters\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.99)\n\n# Add with different algorithm AND parameters\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.95,\n    algorithm = :second_order)\n\n(Image: Gali 2015 solution - comparing β values across algorithms)\n\nThe legend will show 1 and 2, with a table below the plot listing the parameter and algorithm values for each scenario.","category":"section"},{"location":"plot_solution/#State-Variable-(Required)","page":"Policy Functions","title":"State Variable (Required)","text":"The state argument (type: Union{Symbol, String}) specifies which state variable to vary. This must be a state variable from the model (variables with lagged values). If a state variable is provided that is not part of the model's state vector, an error is raised and the valid state variables are listed.\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A)  # Using Symbol\nplot_solution(Gali_2015_chapter_3_nonlinear, \"A\") # Using String","category":"section"},{"location":"plot_solution/#Variables-to-Plot","page":"Policy Functions","title":"Variables to Plot","text":"The variables argument (default: :all) specifies for which variables to show results. Variable names can be specified as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc includes all variables except auxiliary variables and those related to occasionally binding constraints (OBC). :all_excluding_obc includes all variables except those related to occasionally binding constraints. :all includes all variables.\n\nSpecific variables can be selected to plot. The following example selects only output (Y) and inflation (Pi) using a Vector of Symbols:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = [:Y, :Pi])\n\n(Image: Gali 2015 solution - selected variables (Y, Pi))\n\nThe plot now displays only the two selected variables (sorted alphabetically), with two subplots for each shock. The same can be done using a Tuple:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = (:Y, :Pi))\n\na Matrix:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = [:Y :Pi])\n\nor providing the variable names as Strings:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = [\"Y\", \"Pi\"])\n\nor a single variable as a Symbol:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = :Y)\n\nor as a String:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = \"Y\")\n\nThen there are some predefined options:\n\n:all_excluding_auxiliary_and_obc plots all variables except auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = :all_excluding_auxiliary_and_obc)\n\n:all_excluding_obc plots all variables except those used to enforce occasionally binding constraints (OBC).\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = :all_excluding_obc)\n\nTo see auxiliary variables, use a model that defines them. The FS2000 model can be used:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nSince both c and P appear in t+2, they generate auxiliary variables in the model. Plotting the policy functions for all variables excluding OBC-related ones means auxiliary variables are shown (same for the default :all option since there are no OBCs in this model):\n\nplot_solution(FS2000, :k,\n    variables = :all_excluding_obc)\n\n(Image: FS2000 solution - including auxiliary variables)\n\nBoth c and P appear twice: once as the variable itself and once as an auxiliary variable with the ᴸ⁽¹⁾ superscript, representing the value of the variable in t+1 as expected in t.\n\n:all (default) plots all variables including auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nUse the Gali_2015_chapter_3 model with an effective lower bound (note the use of the max function in the Taylor rule):\n\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\n    R > 1.0001\nend\n\nPlotting the policy functions for all variables including OBC-related ones reveals the OBC-related auxiliary variables:\n\nplot_solution(Gali_2015_chapter_3_obc, :A)\n\n(Image: Gali 2015 OBC solution - including auxilliary and OBC variables)\n\nThe OBC-related variables appear in the last two subplots. Note that high values of A in the previous period lead to low values of the nominal interest rate R in the current period, hitting the lower bound (indicated by the flat section of the policy function). For values of A where the constraint is binding the OBC-related variables also vary with A:\n\n(Image: Gali 2015 OBC solution - OBC-related variables)\n\nThe effective lower bound is enforced using shocks to the equation containing the max statement. See the documentation for details on constructing occasionally binding constraints. For this specific model, examine the equations the parser generated to enforce the OBC:\n\nget_equations(Gali_2015_chapter_3_obc)\n# 68-element Vector{String}:\n#  \"W_real[0] = C[0] ^ σ * N[0] ^ φ\"\n#  \"Q[0] = ((β * (C[1] / C[0]) ^ -σ * Z[1]) / Z[0]) / Pi[1]\"\n#  \"R[0] = 1 / Q[0]\"\n#  \"Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\"\n#  \"R[0] = Pi[1] * realinterest[0]\"\n#  \"χᵒᵇᶜ⁺ꜝ¹ꜝˡ[0] = R̄ - R[0]\"\n#  ⋮\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁶⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁵⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽⁴⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁷⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁶⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽³⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁸⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁷⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽²⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁹⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁸⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽¹⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻⁴⁰⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁹⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽⁰⁾[x]\"","category":"section"},{"location":"plot_solution/#Solution-Algorithm","page":"Policy Functions","title":"Solution Algorithm","text":"The algorithm argument (default: :first_order, type: Symbol) specifies which algorithm to use to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order.\n\nCompare different solution algorithms by overlaying plots with plot_solution!. The example below plots the first-order solution and then overlays the second-order solution for comparison:\n\n# Plot first-order policy function\nplot_solution(Gali_2015_chapter_3_nonlinear, :A)\n\n# Overlay second-order to compare\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    algorithm = :second_order)\n\n(Image: Gali 2015 solution - multiple solution methods)\n\nThe plot now features both policy functions overlaid. The first-order solution is shown in blue, the second-order solution is shown in orange, as indicated in the legend below the plot. The lines correspond to the policy functions at different orders and the circles indicate the relevant steady state for each solution method. Higher order solutions may have different steady states due to the inclusion of risk effects (see e.g. W_real) and their policy functions may differ due to non-linearities captured at higher orders (see e.g. S which has only higher order dynamics).\n\nAdditional solution methods can be added to the same plot:\n\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    algorithm = :pruned_third_order)\n\n(Image: Gali 2015 solution - multiple solution methods (up to 3rd order))\n\nThe additional solution appears as another colored line with corresponding entries in the legend. Note that the pruned third-order solution incorporates time-varying risk and reverses the sign of the response for MC and N.","category":"section"},{"location":"plot_solution/#State-Variable-Range","page":"Policy Functions","title":"State Variable Range","text":"The σ argument (default: 2, type: Union{Int64, Float64}) specifies the range of the state variable as a multiple of its standard deviation. The state variable varies from -σ * std(state) to +σ * std(state).\n\nPlot over a wider range (±5 standard deviations) using the pruned third-order solution:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    σ = 5,\n    algorithm = :pruned_third_order)\n\n(Image: Gali 2015 solution - 5 standard deviations)\n\nThis expands the x-axis range, showing how the policy functions behave further from the steady state.","category":"section"},{"location":"plot_solution/#Parameter-Values","page":"Policy Functions","title":"Parameter Values","text":"When no parameters are provided, the solution uses the previously defined parameter values. Parameters can be provided as a Vector of values, or as a Vector or Tuple of Pairs mapping parameter Symbols or Strings to values. The solution is recalculated when new parameter values differ from the previous ones.\n\nStart by changing the discount factor β to 0.95:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.95)\n\n(Image: Gali 2015 solution - different parameter values)\n\nThe steady states and dynamics changed as a result of changing the discount factor. To better visualize the differences between β = 0.99 and β = 0.95, the two policy functions can be overlaid (compared). Since parameter changes are permanent, first reset β = 0.99 before overlaying the policy function with β = 0.95 on top of it:\n\n# Plot with default parameters\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.99)\n\n# Overlay with different discount factor to compare\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.95)\n\n(Image: Gali 2015 solution - comparing β values)\n\nThe legend below the plot indicates which color corresponds to which β value. Note that both the steady states and dynamics differ across the two β values.\n\nMultiple parameters can also be changed simultaneously to compare the results to previous plots. This example changes β to 0.97 and τ to 0.5 using a Tuple of Pairs and define the variables with Symbols:\n\nplot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = (:β => 0.97, :τ => 0.5))\n\n(Image: Gali 2015 solution - multiple parameter changes)\n\nSince the plot function calls now differ in multiple input arguments, the legend indicates which color corresponds to which input combination, with the table showing relevant input combinations.\n\nA Vector of Pairs can also be used:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = [:β => 0.98, :τ => 0.25])\n\nAlternatively, use a Vector of parameter values in the order they were defined in the model. To obtain them:\n\nparams = get_parameters(Gali_2015_chapter_3_nonlinear, values = true)\n# 16-element Vector{Pair{String, Float64}}:\n#       \"σ\" => 1.0\n#       \"φ\" => 5.0\n#     \"ϕᵖⁱ\" => 1.5\n#      \"ϕʸ\" => 0.125\n#       \"θ\" => 0.75\n#     \"ρ_ν\" => 0.5\n#     \"ρ_z\" => 0.5\n#     \"ρ_a\" => 0.9\n#       \"β\" => 0.95\n#       \"η\" => 3.77\n#       \"α\" => 0.25\n#       \"ϵ\" => 9.0\n#       \"τ\" => 0.5\n#   \"std_a\" => 0.01\n#   \"std_z\" => 0.05\n#  \"std_nu\" => 0.0025\n\nparam_vals = [p[2] for p in params]\n# 16-element Vector{Float64}:\n#  1.0\n#  5.0\n#  1.5\n#  0.125\n#  0.75\n#  0.5\n#  0.5\n#  0.9\n#  0.95\n#  3.77\n#  0.25\n#  9.0\n#  0.5\n#  0.01\n#  0.05\n#  0.0025\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = param_vals)","category":"section"},{"location":"plot_solution/#Ignoring-Occasionally-Binding-Constraints","page":"Policy Functions","title":"Ignoring Occasionally Binding Constraints","text":"The ignore_obc argument (default: false, type: Bool), when true, ignores occasionally binding constraints (OBC) even if they are part of the model. This is useful for comparing dynamics with and without OBC. For models with defined OBC, use the ignore_obc argument to ignore them. The following example compares the policy functions of the Gali_2015_chapter_3_obc model with and without OBC. First, examine the policy function with OBC enforced. Since OBC is enforced by default, call:\n\nplot_solution(Gali_2015_chapter_3_obc, :A)\n\n(Image: Gali 2015 OBC solution - OBC)\n\nThen overlay the policy function ignoring the OBC:\n\nplot_solution!(Gali_2015_chapter_3_obc, :A,\n    ignore_obc = true)\n\n(Image: Gali 2015 OBC solution - comparing with and without OBC)\n\nThe legend indicates which color corresponds to which ignore_obc value. The difference between the two can be noticed at the effective lower bound for R. For values of A where the effective lower bound is reached the shocks enforcing the lower bound act on the economy and the policy function changes for most other variables as well.","category":"section"},{"location":"plot_solution/#Plot-Labels","page":"Policy Functions","title":"Plot Labels","text":"The label argument (type: Union{Real, String, Symbol}) adds custom labels to the plot legend. This is useful when comparing multiple solutions using plot_solution! to overlay plots. By default, labels take on the values of the one dimensional input that differs and are sequential numbers in case the input differs along more than one dimension. Furthermore, custom labels can be provided using this argument. Acceptable inputs are a String, Symbol, or a Real.\n\n# Compare policy functions with different settings\nplot_solution(Gali_2015_chapter_3_obc, :A,\n    algorithm = :pruned_second_order,\n    parameters = :β => 0.99,\n    label = \"2nd Order with OBC\"\n    )\n\n# Add solution without OBC\nplot_solution!(Gali_2015_chapter_3_obc, :A,\n    algorithm = :pruned_second_order,\n    ignore_obc = true,\n    label = \"2nd Order without OBC\"\n    )\n\n# Add different parameter setting\nplot_solution!(Gali_2015_chapter_3_obc, :A,\n    algorithm = :pruned_second_order,\n    parameters = :β => 0.9925,\n    label = \"2nd Order with OBC and β=0.9925\"\n    )\n\n(Image: Gali 2015 OBC solution - custom labels)\n\nThe plot demonstrates how to use labels to describe complex inputs. Here variations in multiple input dimensions are compared: solution algorithms, occasionally binding constraints, and parameter values.","category":"section"},{"location":"plot_solution/#Plot-Attributes","page":"Policy Functions","title":"Plot Attributes","text":"The plot_attributes argument (default: Dict(), type: Dict) accepts a dictionary of attributes passed on to the plotting function. See the Plots.jl documentation for details.\n\nThe color palette can be customized using the plot_attributes argument. The following example defines a custom color palette (inspired by the European Commission's economic reports) to plot policy functions for multiple solution algorithms using the Gali_2015_chapter_3_nonlinear model. First, define the custom color palette using hex color codes:\n\nec_color_palette =\n[\n    \"#FFD724\",  # \"Sunflower Yellow\"\n    \"#353B73\",  # \"Navy Blue\"\n    \"#2F9AFB\",  # \"Sky Blue\"\n    \"#B8AAA2\",  # \"Taupe Grey\"\n    \"#E75118\",  # \"Vermilion\"\n    \"#6DC7A9\",  # \"Mint Green\"\n    \"#F09874\",  # \"Coral\"\n    \"#907800\"   # \"Olive\"\n]\n\nNext, plot the policy function for the first order solution algorithm using the custom color palette:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    plot_attributes = Dict(:palette => ec_color_palette))\n\nFinally, overlay the policy functions for the second and third order solution algorithms using the custom color palette:\n\nfor a in [:second_order, :third_order]\n    plot_solution!(Gali_2015_chapter_3_nonlinear, :A,\n        algorithm = a,\n        plot_attributes = Dict(:palette => ec_color_palette))\nend\n\n(Image: Gali 2015 solution - different solution algorithms custom color palette)\n\nThe colors of the policy functions and steady state markers now follow the custom color palette.\n\nOther attributes such as the font family can also be modified (see here for GR font options):\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    plot_attributes = Dict(:fontfamily => \"computer modern\"))\n\n(Image: Gali 2015 solution - custom font)\n\nAll text in the plot now uses the Computer Modern font. Note that font rendering inherits the constraints of the plotting backend (GR in this case)—for example, the subscripts (e.g. ₍₀₎) are not rendered properly for this font.\n\nHere is another example that customizes the line style and width:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    plot_attributes = Dict(:linestyle => :dashdot, :linewidth => 2))\n\n(Image: Gali 2015 solution - custom linestyle and width)","category":"section"},{"location":"plot_solution/#Plots-Per-Page","page":"Policy Functions","title":"Plots Per Page","text":"The plots_per_page argument (default: 6, type: Int) controls the number of subplots per page. When the number of variables exceeds this value, multiple pages are created. The following example selects 4 variables and sets plots_per_page to 2, resulting in 2 pages with 2 subplots each:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    variables = [:Y, :Pi, :R, :C],\n    plots_per_page = 2)\n\n(Image: Gali 2015 solution - 2 plots per page)\n\nThe first page displays the first two variables (sorted alphabetically) with two subplots for each shock. The title indicates this is page 1 of 2.","category":"section"},{"location":"plot_solution/#Display-Plots","page":"Policy Functions","title":"Display Plots","text":"The show_plots argument (default: true, type: Bool), when true, displays the plots; otherwise, they are only returned as an object.\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    show_plots = false)","category":"section"},{"location":"plot_solution/#Saving-Plots","page":"Policy Functions","title":"Saving Plots","text":"The save_plots argument (default: false, type: Bool), when true, saves the plots to disk; otherwise, they are only displayed and returned as an object.\n\nRelated arguments control the saving behavior:\n\nsave_plots_format (default: :pdf, type: Symbol): output format of saved plots. See input formats compatible with GR for valid formats.\nsave_plots_path (default: \".\", type: String): path where plots are saved. If the path does not exist, it will be created automatically.\nsave_plots_name (default: \"solution\", type: Union{String, Symbol}): prefix prepended to the filename when saving plots.\n\nEach plot is saved as a separate file with a name indicating the prefix, model name, shocks, and a sequential number for multiple plots (e.g., solution__ModelName__shock__1.pdf).\n\nThe following example saves all policy functions for the Gali_2015_chapter_3_nonlinear model as PNG files in the ../plots directory with policy_function as the filename prefix:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    save_plots = true,\n    save_plots_format = :png,\n    save_plots_path = \"./../plots\",\n    save_plots_name = :policy_function)\n\nThe plots appear in the specified folder with the specified prefix. Each plot is saved in a separate file with a name reflecting the model, the shock, and a sequential index when the number of variables exceeds the plots per page.","category":"section"},{"location":"plot_solution/#Variable-and-Shock-Renaming-(rename-dictionary)","page":"Policy Functions","title":"Variable and Shock Renaming (rename dictionary)","text":"The rename_dictionary argument (default: Dict(), type: AbstractDict{<:Union{Symbol, String}, <:Union{Symbol, String}}) maps variable or shock symbols to custom display names in plots. This is particularly useful when comparing models with different variable naming conventions, allowing them to be displayed with consistent labels.\n\nFor example, to rename variables for clearer display:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    rename_dictionary = Dict(:Y => \"Output\", :Pi => \"Inflation\", :R => \"Interest Rate\"))\n\n(Image: Gali 2015 solution - rename dictionary)\n\nThis feature is especially valuable when plotting policy functions from different models. Consider comparing FS2000 (which uses R for the interest rate) with Caldara_et_al_2012 (which uses gross_r for the interest rate expressed as a gross return). The rename_dictionary allows harmonizing these names when plotting them together.\n\nLet's first parse the Caldara_et_al_2012 model:\n\n@model Caldara_et_al_2012 begin\n    V[0] = ((1 - β) * (c[0] ^ ν * (1 - l[0]) ^ (1 - ν)) ^ (1 - 1 / ψ) + β * V[1] ^ (1 - 1 / ψ)) ^ (1 / (1 - 1 / ψ))\n    exp(s[0]) = V[1] ^ (1 - γ)\n    1 = (1 + ζ * exp(z[1]) * k[0] ^ (ζ - 1) * l[1] ^ (1 - ζ) - δ) * c[0] * β * (((1 - l[1]) / (1 - l[0])) ^ (1 - ν) * (c[1] / c[0]) ^ ν) ^ (1 - 1 / ψ) / c[1]\n    Rᵏ[0] = ζ * exp(z[1]) * k[0] ^ (ζ - 1) * l[1] ^ (1 - ζ) - δ\n    SDF⁺¹[0] = c[0] * β * (((1 - l[1]) / (1 - l[0])) ^ (1 - ν) * (c[1] / c[0]) ^ ν) ^ (1 - 1 / ψ) / c[1]\n    1 + Rᶠ[0] = 1 / SDF⁺¹[0]\n    (1 - ν) / ν * c[0] / (1 - l[0]) = (1 - ζ) * exp(z[0]) * k[-1] ^ ζ * l[0] ^ (-ζ)\n    c[0] + i[0] = exp(z[0]) * k[-1] ^ ζ * l[0] ^ (1 - ζ)\n    k[0] = i[0] + k[-1] * (1 - δ)\n    z[0] = λ * z[-1] + σ[0] * ϵᶻ[x]\n    y[0] = exp(z[0]) * k[-1] ^ ζ * l[0] ^ (1 - ζ)\n    log(σ[0]) = (1 - ρ) * log(σ̄) + ρ * log(σ[-1]) + η * ω[x]\n    gross_r[0] = 1 + Rᶠ[0]\nend\n\n@parameters Caldara_et_al_2012 begin\n    β = 0.991\n    l[ss] = 1/3 | ν\n    ζ = 0.3\n    δ = 0.0196\n    λ = 0.95\n    ψ = 0.5\n    γ = 40\n    σ̄ = 0.021\n    η = 0.1\n    ρ = 0.9\nend\n\nand then plot the solutions from both models with consistent variable names using rename_dictionary:\n\n# First model (FS2000) with lowercase variable names\nplot_solution(FS2000, :k,\n    variables = [:c, :y, :R],\n    rename_dictionary = Dict(:c => \"Consumption\", :y => \"Output\", :R => \"Interest Rate\"))\n\n# Overlay second model (Caldara_et_al_2012) with different naming, mapped to same display names\nplot_solution!(Caldara_et_al_2012, :k,\n    variables = [:c, :y, :gross_r],\n    rename_dictionary = Dict(:c => \"Consumption\", :y => \"Output\", :gross_r => \"Interest Rate\"))\n\n(Image: FS2000 and Gali 2015 solution - multiple models with rename dictionary)\n\nAs can be seen the steady states and dynamics around the respective steady states differ across states and variables for the two models but they are shown in the same subplots with consistent labels.\n\nThe rename_dictionary accepts flexible type combinations for keys and values—both Symbol and String types work interchangeably:\n\n# All of these are valid and equivalent:\nDict(:y => \"Output\")              # Symbol key, String value\nDict(\"y\" => \"Output\")             # String key, String value\nDict(:y => :Output)               # Symbol key, Symbol value\nDict(\"y\" => :Output)              # String key, Symbol value\n\nThis flexibility is particularly useful for models like Backus_Kehoe_Kydland_1992, which uses String representations of variable and shock names (because of {}):\n\n# Define the Backus model (abbreviated for clarity)\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1-theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1/nu{co})\n        K{co}[0] = (1-delta{co})*K{co}[-1] + S{co}[0]\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n        A{co}[0] = (1-eta{co}) * A{co}[-1] + N{co}[0]\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1-alpha{co})*eta{co} * A{co}[-1]\n        U{co}[0] = (C{co}[0]^mu{co}*L{co}[0]^(1-mu{co}))^gamma{co}\n        psi{co} * mu{co} / C{co}[0]*U{co}[0] = LGM[0]\n        psi{co} * (1-mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1-theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co}*N{co}[0]^(1-theta{co}))^(-nu{co})*Y{co}[0]^(1+nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1-delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1-theta{co})) ^ (-nu{co})* Y{co}[+4]^(1+nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1+sigma{co} * Z{co}[0]^(-nu{co}-1)*Y{co}[+1]^(1+nu{co}))\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1]))/Y{co}[0]\n    end\n\n    (LAMBDA{H}[0]-1) = rho{H}{H}*(LAMBDA{H}[-1]-1) + rho{H}{F}*(LAMBDA{F}[-1]-1) + Z_E{H} * E{H}[x]\n    (LAMBDA{F}[0]-1) = rho{F}{F}*(LAMBDA{F}[-1]-1) + rho{F}{H}*(LAMBDA{H}[-1]-1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend\n\n# Backus model example showing String to String mapping\nplot_solution(Backus_Kehoe_Kydland_1992, \"K{H}\",\n    rename_dictionary = Dict(\"K{H}\" => \"Capital (Home)\", \n                             \"K{F}\" => \"Capital (Foreign)\",\n                             \"Y{H}\" => \"Output (Home)\",\n                             \"Y{F}\" => \"Output (Foreign)\"))\n\n(Image: Backus, Kehoe, Kydland 1992 solution - rename dictionary)\n\nVariables or shocks not included in the dictionary retain their default names. The renaming applies to all plot elements including legends, axis labels, and tables.","category":"section"},{"location":"plot_solution/#Verbose-Output","page":"Policy Functions","title":"Verbose Output","text":"The verbose argument (default: false, type: Bool), when true, enables verbose output related to solving the model\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    verbose = true)\n\nThe code outputs information about solving the steady state blocks. When parameters change, the first-order solution is recomputed; otherwise, it uses the cached solution:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    parameters = :β => 0.955,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.99       to 0.955\n# New parameters changed the steady state.\n# Block: 1, - Solved with newton using previous solution - 1.1102230246251565e-16 - 4.2410519540681003e-16 - [6, 6]\n# Block: 2, - Solved with newton using previous solution - 1.1102230246251565e-16 - 5.691489219773501e-16 - [3, 3]\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.138740904769479e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 1.1102230246251565e-16\n# Quadratic matrix equation solver previous solution has tolerance: 3.138740904769479e-15\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 1.3848825622828143e-16; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 1.1102230246251565e-16","category":"section"},{"location":"plot_solution/#Numerical-Tolerances","page":"Policy Functions","title":"Numerical Tolerances","text":"The tol argument (default: Tolerances(), type: Tolerances) defines various tolerances for the algorithm used to solve the model. See the Tolerances documentation for more details: ?Tolerances. The tolerances used by the numerical solvers can be adjusted. The Tolerances object allows setting tolerances for the non-stochastic steady state solver (NSSS), Sylvester equations, Lyapunov equation, and quadratic matrix equation (QME). For example, to set tighter tolerances (this example also changes parameters to force recomputation):\n\ncustom_tol = Tolerances(qme_acceptance_tol = 1e-12,\n    sylvester_acceptance_tol = 1e-12)\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    tol = custom_tol,\n    algorithm = :second_order,\n    parameters = :β => 0.9555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.955      to 0.9555\n# New parameters changed the steady state.\n# Take symbolic derivatives up to second order:                           0.695 seconds\n# Block: 1, - Solved with newton using previous solution - 3.1401849173675503e-16 - 3.4746121346743126e-13 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 5.20740757162067e-16 - 4.1252659916132045e-16 - [3, 3]\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.98829092574606e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.551115123125783e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.98829092574606e-15\n# Sylvester equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 8.152041655449966e-17; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.551115123125783e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.98829092574606e-15\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 1.5026261035607414e-16; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.551115123125783e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.551115123125783e-16\n\nThis is useful when higher precision is needed or when the default tolerances are insufficient for convergence. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_solution/#Quadratic-Matrix-Equation-Solver","page":"Policy Functions","title":"Quadratic Matrix Equation Solver","text":"The quadratic_matrix_equation_algorithm argument (default: :schur, type: Symbol) specifies the algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling The quadratic matrix equation solver is used internally when solving the model to first order. Different algorithms are available. The :schur algorithm is generally faster and more reliable, while :doubling can be more precise in some cases (this example also changes parameters to force recomputation):\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    quadratic_matrix_equation_algorithm = :doubling,\n    parameters = :β => 0.95555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.9555     to 0.95555\n# New parameters changed the steady state.\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver: doubling - converged: true in 8 iterations to tolerance: 2.5226767989622104e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 8.580119223206854e-17; algorithm: doubling\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n\nFor most use cases, the default :schur algorithm is recommended. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_solution/#Sylvester-Equation-Solver","page":"Policy Functions","title":"Sylvester Equation Solver","text":"[Default: selector that uses :doubling for smaller problems and switches to :bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: Algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. The input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solution's Sylvester equation. When only one element is provided, it corresponds to the second-order perturbation solution's Sylvester equation. The algorithm to use can be specified for solving Sylvester equations in higher-order solutions. For example, select the :bartels_stewart algorithm for solving the second-order perturbation problem:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    algorithm = :second_order,\n    sylvester_algorithm = :bartels_stewart,\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: -1; reached tol: 8.857092101472476e-17; algorithm: bartels_stewart\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 8.580119223206854e-17; algorithm: doubling\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n\nFor third-order solutions, different algorithms can be specified for the second- and third-order Sylvester equations using a Tuple:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    algorithm = :third_order,\n    sylvester_algorithm = (:doubling, :bicgstab),\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Sylvester equation - previous solution achieves relative tol of 8.646717716454426e-17\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Sylvester equation - previous solution achieves relative tol of 8.646717716454426e-17\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: 20; reached tol: 2.246045342648752e-16; algorithm: bicgstab\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 8.580119223206854e-17; algorithm: doubling\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n\nThe choice of algorithm affects both speed and precision: :doubling and :bartels_stewart are generally faster, while :bicgstab, :dqgmres, and :gmres are better for large sparse problems. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_solution/#Lyapunov-Equation-Solver","page":"Policy Functions","title":"Lyapunov Equation Solver","text":"[Default: :doubling, Type: Symbol]: Algorithm to solve the Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres.\n\nThe algorithm is used to compute the first-order standard deviation that defines the range for the state variable. A different algorithm can be specified for solving the Lyapunov equation. For example, the :bartels_stewart algorithm can be selected:\n\nplot_solution(Gali_2015_chapter_3_nonlinear, :A,\n    lyapunov_algorithm = :bartels_stewart,\n    verbose = true)\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 2.5226767989622104e-16\n# Lyapunov equation - converged to tol 1.0e-12: true; iterations: 0; reached tol: 6.174299026893289e-17; algorithm: bartels_stewart\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 4.839349969133127e-16 - 4.1390488915798046e-16 - [3, 3]\n\nThe choice of algorithm affects both speed and precision: :doubling and :bartels_stewart are generally faster, while :bicgstab, and :gmres are better for large sparse problems. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_model_estimates/#Model-Estimates","page":"Model Estimates","title":"Model Estimates","text":"plot_model_estimates visualizes the variables used in an estimation problem: the filtered or smoothed estimates of endogenous variables and exogenous shocks, an unconditional forecast extending beyond the last data period, and optionally the contribution of each shock to the endogenous variables. Each subplot shows a variable or shock as a line and, when enabled, shock contributions as stacked bars measured against the non‑stochastic or stochastic steady state relevant for the selected solution algorithm. The unconditional forecast (shown as a dashed line by default for 12 periods) displays the model's expected path absent any exongeos shocks starting from the final filtered state. Occasionally binding constraints are not supported by this function. The function returns a Vector{Plots.Plot}, enabling the figures to be displayed, saved, or combined further.\n\nThe figures are built with StatsPlots.jl/Plots.jl and expect a KeyedArray from the AxisKeys package as data input. Axis 1 must contain the observable names, axis 2 the period labels. Observables are automatically matched to model variables, renamed (if desired), and sorted alphabetically in the plot legends. Period labels can be of any format compatible with Plots.jl and are used to fill the x-axis of the plots.\n\nIn order to run the examples on this page, the following packages need to be installed and loaded:\n\nusing MacroModelling, StatsPlots, CSV, DataFrames, AxisKeys, Dates\n\nThe latter four packages are only needed to load the data.\n\nNext, define and load a model:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nThe second argument is always the data on which to base the model estimates. The following code loads data from a CSV file and converts it to a KeyedArray:\n\ndat = CSV.read(\"test/data/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)',Variable = Symbol.(\"log_\".*names(dat)),Time = 1:size(dat)[1])\ndata = log.(data)\n\nGiven the model and data the model estimates can be plotted as follows:\n\nplot_model_estimates(FS2000, data)\n\n(Image: FS2000 model estimates)\n\nThe function plots the filtered or smoothed estimates of the model variables that correspond to the observables in the data, along with the shock decomposition. Each subplot displays an observable or filtered variable (as a line plot) or the contribution of a shock (as stacked bars) measured against the relevant steady state for the chosen solution algorithm.\n\nAnother way to plot the model estimates including the shock decomposition is by calling:\n\nplot_shock_decomposition(FS2000, data)\n\nThis produces the same output as plot_model_estimates with shock_decomposition = true, which is the default setting for first order, pruned second order, and pruned third order solution algorithms.","category":"section"},{"location":"plot_model_estimates/#Compare-Model-Estimates-with-plot_model_estimates!","page":"Model Estimates","title":"Compare Model Estimates with plot_model_estimates!","text":"The plot_model_estimates! function (note the exclamation mark !) adds additional model estimates to an existing plot created with plot_model_estimates, enabling direct comparison between different scenarios. Any input argument that affects the model's output (such as datasets, solution algorithm, parameter values, filtering methods, or smoothing options) can be varied to compare how these changes influence the estimates. See the respective subsections below (e.g., Data, Filter, Solution Algorithm, Parameter Values) for details on specific arguments.\n\nWhen using plot_model_estimates!, the new estimates are overlaid on the existing plot with a different color. Note that when combining multiple plots, shock decomposition is automatically disabled to avoid visual clutter - only the line plots showing the estimates are displayed.\n\nLegend and table behavior:\n\nWhen inputs differ in one dimension (e.g., only the algorithm changes), the legend displays the value of that input dimension for each line (e.g., :first_order, :second_order).\nWhen inputs differ in multiple dimensions (e.g., different datasets and parameters), the legend shows sequential numbers (1, 2, 3, ...) and references a table below the plot that details all input differences for each numbered scenario.\nDifferent data inputs are indexed with a running number in the legend for easy reference.\nAdditional tables below show the relevant steady state values for each scenario to help identify differences across solution methods or parameter values.\n\nExample with single input difference:\n\nWhen only one input differs (e.g., the solution algorithm), the legend shows the algorithm names directly:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\n\n# Plot first-order estimates\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data)\n\n# Add second-order estimates to the same plot\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     algorithm = :second_order)\n\n(Image: Gali 2015 model estimates - first and second order)\n\nThe legend will display :first_order and :second_order to identify each estimate.\n\nThe subplot y-axis labels change depending on the steady state values and data availability for each scenario. If the steady state values differ across scenarios and there is no data for a variable, the y-axis label will indicate that the lines are in absolute deviations from the steady state. In that case no percent deviation is shown on the secondary y-axis, as the steady state values differ. In case the steady state values are the same across scenarios or there is data for a variable, the y-axis label indicates absolute levels on the primary y-axis. If the steady state values are the same and if the values are strictly positive the secondary y-axis shows the percent deviation scale. In case the steady state values differ but there is data for a variable, then levels are shown without percent deviation as the secondary axis and the steady states are shown as horizontal black lines.\n\nExample with multiple input differences:\n\nWhen multiple inputs differ (e.g., both algorithm and parameters), the legend shows sequential numbers and a table details the differences:\n\n# Plot with baseline parameters\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                    sim_data,\n                    parameters = :β => 0.99)\n\n# Add with different algorithm AND parameters\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = :β => 0.95,\n                     algorithm = :second_order)\n\n(Image: Gali 2015 model estimates - comparing β values across algorithms)\n\nThe legend will show 1 and 2, with a table below the plot listing the parameter and algorithm values for each scenario.","category":"section"},{"location":"plot_model_estimates/#Data-(Required)","page":"Model Estimates","title":"Data (Required)","text":"The data argument [Type: KeyedArray{Float64}] contains the data used for filtering or smoothing the model estimates. The first axis must contain variable names (as Symbols or Strings) and the second axis must contain period labels (as any format compatible with Plots.jl). Note that the second axis is used to fill the x-axis of the plots.\n\nPlotting model estimates with Symbols as variable names can be done as follows, but here the way to load the data is shown again for completeness, and can be done in various ways:\n\nvariable_names = Symbol.(\"log_\".*names(dat))\n\ndat = CSV.read(\"test/data/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)',Variable = variable_names, Time = 1:size(dat)[1])\ndata = log.(data)\n\nplot_model_estimates(FS2000, data)\n\nThe same can be done with Strings as variable names:\n\nvariable_names = \"log_\".*names(dat)\n\ndat = CSV.read(\"test/data/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)',Variable = variable_names, Time = 1:size(dat)[1])\ndata = log.(data)\n\nplot_model_estimates(FS2000, data)\n\nA useful feature is that the second dimension of the KeyedArray can be used to customize the x-axis labels of the plots. The following example shows how to create date labels for quarterly data starting from 1960-01-01:\n\ndat = CSV.read(\"test/data/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)', Variable = Symbol.(\"log_\".*names(dat)), Time = 1:size(dat)[1])\ndata = log.(data)\n\nfunction quarterly_dates(start_date::Date, len::Int)\n    dates = Vector{Date}(undef, len)\n    current_date = start_date\n    for i in 1:len\n        dates[i] = current_date\n        current_date = current_date + Dates.Month(3)\n    end\n    return dates\nend\n\ndata_rekey = rekey(data, :Time => quarterly_dates(Date(1960, 1, 1), size(data,2)))\n\nplot_model_estimates(FS2000, data_rekey)\n\n(Image: FS2000 model estimates - custom x-axis)\n\nThe function generates the date labels by starting from a given date and adding three months for each subsequent period. The rekey function from AxisKeys is then used to replace the second axis of the KeyedArray with the generated date labels. The resulting plot now has dates on the x-axis. Note that any input type for the second axis that Plots.jl can handle is valid.\n\nEstimates based on different data can also be compared:\n\nsim_data = simulate(FS2000)([:log_gy_obs,:log_gp_obs],:,:simulate)\nplot_model_estimates!(FS2000, sim_data)\n\n(Image: FS2000 model estimates - different data)\n\nNote that the different data inputs are indexed with a running number in the legend.","category":"section"},{"location":"plot_model_estimates/#Data-in-levels","page":"Model Estimates","title":"Data in levels","text":"By default, the data is assumed to be in levels (data_in_levels = true). If the data is in absolute deviations from the non-stochastic steady state, set data_in_levels = false.\n\nThe previously shown example uses data in levels, so that it is compatible with the default setting:\n\ndat = CSV.read(\"test/data/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)', Variable = \"log_\".*names(dat), Time = 1:size(dat)[1])\ndata = log.(data)\n\nplot_model_estimates(FS2000, data)\n\nData in absolute deviations from the non-stochastic steady state can be used as follows.\n\nA practical way to create data in deviation from the non-stochastic steady state is to use the simulate function with the argument levels = false. This generates random data in deviations for all endogenous variables, of which in the example below only R and y are used:\n\nsim = simulate(FS2000, levels = false)\nplot_model_estimates(FS2000, sim([:y,:R],:,:simulate), data_in_levels = false)\n\n(Image: FS2000 model estimates - data in deviations from non-stochastic steady state)","category":"section"},{"location":"plot_model_estimates/#Filter","page":"Model Estimates","title":"Filter","text":"The filter argument [Type: Symbol] specifies the filtering method to use. Options are :kalman for the Kalman filter or smoother (depending on the smooth argument) and :inversion for the inversion filter. By default, the Kalman smoother is used for first order solutions and the inversion method for higher order (nonlinear) solutions.\n\nA model featuring more than two shocks clearly illustrates the difference between the two filtering methods. The Gali (2015) model from chapter 3 with three shocks is presented below:\n\n@model Gali_2015_chapter_3_nonlinear begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0])\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_nonlinear begin\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\nend\n\nThe Kalman smoother (because by default smooth = true for the first order solution algorithm) can be explicitly specified as follows (but it would be the default in this case and there is no need to specify it):\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, filter = :kalman)\n\nand the inversion filter can be overlayed, in order to compare with the Kalman smoother, as:\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear, sim_data, filter = :inversion)\n\n(Image: Gali 2015 model estimates - inversion and Kalman filters)\n\nNote that the two filtering methods yield different results when there are more shocks than observables, as is the case here. The Kalman smoother (due to the default setting smooth = true) produces smoother estimates by optimally combining information from all periods, while the inversion filter directly solves for shocks that match the observables in each period. Furthermore, when comparing two estimates only the estimates but not the shock decomposition are shown.","category":"section"},{"location":"plot_model_estimates/#Smooth","page":"Model Estimates","title":"Smooth","text":"The smooth argument [Default: true, Type: Bool] specifies whether to use smoothing (only available for the Kalman filter and set to true by default for the Kalman filter) or filtering (available for both and set to true in case the inversion filter is used). If true, smoothed estimates are plotted, otherwise filtered estimates are shown. Smoothing uses information from the entire sample to estimate the states at each point in time, while filtering only uses information up to the current period.\n\nSmoothed estimates using the Kalman filter can be plotted as follows (this is the default behaviour and does not need to be specified explicitly):\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, \n                    sim_data, \n                    smooth = true)\n\ncomparing with filtered estimates (using the Kalman filter) can be done like this:\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear, \n                    sim_data, \n                    smooth = false)\n\n(Image: Gali 2015 model estimates - smoothing options)\n\nadditionally the filtered estimates can be compared using the inversion filter (with smooth = false being the default for the inversion filter which doesn't need to be specified explicitly):\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear, \n                    sim_data, \n                    filter = :inversion, \n                    smooth = false)\n\n(Image: Gali 2015 model estimates - smoothing options and inversion filter)","category":"section"},{"location":"plot_model_estimates/#Presample-periods","page":"Model Estimates","title":"Presample periods","text":"The presample_periods argument [Default: 0, Type: Int] specifies the number of periods at the beginning of the data that are not shown in the plots but are used for filtering. This is useful if the goal is to view only later periods in the sample, while still using the earlier periods for filtering.\n\nFor example, to exclude the first 20 periods from the plots, while still using them for filtering, run:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, presample_periods = 20)\n\n(Image: Gali 2015 model estimates - 20 presample periods)\n\nNote that now only 20 periods of the 40 periods in the data are shown in the plots, starting from period 21, while the first 20 periods were used in the filtering process.","category":"section"},{"location":"plot_model_estimates/#Forecast-periods","page":"Model Estimates","title":"Forecast periods","text":"The forecast_periods argument [Default: 12, Type: Int] specifies the number of unconditional forecast periods to display after the last data period. The forecast shows the model's expected dynamics without further exogenous shocks, starting from the final filtered state. The forecast is displayed as a dashed line to distinguish it from the model estimates, and a \"Forecast\" entry is added to the legend.\n\nTo plot model estimates with the default 12-period forecast:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data)\n\n(Image: Gali 2015 model estimates - default forecast)\n\nThe dashed line shows the unconditional forecast extending 12 periods beyond the last data point.\n\nTo specify a custom forecast horizon, for example 24 periods:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, forecast_periods = 24)\n\n(Image: Gali 2015 model estimates - 24 period forecast)\n\nTo disable the forecast and show only model estimates, set forecast_periods = 0:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, forecast_periods = 0)\n\n(Image: Gali 2015 model estimates - no forecast)\n\nThe forecast also works with plot_model_estimates! for comparing multiple scenarios. Each scenario can have its own forecast horizon:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, parameters = :β => 0.99)\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear, sim_data, parameters = :β => 0.95, forecast_periods = 18)\n\n(Image: Gali 2015 model estimates - forecast comparison)\n\nThe legend shows each scenario with its corresponding forecast as a dashed line in the same color.","category":"section"},{"location":"plot_model_estimates/#Shock-decomposition","page":"Model Estimates","title":"Shock decomposition","text":"The shock_decomposition argument [Type: Bool] specifies whether to include shock decompositions in the plots. By default, it is set to true for first order, pruned second order, and pruned third order solutions. For second order and third order solutions shock_decomposition = false, as the algorithm is not designed to handle it. If set to true, stacked bar charts showing the contribution of each shock to the variable's deviation from its steady state are included below the line plots for each variable.\n\nShock decompositions are included by default in the plots (except for second and third order solutions), and it can be specified explicitly as follows:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, shock_decomposition = true)\n\n(Image: Gali 2015 model estimates - shock decomposition true)\n\nThis will generate plots with stacked bar charts below the line plots, illustrating how each shock contributes to the variable's deviation from its steady state over time.\n\nTo exclude shock decomposition from the plots, set the argument to false:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear, sim_data, shock_decomposition = false)\n\n(Image: Gali 2015 model estimates - shock decomposition)\n\nThis shows only the line plots without the stacked bar charts for shock contributions. When combining multiple plots, the setting for shock_decomposition is ignored and false.","category":"section"},{"location":"plot_model_estimates/#Shocks","page":"Model Estimates","title":"Shocks","text":"The shocks argument determines the shocks shown in the plots as subplots and in the shock decomposition. By default, all shocks are included (:all).  Inputs can be either a Symbol or String (e.g. :eps_a, \"eps_a\", or :all), or Tuple, Matrix or Vector of String or Symbol. :none means no shocks are shown, and :all shows all shocks. If not all shocks are shown, then their respective subplot is ommitted and if a shock decomposition was intended to be shown, the ommitted shocks will be summarised and netted under the label Other shocks (net).\n\nTo recall the shocks of a model use the get_shocks function:\n\nget_shocks(Gali_2015_chapter_3_nonlinear)\n# 3-element Vector{String}:\n#  \"eps_a\"\n#  \"eps_nu\"\n#  \"eps_z\"\n\nTo plot only a subset of shocks, specify them as follows, using a Vector of Symbols:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = [:eps_a, :eps_nu])\n\n(Image: Gali 2015 model estimates - selected shocks)\n\nNote, how the ommitted shock: :eps_z is not shown but (the only) part of Other shocks (net).\n\nThe same can be done with a Vector of Strings:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = [\"eps_a\", \"eps_nu\"])\n\nor Tuples of Symbols:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = (:eps_a, :eps_nu))\n\nor Tuples of Strings:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = (\"eps_a\", \"eps_nu\"))\n\nor Matrix of Symbols:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = [:eps_a  :eps_z])\n\nor Matrix of Strings:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = [\"eps_a\"  \"eps_z\"])\n\nor simply as a Symbol\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = :eps_a)\n\nor simply as a String\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = \"eps_a\")\n\nNot showing any shocks by using shocks = :none:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     shocks = :none)\n\n(Image: Gali 2015 model estimates - no shocks)\n\nmeans that no subplots with the estimated shocks are shown and the shock decompositions only distinguish between the initial state and Other shocks (net).","category":"section"},{"location":"plot_model_estimates/#Solution-Algorithm","page":"Model Estimates","title":"Solution Algorithm","text":"The algorithm argument [Default: :first_order, Type: Symbol] specifies the solution algorithm used for the filtering. Options include :first_order, :second_order, :third_order, as well as :pruned_second_order and :pruned_third_order. The choice of algorithm affects the available filtering method (only first order support the Kalman filter, all solution algorithms support the inversion filter), steady state levels used in the plots and the dynamics of the variables.\n\nThe following example uses a second-order perturbation solution:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     algorithm = :second_order)\n\n(Image: Gali 2015 model estimates - second order)\n\nThe most notable difference is that at second order, dynamics are observed for S, which remains constant at first order (under certainty equivalence). Additionally, the steady state levels change because the stochastic steady state incorporates risk effects (see horizontal lines). This has consequences for the conditions as they are in levels.\n\nTo compare the two solution methods side by side, use plot_conditional_forecast! to add to an existing plot:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data)\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     algorithm = :second_order)\n\n(Image: Gali 2015 model estimates - first and second order)\n\nThe plots now show both solution methods overlaid. The first-order solution is shown in blue, the second-order solution in orange, as indicated in the legend below the plot. Note that the steady state levels can be different for the two solution methods. For variables where the relevant steady state is the same for both methods (e.g., S), the level appears on the left axis and percentage deviations on the right axis. For variables where the steady state differs between methods (e.g., R), only absolute level deviations (abs. Δ) appear on the left axis. The relevant steady state levels are shown in a table below the plot for reference (rounded to help identify differences). The relevant steady state also implies that the conditions vary in terms of distance to steady state and thereby in the shocks they require for them to be fulfilled. For the variable Y the conditions given a first order solution imply a lower absolute deviation from the relevant steady state than for the second order solution.\n\nAdditional solution methods can be added to the same plot:\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     algorithm = :pruned_third_order)\n\n(Image: Gali 2015 model estimates - multiple orders)\n\nNote that the pruned third-order solution incorporates time-varying risk and the dynamics differ relative to lower order solutions. The additional solution appears as another colored line with corresponding entries in both the legend and the steady state table below.","category":"section"},{"location":"plot_model_estimates/#Variables-to-Plot","page":"Model Estimates","title":"Variables to Plot","text":"The variables argument (default: :all_excluding_obc) specifies for which variables to show results. Variable names can be specified as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc includes all variables except auxiliary variables and those related to occasionally binding constraints (OBC). :all_excluding_obc includes all variables except those related to occasionally binding constraints. :all includes all variables.\n\nSpecific variables can be selected to plot. The following example selects only output (Y) and inflation (Pi) using a Vector of Symbols. Note that selecting shocks can be done using the shocks argument as shown above.\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = [:Y, :Pi])\n\n(Image: Gali 2015 model estimates - selected variables (Y, Pi))\n\nThe plot now displays the two selected variables (sorted alphabetically) as well as the corresponding shocks.\n\nThe same can be done using a Tuple:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = (:Y, :Pi))\n\na Matrix:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = [:Y :Pi])\n\nor providing the variable names as Strings:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = [\"Y\", \"Pi\"])\n\nor a single variable as a Symbol:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = :Y)\n\nor as a String:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = \"Y\")\n\nThen there are some predefined options:\n\n:all_excluding_auxiliary_and_obc (default) plots all variables except auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = :all_excluding_auxiliary_and_obc)\n\n:all_excluding_obc plots all variables except those used to enforce occasionally binding constraints (OBC).\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = :all_excluding_obc)\n\nTo see auxiliary variables, use a model that defines them. The FS2000 model can be used:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nSince both c and P appear in t+2, they generate auxiliary variables in the model. Plotting the model estimates for all variables excluding OBC-related ones means auxiliary variables are shown:\n\nsim_data_FS2000 = simulate(FS2000)([:y],:,:simulate)\nplot_model_estimates(FS2000,\n                     sim_data_FS2000,\n                     variables = :all_excluding_obc)\n\n(Image: FS2000 model estimates - e_a shock with auxiliary variables)\n\nBoth c and P appear twice: once as the variable itself and once as an auxiliary variable with the ᴸ⁽¹⁾ superscript, representing the value of the variable in t+1 as expected in t.\n\n:all plots all variables including auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nUse the Gali_2015_chapter_3 model with an effective lower bound (note the use of the max function in the Taylor rule):\n\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\n    R > 1.0001\nend\n\nPlotting the model estimates for all variables including OBC-related ones reveals the OBC-related auxiliary variables:\n\nsim_data_Gali_obc = simulate(Gali_2015_chapter_3_obc)([:R],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_obc,\n                     sim_data_Gali_obc,\n                     variables = :all)\n\n(Image: Gali 2015 OBC model estimates - with OBC variables)\n\nThe OBC-related variables appear in the last subplot, but note that simulated data respected the OBCs but the model estimates do not and explain the data using the standard model equations.","category":"section"},{"location":"plot_model_estimates/#Parameter-Values","page":"Model Estimates","title":"Parameter Values","text":"When no parameters are provided, the solution uses the previously defined parameter values. Parameters can be provided as a Vector of values, or as a Vector or Tuple of Pairs mapping parameter Symbols or Strings to values. The solution is recalculated when new parameter values differ from the previous ones.\n\nStart by changing the discount factor β from 0.99 to 0.95:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = :β => 0.95)\n\n(Image: Gali 2015 model estimates - `β = 0.95`)\n\nThe steady states and dynamics changed as a result of changing the discount factor, also because the absolute deviation of the conditons on the endogenous variables from the relevant steady state changed. To better visualize the differences between β = 0.99 and β = 0.95, the two conditional forecasts can be overlaid (compared). Since parameter changes are permanent, first reset β = 0.99 before overlaying the model estimates with β = 0.95 on top of it:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = :β => 0.99)\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = :β => 0.95)\n\n(Image: Gali 2015 model estimates - comparing β values)\n\nThe legend below the plot indicates which color corresponds to which β value, with the table underneath showing the relevant steady states. Note that both the steady states and dynamics differ across the two β values, even when the steady state remains the same (e.g., for Y).\n\nMultiple parameters can also be changed simultaneously to compare the results to previous plots. This example changes β to 0.97 and τ to 0.5 using a Tuple of Pairs and define the variables with Symbols:\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = (:β => 0.97, :τ => 0.5))\n\n(Image: Gali 2015 model estimates - multiple parameter changes)\n\nSince the plot function calls now differ in multiple input arguments, the legend indicates which color corresponds to which input combination, with the table showing steady states for all three combinations. The change in steady state for the latest change means substantially different absolute differences relevant for the conditions and therefore also different size of shocks to enforce the conditions.\n\nA Vector of Pairs can also be used:\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = [:β => 0.98, :τ => 0.25])\n\n(Image: Gali 2015 model estimates - multiple parameter changes (2))\n\nNote that the parameter change led to a different relevant steady state for variable Y. Since Y is also an observable, the subplot is shown in levels with the relevant steady states being indicated by black lines and their respective values mentioned in the table below the plot. This behaviour is in contrast to cases where the variables is not an observable, in which case absolute deviations from steady state are shown.\n\nAlternatively, use a Vector of parameter values in the order they were defined in the model. To obtain them:\n\nparams = get_parameters(Gali_2015_chapter_3_nonlinear, values = true)\n# 16-element Vector{Pair{String, Float64}}:\n#       \"σ\" => 1.0\n#       \"φ\" => 5.0\n#     \"ϕᵖⁱ\" => 1.5\n#      \"ϕʸ\" => 0.125\n#       \"θ\" => 0.75\n#     \"ρ_ν\" => 0.5\n#     \"ρ_z\" => 0.5\n#     \"ρ_a\" => 0.9\n#       \"β\" => 0.95\n#       \"η\" => 3.77\n#       \"α\" => 0.25\n#       \"ϵ\" => 9.0\n#       \"τ\" => 0.5\n#   \"std_a\" => 0.01\n#   \"std_z\" => 0.05\n#  \"std_nu\" => 0.0025\n\nparam_vals = [p[2] for p in params]\n# 16-element Vector{Float64}:\n#  1.0\n#  5.0\n#  1.5\n#  0.125\n#  0.75\n#  0.5\n#  0.5\n#  0.9\n#  0.95\n#  3.77\n#  0.25\n#  9.0\n#  0.5\n#  0.01\n#  0.05\n#  0.0025\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = param_vals)","category":"section"},{"location":"plot_model_estimates/#Plot-Labels","page":"Model Estimates","title":"Plot Labels","text":"The label argument (type: Union{String,Symbol,Real}) controls labels that appear in plots when using the plot_conditional_forecast! function to overlay multiple conditional forecasts. By default, labels take on the values of the one dimensional input that differs and are sequential numbers in case the input differs along more than one dimension. Furthermore, custom labels can be provided using this argument. Acceptable inputs are a String, Symbol, or a Real.\n\nCustom labels are particularly useful when inputs differ in complex ways (e.g., shock matrices or multiple input changes). For example, let's compare the model estimates of the Gali_2015_chapter_3_nonlinear model for a 1 standard deviation eps_a shock with β = 0.99 and τ = 0 to the model estimates with β = 0.95 and τ = 0.5 using custom labels String input:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = (:β => 0.99, :τ => 0.0),\n                     label = \"Std. params\")\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n                      sim_data,\n                      parameters = (:β => 0.95, :τ => 0.5),\n                      label = \"Alt. params\")\n\n(Image: Gali 2015 model estimates - custom labels)\n\nThe legend now displays the custom label names instead of sequential numbers (1 and 2). Additionally, the tables showing input differences and steady states use the custom labels in the first column instead of sequential numbers.\n\nThe same result can be achieved using Symbols (though they are less expressive):\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     parameters = (:β => 0.99, :τ => 0.0),\n                     label = :standard)\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    parameters = (:β => 0.95, :τ => 0.5),\n    label = :alternative)\n\nor with Real inputs:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    parameters = (:β => 0.99, :τ => 0.0),\n    label = 0.99)\n\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    parameters = (:β => 0.95, :τ => 0.5),\n    label = 0.95)","category":"section"},{"location":"plot_model_estimates/#Plot-Attributes","page":"Model Estimates","title":"Plot Attributes","text":"The plot_attributes argument (default: Dict(), type: Dict) accepts a dictionary of attributes passed on to the plotting function. See the Plots.jl documentation for details.\n\nThe color palette can be customized using the plot_attributes argument. The following example defines a custom color palette (inspired by the European Commission's economic reports) to plot the model estimates (colors are used for the shock decomposition) of the Gali_2015_chapter_3_nonlinear model. First, define the custom color palette using hex color codes:\n\nec_color_palette =\n[\n    \"#FFD724\",  # \"Sunflower Yellow\"\n    \"#353B73\",  # \"Navy Blue\"\n    \"#2F9AFB\",  # \"Sky Blue\"\n    \"#B8AAA2\",  # \"Taupe Grey\"\n    \"#E75118\",  # \"Vermilion\"\n    \"#6DC7A9\",  # \"Mint Green\"\n    \"#F09874\",  # \"Coral\"\n    \"#907800\"   # \"Olive\"\n]\n\nThen plot the model estimates:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     plot_attributes = Dict(:palette => ec_color_palette))\n\n(Image: Gali 2015 model estimates - custom color palette)\n\nThe colors of the bars now follow the custom color palette.\n\nOther attributes such as the font family can also be modified (see here for GR font options):\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     plot_attributes = Dict(:fontfamily => \"computer modern\"))\n\n(Image: Gali 2015 model estimates - custom font)\n\nAll text in the plot now uses the Computer Modern font. Note that font rendering inherits the constraints of the plotting backend (GR in this case).","category":"section"},{"location":"plot_model_estimates/#Plots-Per-Page","page":"Model Estimates","title":"Plots Per Page","text":"The plots_per_page argument (default: 9, type: Int) controls the number of subplots per page. When the number of variables exceeds this value, multiple pages are created. The following example selects 9 variables and sets plots_per_page to 2:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     variables = [:Y, :Pi, :R, :C, :N, :W_real, :MC, :i_ann, :A],\n                     plots_per_page = 2)\n\n(Image: Gali 2015 model estimates - 2 plots per page)\n\nThe first four pages display two variables (sorted alphabetically). The title indicates the current page and the total number of pages.","category":"section"},{"location":"plot_model_estimates/#Display-Plots","page":"Model Estimates","title":"Display Plots","text":"The show_plots argument (default: true, type: Bool), when true, displays the plots; otherwise, they are only returned as an object.\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                     sim_data,\n                     show_plots = false)","category":"section"},{"location":"plot_model_estimates/#Saving-Plots","page":"Model Estimates","title":"Saving Plots","text":"The save_plots argument (default: false, type: Bool), when true, saves the plots to disk; otherwise, they are only displayed and returned as an object.\n\nRelated arguments control the saving behavior:\n\nsave_plots_format (default: :pdf, type: Symbol): output format of saved plots. See input formats compatible with GR for valid formats.\nsave_plots_path (default: \".\", type: String): path where plots are saved. If the path does not exist, it will be created automatically.\nsave_plots_name (default: \"estimation\", type: Union{String, Symbol}): prefix prepended to the filename when saving plots.\n\nEach plot is saved as a separate file with a name indicating the prefix, model name, shocks, and a sequential number for multiple plots (e.g., estimation__ModelName__1.pdf).\n\nThe following example saves all conditional forecasts for the Gali_2015_chapter_3_nonlinear model as PNG files in the ../plots directory with estim as the filename prefix:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    save_plots = true,\n    save_plots_format = :png,\n    save_plots_path = \"./../plots\",\n    save_plots_name = :estim)\n\nThe plots appear in the specified folder with the specified prefix. Each plot is saved in a separate file with a name reflecting the model, and a sequential index when the number of variables exceeds the plots per page.","category":"section"},{"location":"plot_model_estimates/#Variable-and-Shock-Renaming-(rename-dictionary)","page":"Model Estimates","title":"Variable and Shock Renaming (rename dictionary)","text":"The rename_dictionary argument (default: Dict(), type: AbstractDict{<:Union{Symbol, String}, <:Union{Symbol, String}}) maps variable or shock symbols to custom display names in plots. This is particularly useful when comparing models with different variable naming conventions, allowing them to be displayed with consistent labels.\n\nFor example, to rename variables for clearer display:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    rename_dictionary = Dict(:Y => \"Output\", :Pi => \"Inflation\", :R => \"Interest Rate\"))\n\n(Image: Gali 2015 model estimates - rename dictionary)\n\nThis feature is especially valuable when overlaying conditional forecasts from different models. Consider comparing FS2000 (which uses lowercase variable names like c) with Gali_2015_chapter_3_nonlinear (which uses uppercase variable names like C). The rename_dictionary allows harmonizing these names when plotting them together:\n\nsim_data_FS2000 = simulate(FS2000)([:y],:,:simulate)\nplot_model_estimates(FS2000,\n                         sim_data_FS2000,\n                         rename_dictionary = Dict(\n                            :c => \"Consumption\", \n                            :y => \"Output\", \n                            :R => \"Interest Rate\"\n                         ))\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates!(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    rename_dictionary = Dict(\n        :C => \"Consumption\", \n        :Y => \"Output\", \n        :R => \"Interest Rate\"\n        ))\n\n(Image: FS2000 and Gali 2015 model estimates - multiple models with rename dictionary)\n\nBoth models now appear in the plot with consistent labels, facilitating comparison.\n\nThe rename_dictionary also works with shocks. For example, Gali_2015_chapter_3_nonlinear has shocks eps_a and eps_nu, while FS2000 has e_a and e_m. To compare these with consistent labels:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n                            sim_data,\n                            rename_dictionary = Dict(\n                                :eps_a => \"Technology Shock\", \n                                :eps_nu => \"Monetary Policy Shock\"\n                                ))\n\nplot_model_estimates!(FS2000,\n                         sim_data_FS2000,\n                         rename_dictionary = Dict(\n                            :e_a => \"Technology Shock\", \n                            :e_m => \"Monetary Policy Shock\"\n                            ))\n\n(Image: FS2000 and Gali 2015 model estimates - multiple models with shock rename dictionary)\n\nThe rename_dictionary accepts flexible type combinations for keys and values, both Symbol and String types work interchangeably:\n\n# All of these are valid and equivalent:\nDict(:Y => \"Output\")              # Symbol key, String value\nDict(\"Y\" => \"Output\")             # String key, String value\nDict(:Y => :Output)               # Symbol key, Symbol value\nDict(\"Y\" => :Output)              # String key, Symbol value\n\nThis flexibility is particularly useful for models like Backus_Kehoe_Kydland_1992, which uses String representations of variable and shock names (because of {}):\n\n# Define the Backus model (abbreviated for clarity)\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1-theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1/nu{co})\n        K{co}[0] = (1-delta{co})*K{co}[-1] + S{co}[0]\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n        A{co}[0] = (1-eta{co}) * A{co}[-1] + N{co}[0]\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1-alpha{co})*eta{co} * A{co}[-1]\n        U{co}[0] = (C{co}[0]^mu{co}*L{co}[0]^(1-mu{co}))^gamma{co}\n        psi{co} * mu{co} / C{co}[0]*U{co}[0] = LGM[0]\n        psi{co} * (1-mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1-theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co}*N{co}[0]^(1-theta{co}))^(-nu{co})*Y{co}[0]^(1+nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1-delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1-theta{co})) ^ (-nu{co})* Y{co}[+4]^(1+nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1+sigma{co} * Z{co}[0]^(-nu{co}-1)*Y{co}[+1]^(1+nu{co}))\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1]))/Y{co}[0]\n    end\n\n    (LAMBDA{H}[0]-1) = rho{H}{H}*(LAMBDA{H}[-1]-1) + rho{H}{F}*(LAMBDA{F}[-1]-1) + Z_E{H} * E{H}[x]\n    (LAMBDA{F}[0]-1) = rho{F}{F}*(LAMBDA{F}[-1]-1) + rho{F}{H}*(LAMBDA{H}[-1]-1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend\n\nsim_data = simulate(Backus_Kehoe_Kydland_1992)([\"Y{H}\"],:,:simulate)\nplot_model_estimates(Backus_Kehoe_Kydland_1992,\n    sim_data,\n    rename_dictionary = Dict(\"C{H}\" => \"Home Consumption\", \n                             \"C{F}\" => \"Foreign Consumption\",\n                             \"Y{H}\" => \"Home Output\",\n                             \"Y{F}\" => \"Foreign Output\"))\n\n(Image: Backus, Kehoe, Kydland 1992 model estimates - E{H} shock with rename dictionary)\n\nVariables or shocks not included in the dictionary retain their default names. The renaming applies to all plot elements including legends, axis labels, and tables.","category":"section"},{"location":"plot_model_estimates/#Verbose-Output","page":"Model Estimates","title":"Verbose Output","text":"The verbose argument (default: false, type: Bool), when true, enables verbose output related to solving the model\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    verbose = true)\n\nThe code outputs information about solving the steady state blocks. When parameters change, the first-order solution is recomputed; otherwise, it uses the cached solution:\n\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    parameters = :β => 0.955,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.95       to 0.955\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.3825585462666584e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16","category":"section"},{"location":"plot_model_estimates/#Numerical-Tolerances","page":"Model Estimates","title":"Numerical Tolerances","text":"The tol argument (default: Tolerances(), type: Tolerances) defines various tolerances for the algorithm used to solve the model. See the Tolerances documentation for more details: ?Tolerances. The tolerances used by the numerical solvers can be adjusted. The Tolerances object allows setting tolerances for the non-stochastic steady state solver (NSSS), Sylvester equations, Lyapunov equation, and quadratic matrix equation (QME). For example, to set tighter tolerances (this example also changes parameters to force recomputation):\n\ncustom_tol = Tolerances(qme_acceptance_tol = 1e-12,\n    sylvester_acceptance_tol = 1e-12)\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    tol = custom_tol,\n    algorithm = :second_order,\n    parameters = :β => 0.9555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.955      to 0.9555\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Sylvester equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 6.494758134185766e-17; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n\nThis is useful when higher precision is needed or when the default tolerances are insufficient for convergence. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_model_estimates/#Quadratic-Matrix-Equation-Solver","page":"Model Estimates","title":"Quadratic Matrix Equation Solver","text":"The quadratic_matrix_equation_algorithm argument (default: :schur, type: Symbol) specifies the algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling The quadratic matrix equation solver is used internally when solving the model to first order. Different algorithms are available. The :schur algorithm is generally faster and more reliable, while :doubling can be more precise in some cases (this example also changes parameters to force recomputation):\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    quadratic_matrix_equation_algorithm = :doubling,\n    parameters = :β => 0.95555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.9555     to 0.95555\n# New parameters changed the steady state.\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver: doubling - converged: true in 8 iterations to tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor most use cases, the default :schur algorithm is recommended. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_model_estimates/#Sylvester-Equation-Solver","page":"Model Estimates","title":"Sylvester Equation Solver","text":"[Default: selector that uses :doubling for smaller problems and switches to :bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: Algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. The input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solution's Sylvester equation. When only one element is provided, it corresponds to the second-order perturbation solution's Sylvester equation. The algorithm to use can be specified for solving Sylvester equations in higher-order solutions. For example, select the :bartels_stewart algorithm for solving the second-order perturbation problem:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    algorithm = :second_order,\n    sylvester_algorithm = :bartels_stewart,\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: -1; reached tol: 6.19336731775721e-17; algorithm: bartels_stewart\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor third-order solutions, different algorithms can be specified for the second- and third-order Sylvester equations using a Tuple:\n\nsim_data = simulate(Gali_2015_chapter_3_nonlinear)([:Y],:,:simulate)\nplot_model_estimates(Gali_2015_chapter_3_nonlinear,\n    sim_data,\n    algorithm = :third_order,\n    sylvester_algorithm = (:doubling, :bicgstab),\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: 23; reached tol: 8.328904812714592e-17; algorithm: bicgstab\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nThe choice of algorithm affects both speed and precision: :doubling and :bartels_stewart are generally faster, while :bicgstab, :dqgmres, and :gmres are better for large sparse problems. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"unfinished_docs/todo/#Todo-list","page":"Todo list","title":"Todo list","text":"","category":"section"},{"location":"unfinished_docs/todo/#High-priority","page":"Todo list","title":"High priority","text":"[ ] allow not to define all parameters in @parameters and enter them later in subsequent calls. so you can do things like loading them from a file and putting them in. internally he would need to delay the solution until all parameters are defined\n[ ] add FRB US model\n[ ] check allocations of jacobian in sparse case (NAWM)\n[ ] write another seciton in the docs explaining the parameters macro and what you can do (calibration equations, parameters as functions of other parameters, delayed definition of parameters)\n[ ] more informative errors when something goes wrong when writing a model\n[ ] error when parsing expression of the form: XYZ[0] = 0\n[ ] programmatic model writing: accept {i}[0] as definition for variable\n[ ] have parser accept rss | (r[ss] - 1) * 400 = rss\n[ ] allow to define y[ss] = 1 in parameters block\n[ ] add caches to lyapunov krylov solvers\n[ ] eliminiate last elements of factorisation calls not using linearsolvers.jl, check whether they can be done with linearsolvers in case of a matrix as RHS (otherwise consider mumps for sparse matrix RHS)\n[ ] separate docs from main package as all the plots get too big\n[ ] write tests/docs/technical details for nonlinear obc, forecasting, (non-linear) solution algorithms, SS solver, obc solver, and other algorithms\n[ ] collect helper function only used in statsplots extension in that script\n[ ] collect the argument wrangling functions in functions instead of them being in function bodies\n[ ] apply sort by normalised superscript across functions\n[ ] make package mooncake compatible. write custom pullback functions where necessary (all in one for llh)\n[ ] print out the OBC shocks as auxilliary shocks\n[ ] generalised higher order IRF is around mean not SSS. plot mean line?\n[ ] set irrelevant arguments back to default and inform user\n[ ] generalised IRF prunedthirdorder is somewhat slow - investigate\n[ ] consider making sympy an extension or try to partially replace with Symbolics\n[ ] make sympy optional (maybe even an extension) and use Symbolics where possible\n[ ] switch from sympy to Symbolics\n[ ] replace RF with LinearSolve codes (RF has too many dependencies)\n[ ] check again return value when NSSS not found, maybe NaN is better here\n[ ] use isfresh flag on dense linear solves\n[ ] implement check for plots, that they always return a plot (shocks = :none didn't return a plot)\n[ ] cache sparse kron, sylvester solution, and compressed kron in order to avoid allocs; check sparse kron! call\n[ ] prettify plotlyjs plots\n[ ] fix findiff and zygote consistency for llh derivatives of inversion filter\n[ ] add correlation and other moments to get statistics\n[ ] get irf with parameters for higher order and make it zygote compatible\n[ ] implement rrule for higher order moments\n[ ] add derivatives wrt covariance in get_moments\n[ ] recheck function examples and docs (include output description)\n[ ] Docs: document outputs and associated functions to work with function\n[ ] write documentation/docstrings using copilot\n[ ] implement getconditionalvariance_decomposition for higher order\n[ ] improve model writing related errors. dont throw errors right away but collect them\n[ ] moments related functions: fix return types and implement early returns on errors for \n[ ] ss transition by entering new parameters at given periods\n[ ] implement forwarddiff for find_shocks\n[ ] redo inversion filter 1st order rrule based on the higher order ones. the accumulated matmul might not be necessary at all\n[ ] inversion filter: use subset of observables and states when propagating states (see kalman filter)\n[ ] start filter from initial values provided by user\n[ ] higher order estimation should start from mean not the stochastic steady state as the mean is the most likely starting point\n[ ] large models will need functions to be compiled individually as done for higher order; when tackling that, also separate steady state related equations from the steady state, so that speed issue is addresses due to replacing parameters with the steady state equations from the parameter block; also creat non allocating (residuals) steady state function\n[ ] check tols throughout. adopt max(abs,rel*norm) tols\n[ ] redo diffs (DiffInt or ForwardDiff or FastDiff)\n[ ] optimize second order estim with SW07 or NAWM\n[ ] optimize third order with smaller model\n[ ] fix higher order shock finder (3rd order) and check results for pruned second order. are the right state values taken for 1st and second order subprocesses?\n[ ] take analytical derivatives of NSSS funcs to reduce allocation and speed up the NSSS solver\n[ ] in the docs make it clear that for estimation you need to have variables which have the name of the observables in the dataframe and the parameters must be handed over to the getloglikelihood function in the same order as declared. check with getparameters\n[ ] check out dense sparse matmul on transposed matrices\n[ ] check out DiffInterface for NSSS solver\n[ ] write plotting callback for NSSS solver\n[ ] time NSSS solver and estimation codes\n[ ] move kornss_s to higher order aux variables\n[ ] write own interior point solver\n[ ] write more tests for the plots\n[ ] add background part in docs on NSSS solver (use material from presentation)\n[ ] juliacon followup: checkout alloccheck, infiltrator, bestie, DifferentiableInterface, DepotDelivery, Interfaces, ThreadedDenseparseMul, Optimization Ensemble, redo Kalman filter with PDMats\n[ ] use IrrationalConstants for log2pi...\n[ ] checkout this invalidation precompile trick and g dalle part on precompilation\n[ ] use sobol random numbers (gives you uniform but then use norminvcdf to get norm) to integrate out future randomness when solving with neural nets\n[ ] do proper testing of ss solver with random set of params, equal across configs\n[ ] load create parts of derivatives later and not directly after parameters block\n[ ] fix model estimate plot. data not above estimate (should be red but is blue)\n[ ] implement higher order (pruned) variance decomposition\n[ ] try slicesampler instead of pigeons\n[ ] use faster derivatives for SS solver (currently forward diff)\n[ ] speed up sensitivity by caching matrix inversion from implicit diff with LRUcache\n[ ] fix this inference errors for large functions. they are slow. fix derivatives in general.\n[ ] check downgrade tests\n[ ] put writederivativesfunction and lock structure inside function\n[ ] take apart solvematrixequation for various cases\n[ ] try static arrays in KF\n[ ] check derivatives of erfcinv with Symbolics. seems off\n[ ] have a workspace in the model object. to be accessed for example by the riccati solver at each run (instead of initialising values at each function call)\n[ ] check why PG samples are off\n[ ] optimise vanilla loglikelihood calculation and gradient thereof (incl comp time)\n[ ] checkout dynamic perturbation for obc solution: https://www.southampton.ac.uk/~alexmen/dynamic_perturbation.pdf\n[ ] checkout schedule free ADAM for global methods: https://github.com/facebookresearch/schedule_free\n[ ] figure out why PG and IS return basically the prior | related to context but also that they need to be somewhat close to the posterior, if they aren't the sampler has a hard time finding it\n[ ] allow external functions to calculate the steady state (and hand it over via SS or get_loglikelihood function) - need to use the check function for implicit derivatives and cannot use it to get him a guess from which he can use internal solver going forward\n[ ] go through custom SS solver once more and try to find parameters and logic that achieves best results\n[ ] SS solver with less equations than variables\n[ ] improve docs: timing in first sentence seems off; have something more general in first sentence; why is the syntax user friendly? give an example; make the former and the latter a footnote\n[ ] change docs to reflect that the output of irfs include aux vars and also the model info Base.show includes aux vars\n[ ] feedback: sell the sampler better (ESS vs dynare), more details on algorithm (SS solver)\n[ ] NaNMath pow does not work (is not substituted)\n[ ] check whether its possible to run parameters macro/block without rerunning model block\n[ ] eliminate possible log, ^ terms in parameters block equations - because of nonnegativity errors\n[ ] throw error when equations appear more than once\n[ ] make SS calc faster (func and optim, maybe inplace ops)\n[ ] check obc once more\n[ ] rm obc vars from get_SS\n[ ] check why warmup_iterations = 0 makes estimated shocks larger\n[ ] use analytical derivatives also for shocks matching optim (and HMC - implicit diff)\n[ ] info on when what filter is used and chosen options are overridden\n[ ] check warnings, errors throughout. check suppress not interfering with pigeons\n[ ] functions to reverse state_update (input: previous shock and current state, output previous state), find shocks corresponding to bringing one state to the next\n[ ] cover nested case: min(50,a+b+max(c,10))\n[ ] add balanced growth path handling\n[ ] autocorr and covariance with derivatives. return 3d array\n[ ] add pydsge and econpizza to overview\n[ ] add for loop parser in @parameters\n[ ] implement more multi country models\n[ ] speed benchmarking (focus on ImplicitDiff part)\n[ ] for cond forecasting allow less shocks than conditions with a warning. should be svd then\n[ ] when doing calibration with optimiser have better return values when he doesn't find a solution (probably NaN)\n[ ] sampler returned negative std. investigate and come up with solution ensuring sampler can continue\n[ ] have get_std take variables as an input\n[ ] initial state accept keyed array, SS and SSS as arguments\n[ ] kick out unused parameters from m.parameters\n[ ] use cache for gradient calc in estimation (see DifferentiableStateSpaceModels)\n[ ] write functions to debug (fix_SS.jl...)\n[ ] model compression (speed up 2nd moment calc (derivatives) for large models; gradient loglikelihood is very slow due to large matmuls) -> model setup as maximisation problem (gEcon) -> HANK models\n[ ] implement global solution methods - Julien Pascal, QuantEcon\n[ ] add more models\n[ ] use @assert for errors and @test_throws\n[ ] print SS dependencies (get parameters (in function of parameters) into the dependencies), show SS solver\n[ ] use strings instead of symbols internally\n[ ] write how-to for calibration equations\n[ ] make the nonnegativity trick optional or use nanmath?\n[ ] clean up different parameter types\n[ ] clean up printouts/reporting\n[ ] clean up function inputs and harmonise AD and standard commands\n[ ] figure out combinations for inputs (parameters and variables in different formats for get_irf for example)\n[ ] weed out SS solver and saved objects\n[x] separate estimation test using Pigeons from normal tests so that newest version of Turing can be tested and maintained\n[x] fix borrowing_constraint how-to\n[x] append forecast (no shocks) after estimated variables\n[x] FastDifferentiation is faster in taking derivatives and more efficient in writing functions but does not support custom functions (e.g. normlogpdf) | Symbolics is better by now\n[x] plot multiple solutions of models - multioptions in one graph\n[x] include weakdeps: https://pkgdocs.julialang.org/dev/creating-packages/#Weak-dependencies\n[x] plotmodelestimates with unconditional forecast at the end\n[x] add to the doc/strings that KeyedArrays are part of the AxisKeys package so people can look up how to access elements there. otherwise they might confuse it for a format provided by the package and wouldnt know how to access elements from it\n[x] add argument to plotting functions to replace names in plots (e.g. input a dictionary: Dict(:dinve => \"Investment growth\"))\n[x] implement benchmarks\n[x] write non allocating version of steady state functions\n[x] do SVD on matrices before solving first order. idea to solve in lower dimensional subspace. doesn't work as that is the whole point of the solution. what breaks is the X^2 as any transformation of X would have a term in the middle remaining\n[x] automatically adjust plots for different legend widths and heights\n[x] use ID for sparse output sylvester solvers (filed issue)\n[x] add user facing option to choose sylvester solver\n[x] speed up sparse matrix calcs in implicit diff of higher order funcs\n[x] compressed higher order derivatives and sparsity of jacobian\n[x] dont use SSsolvefunc but the wrapper instead (write forwarddiff wrapper)\n[x] make inversion filter / higher order sols suitable for HMC (forward and reverse diff!!, currently only analytical pushforward, no implicitdiff) | analytic derivatives\n[x] higher order solutions: some kron matrix mults are later compressed. write custom compressed kron mult; check if sometimes dense mult is faster? (e.g. GNSS2010 seems dense at higher order). wrote custom kron matmuls\n[x] add nonlinear shock decomposition\n[x] try preallocation tools for forwarddiff (DiffInterface). works\n[x] analytical derivatives of inversion filter (higher order)\n[x] try a newton version of binder pesaran. it's very slow\n[x] newton SS solver once sol was found\n[x] fix presample period for higher order estim\n[x] insight: spgemm in SparseArrays is the fastest way. threading doesn't work well due to memory/cache issues, csr format doesn't give many gains. other libraries dont improve over standard implementation (Finch...)\n[x] use kalman filter to initialize inversion filter for third order or some other simplification; didn't do it bcs it seems the inversion filter is well behaved for reasonable shock sizes\n[x] implement estimation tests for all models\n[x] make plotting options as dynamic setting instead of default, accept kwargs\n[x] streamline estimation part (dont do string matching... but rely on precomputed indices...)\n[x] estimation: run auto-tune before and use solver treating parameters as given\n[x] use arraydist in tests and docs\n[x] include guess in docs\n[x] Find any SS by optimising over both SS guesses and parameter inputs\n[x] riccati with analytical derivatives (much faster if sparse) instead of implicit diff; done for ChainRules; ForwardDiff only feasible for smaller problems -> ID is fine there\n[x] log in parameters block is recognized as variable\n[x] add termination condition if relative change in ss solver is smaller than tol (relevant when values get very large)\n[x] provide option for external SS guess; provided in parameters macro\n[x] make it possible to run multiple ss solver parameter combination including starting points when solving a model\n[x] automatically put the combi first which solves it fastest the first time\n[x] write auto-tune in case he can't find SS (add it to the warning when he can't find the SS)\n[x] nonlinear conditional forecasts for higher order and obc\n[x] for cond forecasting and kalman, get rid of observables input and use axis key of data input\n[x] fix translate dynare mod file from file written using write to dynare file (see test models): added retranslation to test\n[x] use packages for kalman filter: nope sticking to own implementation\n[x] check that there is an error if he can't find SS\n[x] bring solution error into an object of the model so we dont have to pass it on as output: errors get returned by functions and are thrown where appropriate\n[x] include option to provide pruned states for irfs\n[x] use other quadratic iteration for diffable first order solve (useful because schur can error in estimation): used try catch, schur is still fastest\n[x] fix SS solver (failed for backus in guide): works now\n[x] nonlinear estimation using unscented kalman filter / inversion filter (minimization problem: find shocks to match states with data): used inversion filter with gradient optim\n[x] check if higher order effects might distort results for autocorr (problem with order definition) - doesn't seem to be the case; full_covar yields same result\n[x] implement occasionally binding constraints with shocks\n[x] add QUEST3 tests\n[x] add obc tests\n[x] highlight NUTS sampler compatibility\n[x] differentiate more vs diffstatespace\n[x] reorder other toolboxes according to popularity\n[x] add JOSS article (see Makie.jl)\n[x] write to mod file for unicode characters. have them take what you would type: \\alpha\\bar\n[x] write dynare model using function converting unicode to tab completion\n[x] write parameter equations to dynare (take ordering on board)\n[x] pruning of 3rd order takes pruned 2nd order input\n[x] implement moment matching for pruned models\n[x] test pruning and add literature\n[x] use more implicit diff for the other functions as well\n[x] handle sparsity in sylvester solver better (hand over indices and nzvals instead of vec)\n[x] redo naming in moments calc and make whole process faster (precalc wrangling matrices)\n[x] write method of moments how to\n[x] check tols - all set to eps() except for dependencies tol (1e-12)\n[x] set to 0 SS values < 1e-12 - doesn't work with Zygote\n[x] sylvester with analytical derivatives (much faster if sparse) instead of implicit diff - yes but there are still way too large matrices being realised. implicitdiff is better here\n[x] autocorr to statistics output and in general for higher order pruned sols\n[x] fix product moments and test for cases with more than 2 shocks\n[x] write tests for variables argument in get_moment and for higher order moments\n[x] handle KeyedArrays with strings as dimension names as input\n[x] add mean in output funcs for higher order \n[x] recheck results for third order cov\n[x] have a look again at get_statistics function\n[x] consolidate sylvester solvers (diff)\n[x] put outside of loop the ignore derivatives for derivatives\n[x] write function to smart select variables to calc cov for\n[x] write get function for variables, parameters, equations with proper parsing so people can understand what happens when invoking for loops\n[x] have for loop where the items are multiplied or divided or whatever, defined by operator | + or * only\n[x] write documentation for string inputs\n[x] write documentation for programmatic model writing\n[x] input indices not as symbol\n[x] make sure plots and printed output also uses strings instead of symbols if adequate\n[x] have keyedarray with strings as axis type if necessary as output\n[x] write test for keyedarray with strings as primary axis\n[x] test string input\n[x] have all functions accept strings and write tests for it\n[x] parser model into per equation functions instead of single big functions\n[x] use krylov instead of linearsolve\n[x] implement for loops in model macro (e.g. to setup multi country models)\n[x] fix ss of pruned solution in plotsolution. seems detached\n[x] try solve first order with JuMP - doesn't work because JuMP cannot handle matrix constraints/objectives \n[x] get solution higher order with multidimensional array (states, 1 and 2 partial derivatives variables names as dimensions in 2order case)\n[x] add pruning\n[x] add other outputs from estimation (smoothed, filter states and shocks)\n[x] shorten plot_irf (take inspiration from model estimate)\n[x] fix solution plot\n[x] see if we can avoid try catch and test for invertability instead\n[x] have Flux solve SS field #gradient descent based is worse than LM based\n[x] have parameters keyword accept Int and 2/3\n[x] plot_solution colors change from 2nd to 2nd order\n[x] custom LM: optimize for other RBC models, use third order backtracking\n[x] add SSS for third order (can be different than the one from 2nd order, see Gali (2015)) in solution plot; also put legend to the bottom as with Condition\n[x] check out Aqua.jl as additional tests\n[x] write tests and documentation for solution, estimation... making sure results are consistent\n[x] catch cases where you define calibration equation without declaring conditional variable\n[x] flag if equations contain no info for SS, suggest to set ss values as parameters\n[x] handle SS case where there are equations which have no information for the SS. use SS definitions in parameter block to complete system | no, set steady state values to parameters instead. might fail if redundant equation has y[0] - y[-1] instead of y[0] - y[ss]\n[x] try eval instead of runtimegeneratedfunctions; eval is slower but can be typed\n[x] check correctness of solution for models added\n[x] SpecialFunctions eta and gamma cause conflicts; consider importing used functions explicitly\n[x] bring the parsing of equations after the parameters macro\n[x] rewrite redundant var part so that it works with ssauxequations instead of ss_equations\n[x] catch cases where ss vars are set to zero. x[0] * eps_z[x] in SS becomes x[0] * 0 but should be just 0 (use sympy for this)\n[x] remove duplicate nonnegative aux vars to speed up SS solver\n[x] error when defining variable more than once in parameters macro\n[x] consolidate aux vars, use sympy to simplify\n[x] error when writing equations with only one variable\n[x] error when defining variable as parameter\n[x] more options for IRFs, simulate only certain shocks - set stds to 0 instead\n[x] add NBTOOLBOX, IRIS to overview\n[x] input field for SS init guess in all functions #not necessary so far. SS solver works out everything just fine\n[x] symbolic derivatives\n[x] check SW03 SS solver\n[x] more options for IRFs, pass on shock vector\n[x] write to dynare\n[x] add plot for policy function\n[x] add plot for FEVD\n[x] add functions like getvariance, getsd, getvar, getcovar\n[x] add correlation, autocorrelation, and (conditional) variance decomposition\n[x] go through docs to reflect verbose behaviour\n[x] speed up covariance mat calc\n[x] have conditional parameters at end of entry as well (... | alpha instead of alpha | ...)\n[x] Get functions: getoutput, getmoments\n[x] get rid of init_guess\n[x] an and schorfheide estimation\n[x] estimation, IRF matching, system priors\n[x] check derivative tests with finite diff\n[x] release first version\n[x] SS solve: add domain transformation optim\n[x] revisit optimizers for SS\n[x] figure out licenses\n[x] SS: replace variables in log() with auxiliary variable which must be positive to help solver\n[x] complex example with lags > 1, [ss], calib equations, aux nonneg vars\n[x] add NLboxsolve\n[x] try NonlinearSolve - fails due to missing bounds\n[x] make noneg aux part of optim problem for NLboxsolve in order to avoid DomainErrors - not necessary\n[x] have bounds on alpha (failed previously due to naming conflict) - works now","category":"section"},{"location":"unfinished_docs/todo/#Not-high-priority","page":"Todo list","title":"Not high priority","text":"[ ] estimation codes with missing values (adopt kalman filter)\n[ ] decide on whether levels = false means deviations from NSSS or relevant SS\n[ ] what's a good error measure for higher order solutions (taking whole dist of future shock into account)? use mean error for n number of future shocks\n[ ] improve redundant calculations of SS and other parts of solution\n[ ] restructure functions and containers so that compiler knows what types to expect\n[ ] use RecursiveFactorization and TriangularSolve to solve, instead of MKL or OpenBLAS\n[ ] fix SnoopCompile with generated functions\n[ ] exploit variable incidence and compression for higher order derivatives\n[ ] for estimation use CUDA with st order: linear time iteration starting from last 1st order solution and then LinearSolveCUDA solvers for higher orders. this should bring benefits for large models and HANK models\n[ ] pull request in StatsFuns to have norminv... accept type numbers and add translation from matlab: norminv to StatsFuns norminvcdf\n[ ] more informative errors when declaring equations/ calibration\n[ ] unit equation errors\n[ ] implenent reduced linearised system solver + nonlinear\n[ ] implement HANK\n[ ] implement automatic problem derivation (gEcon)\n[ ] print legend for algorithm in last subplot of plot only\n[ ] select variables for moments\n[x] rewrite first order with riccati equation MatrixEquations.jl: not necessary/feasible see dynare package\n[x] test on highly nonlinear model # caldara et al is actually epstein zin with stochastic vol\n[x] conditional forecasting\n[x] find way to recover from failed SS solution which is written to init guess\n[x] redo ugly solution for selecting parameters to differentiate for\n[x] conditions for when to use which solution. if solution is outdated redo all solutions which have been done so far and use smart starting points\n[x] Revise 2,3 pert codes to make it more intuitive\n[x] implement blockdiag with julia package instead of python\n[x] Pretty print linear solution\n[x] write function to get_irfs\n[x] Named arrays for irf\n[x] write state space function for solution\n[x] Status print for model container\n[x] implenent 2nd + 3rd order perturbation\n[x] implement functions for distributions\n[x] try speedmapping.jl - no improvement\n[x] moment matching\n[x] write tests for higher order pert and standalone function\n[x] add compression back in\n[x] FixedPointAcceleration didn't improve on iterative procedure\n[x] add exogenous variables in lead or lag\n[x] regex in parser of SS and exo\n[x] test SS solver on SW07\n[x] change calibration, distinguish SS/dyn parameters\n[x] plot multiple solutions at same time (save them in separate constructs)\n[x] implement bounds in SS finder\n[x] map pars + vars impacting SS\n[x] check bounds when putting in new calibration\n[x] Save plot option\n[x] Add shock to plot title\n[x] print model name","category":"section"},{"location":"unfinished_docs/todo/#Code-notes","page":"Todo list","title":"Code notes","text":"The following tasks were extracted from comments in the code base. Each item references the relevant file and context.\n\n[ ] src/MacroModelling.jl (calculate_third_order_stochastic_steady_state): verify sparse matrix support\n[ ] src/filter/inversion.jl (calculate_inversion_filter_loglikelihood): use subsets of observables and states when propagating states\n[ ] src/filter/inversion.jl (rrule for first order): rewrite based on higher order implementation to remove unnecessary matmul\n[ ] src/filter/inversion.jl (rrule for first order): add warmup iterations\n[ ] src/filter/inversion.jl (rrule for first order): reduce allocations in pullback\n[ ] src/filter/inversion.jl (rrule for higher order): clean up length and size handling and avoid temporary vector allocations\n[ ] src/filter/find_shocks.jl: add ForwardDiff support for find_shocks\n[ ] src/get_functions.jl: verify derivatives against finite differences\n[ ] src/get_functions.jl (get_conditional_variance_decomposition): extend to higher order solutions\n[ ] src/get_functions.jl (get_variance_decomposition): extend to higher order solutions\n[ ] src/get_functions.jl (get_loglikelihood): error when bounds are violated to catch wrong parameter ordering","category":"section"},{"location":"plot_conditional_variance_decomposition/#Conditional-Variance-Decomposition","page":"Variance Decomposition","title":"Conditional Variance Decomposition","text":"The plot_conditional_variance_decomposition function visualizes the forecast error variance decomposition (FEVD), showing how much of the variance in forecast errors for each variable can be attributed to different shocks over various forecast horizons.\n\nFirst, define and load a model:\n\n@model Smets_Wouters_2007_linear begin\n    a[0] = calfa * rkf[0] + (1 - calfa) * wf[0]\n    zcapf[0] = rkf[0] * 1 / (czcap / (1 - czcap))\n    rkf[0] = wf[0] + labf[0] - kf[0]\n    kf[0] = zcapf[0] + kpf[-1]\n    invef[0] = qs[0] + 1 / (1 + cgamma * cbetabar) * (pkf[0] * 1 / (csadjcost * cgamma ^ 2) + invef[-1] + invef[1] * cgamma * cbetabar)\n    pkf[0] = b[0] * (1 / ((1 - chabb / cgamma) / (csigma * (1 + chabb / cgamma)))) - rrf[0] + rkf[1] * (crk / (crk + (1 - ctou))) + pkf[1] * ((1 - ctou) / (crk + (1 - ctou)))\n    cf[0] = b[0] + cf[-1] * chabb / cgamma / (1 + chabb / cgamma) + cf[1] * 1 / (1 + chabb / cgamma) + (labf[0] - labf[1]) * ((csigma - 1) * cwhlc / (csigma  *(1 + chabb / cgamma))) - rrf[0] * (1 - chabb / cgamma) / (csigma * (1 + chabb / cgamma))\n    yf[0] = g[0] + cf[0] * ccy + invef[0] * ciy + zcapf[0] * crkky\n    yf[0] = cfc * (a[0] + calfa * kf[0] + (1 - calfa) * labf[0])\n    wf[0] = labf[0] * csigl + cf[0] * 1 / (1 - chabb / cgamma) - cf[-1] * chabb / cgamma / (1 - chabb / cgamma)\n    kpf[0] = kpf[-1] * (1 - cikbar) + invef[0] * cikbar + qs[0] * csadjcost * cgamma ^ 2 * cikbar\n    mc[0] = calfa * rk[0] + (1 - calfa) * w[0] - a[0]\n    zcap[0] = 1 / (czcap / (1 - czcap)) * rk[0]\n    rk[0] = w[0] + lab[0] - k[0]\n    k[0] = zcap[0] + kp[-1]\n    inve[0] = qs[0] + 1 / (1 + cgamma * cbetabar) * (pk[0] * 1 / (csadjcost * cgamma ^ 2) + inve[-1] + inve[1] * cgamma * cbetabar)\n    pk[0] = pinf[1] - r[0] + b[0] * 1 / ((1 - chabb / cgamma) / (csigma * (1 + chabb / cgamma))) + rk[1] * (crk / (crk + (1 - ctou))) + pk[1] * ((1 - ctou) / (crk + (1 - ctou)))\n    c[0] = b[0] + c[-1] * chabb / cgamma / (1 + chabb / cgamma) + c[1] * 1 / (1 + chabb / cgamma) + \n    (lab[0] - lab[1]) * ((csigma - 1) * cwhlc / (csigma * (1 + chabb / cgamma))) - (r[0] - pinf[1]) * (1 - chabb / cgamma) / (csigma * (1 + chabb / cgamma))\n    y[0] = g[0] + c[0] * ccy + inve[0] * ciy + zcap[0] * crkky\n    y[0] = cfc * (a[0] + calfa * k[0] + (1 - calfa) * lab[0])\n    pinf[0] = spinf[0] + 1 / (1 + cindp * cgamma * cbetabar) * (cindp * pinf[-1] + pinf[1] * cgamma * cbetabar + mc[0] * (1 - cprobp) * (1 - cprobp * cgamma * cbetabar) / cprobp / (1 + (cfc - 1) * curvp))\n    w[0] = sw[0] + w[-1] * 1 / (1 + cgamma * cbetabar) + w[1] * cgamma * cbetabar / (1 + cgamma * cbetabar) + pinf[-1] * cindw / (1 + cgamma * cbetabar) - pinf[0] * (1 + cindw * cgamma * cbetabar) / (1 + cgamma * cbetabar) + pinf[1] * cgamma * cbetabar / (1 + cgamma * cbetabar) + (csigl * lab[0] + c[0] * 1 / (1 - chabb / cgamma) - c[-1] * chabb / cgamma / (1 - chabb / cgamma) - w[0]) * 1 / (1 + (clandaw - 1) * curvw) * (1 - cprobw) * (1 - cprobw * cgamma * cbetabar) / (cprobw * (1 + cgamma * cbetabar))\n    r[0] = pinf[0] * crpi * (1 - crr) + (1 - crr) * cry * (y[0] - yf[0]) + crdy * (y[0] - yf[0] - y[-1] + yf[-1]) + crr * r[-1] + ms[0]\n    a[0] = crhoa * a[-1] + z_ea * ea[x]\n    b[0] = crhob * b[-1] + z_eb * eb[x]\n    g[0] = crhog * g[-1] + z_eg * eg[x] + z_ea * ea[x] * cgy\n    qs[0] = crhoqs * qs[-1] + z_eqs * eqs[x]\n    ms[0] = crhoms * ms[-1] + z_em * em[x]\n    spinf[0] = crhopinf * spinf[-1] + epinfma[0] - cmap * epinfma[-1]\n    epinfma[0] = z_epinf * epinf[x]\n    sw[0] = crhow * sw[-1] + ewma[0] - cmaw * ewma[-1]\n    ewma[0] = z_ew * ew[x]\n    kp[0] = kp[-1] * (1 - cikbar) + inve[0] * cikbar + qs[0] * csadjcost * cgamma ^ 2 * cikbar\n    dy[0] = ctrend + y[0] - y[-1]\n    dc[0] = ctrend + c[0] - c[-1]\n    dinve[0] = ctrend + inve[0] - inve[-1]\n    pinfobs[0] = constepinf + pinf[0]\n    robs[0] = r[0] + conster\n    dwobs[0] = ctrend + w[0] - w[-1]\n    labobs[0] = lab[0] + constelab\nend\n\n@parameters Smets_Wouters_2007_linear begin\n    ctou = .025\n    clandaw = 1.5\n    cg = 0.18\n    curvp = 10\n    curvw = 10\n    calfa = .24\n    csigma = 1.5\n    cfc = 1.5\n    cgy = 0.51\n    csadjcost = 6.0144\n    chabb = 0.6361\n    cprobw = 0.8087\n    csigl = 1.9423\n    cprobp = 0.6\n    cindw = 0.3243\n    cindp = 0.47\n    czcap = 0.2696\n    crpi = 1.488\n    crr = 0.8762\n    cry = 0.0593\n    crdy = 0.2347\n    crhoa = 0.9977\n    crhob = 0.5799\n    crhog = 0.9957\n    crhoqs = 0.7165\n    crhoms = 0\n    crhopinf = 0\n    crhow = 0\n    cmap = 0\n    cmaw = 0\n    constelab = 0\n    constepinf = 0.7\n    constebeta = 0.7420\n    ctrend = 0.3982\n    z_ea    = 0.4618\n    z_eb    = 1.8513\n    z_eg    = 0.6090\n    z_em    = 0.2397\n    z_ew    = 0.2089\n    z_eqs   = 0.6017\n    z_epinf = 0.1455\n    cpie    = 1 + constepinf / 100                                                                      # gross inflation rate\n    cgamma  = 1 + ctrend / 100                                                                          # gross growth rate\n    cbeta   = 1 / (1 + constebeta / 100)                                                                # discount factor\n    clandap = cfc                                                                                       # fixed cost share/gross price markup\n    cbetabar= cbeta * cgamma ^ (-csigma)                                                                # growth-adjusted discount factor in Euler equation\n    cr      = cpie / cbetabar                                                                           # steady state gross real interest rate\n    crk     = 1 / cbetabar - (1 - ctou)                                                                 # steady state rental rate\n    cw      = (calfa ^ calfa * (1 - calfa) ^ (1 - calfa) / (clandap * crk ^ calfa)) ^ (1 / (1 - calfa)) # steady state real wage\n    cikbar  = 1 - (1 - ctou) / cgamma                                                                   # (1-k_1) in equation LOM capital, equation (8)\n    cik     = cikbar * cgamma                                                                           # i_k: investment-capital ratio\n    clk     = (1 - calfa) / calfa * crk / cw                                                            # labor to capital ratio\n    cky     = cfc * clk ^ (calfa - 1)                                                                   # k_y: steady state output ratio\n    ciy     = cik * cky                                                                                 # investment-output ratio\n    ccy     = 1 - cg - cik * cky                                                                        # consumption-output ratio\n    crkky   = crk * cky                                                                                 # z_y=R_{*}^k*k_y\n    cwhlc   = (1 / clandaw) * (1 - calfa) / calfa * crk * cky / ccy                                     # W^{h}_{*}*L_{*}/C_{*} used in c_2 in equation (2)\n    conster = (cr - 1) * 100                                                                            # steady state federal funds rate ($\\bar r$)\nend\n\nCalling the conditional variance decomposition plot function:\n\nplot_conditional_variance_decomposition(Smets_Wouters_2007_linear)\n\n(Image: Smets and Wouters 2007 FEVD)\n\nThis creates conditional variance decomposition plots showing the contribution of each shock to the forecast error variance of each variable across different forecast horizons.\n\nThe vertical axis shows the share of the shocks variance contribution, and the horizontal axis the period of the variance decomposition. The stacked bars represent each shocks variance contribution at a specific time horizon.\n\nNote that if occasionally binding constraints are present in the model, they are not taken into account here.\n\nThe same function can be called using different names. For example: plot_fevd, or plot_forecast_error_variance_decomposition. Going forward, plot_fevd will be used for brevity.","category":"section"},{"location":"plot_conditional_variance_decomposition/#Periods-Argument","page":"Variance Decomposition","title":"Periods Argument","text":"The periods argument (default: 40, type: Int) specifies the number of forecast horizons to include in the variance decomposition. This determines how far into the future the decomposition extends.\n\n# Show variance decomposition up to 12 periods ahead\nplot_fevd(Smets_Wouters_2007_linear, periods = 12)\n\n(Image: Smets and Wouters 2007 FEVD - 12 periods)","category":"section"},{"location":"plot_conditional_variance_decomposition/#Variables-to-Plot","page":"Variance Decomposition","title":"Variables to Plot","text":"The variables argument (default: :all) specifies for which variables to show results. Variable names can be specified as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc includes all variables except auxiliary variables and those related to occasionally binding constraints (OBC). :all_excluding_obc includes all variables except those related to occasionally binding constraints. :all includes all variables.\n\nSpecific variables can be selected to plot. The following example selects output Y, consumption c, investment inve, inflation pinf, wages w, and labor lab using a Vector of Symbols:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = [:inve, :c, :y, :pinf, :w, :lab])\n\n(Image: Smets and Wouters 2007 FEVD - selected variables)\n\nThe plot now displays only one plot with the six selected variables (sorted alphabetically).\n\nThe same can be done using a Tuple:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = (:inve, :c, :y, :pinf, :w, :lab))\n\na Matrix:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = [:inve :c :y :pinf :w :lab])\n\nor providing the variable names as Strings:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = [\"inve\", \"c\", \"y\", \"pinf\", \"w\", \"lab\"])\n\nor a single variable as a Symbol:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = :inve)\n\nor as a String:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = \"inve\")\n\nThen there are some predefined options:\n\n:all_excluding_auxiliary_and_obc plots all variables except auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = :all_excluding_auxiliary_and_obc)\n\n:all_excluding_obc plots all variables except those used to enforce occasionally binding constraints (OBC).\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = :all_excluding_obc)\n\nTo see auxiliary variables, use a model that defines them. The FS2000 model can be used:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nSince both c and P appear in t+2, they generate auxiliary variables in the model. Plotting the policy functions for all variables excluding OBC-related ones means auxiliary variables are shown (same for the default :all option since there are no OBCs in this model):\n\nplot_fevd(FS2000,\n    variables = :all_excluding_obc)\n\n(Image: FS2000 FEVD - including auxiliary variables)\n\nBoth c and P appear twice: once as the variable itself and once as an auxiliary variable with the ᴸ⁽¹⁾ superscript, representing the value of the variable in t+1 as expected in t.\n\n:all (default) plots all variables including auxiliary variables. Since OBCs are not considered with FEVD, variables used to enforce occasionally binding constraints (OBC) are not included.\n\nplot_fevd(FS2000)","category":"section"},{"location":"plot_conditional_variance_decomposition/#Parameter-Values","page":"Variance Decomposition","title":"Parameter Values","text":"When no parameters are provided, the solution uses the previously defined parameter values. Parameters can be provided as a Vector of values, or as a Vector or Tuple of Pairs mapping parameter Symbols or Strings to values. The solution is recalculated when new parameter values differ from the previous ones.\n\nStart by changing the discount factor z_eg to 1:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    parameters = :z_eg => 1)\n\n(Image: Smets and Wouters 2007 FEVD - different parameter values)\n\nThe shock contributions changed as a result of changing the shock standard deviation.\n\nMultiple parameters can also be changed simultaneously. This example changes z_eg to 1.5 and crpi to 1.75 using a Tuple of Pairs and define the variables with Symbols:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    parameters = (:z_eg => 1.5, :crpi => 1.75))\n\n(Image: Smets and Wouters 2007 FEVD - multiple parameter changes)\n\nA Vector of Pairs can also be used:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    parameters = [:z_eg => 1.5, :crpi => 1.75])\n\nAlternatively, use a Vector of parameter values in the order they were defined in the model. To obtain them:\n\nparams = get_parameters(Smets_Wouters_2007_linear, values = true)\n\nparam_vals = [p[2] for p in params]\n\nplot_fevd(Smets_Wouters_2007_linear,\n    parameters = param_vals)","category":"section"},{"location":"plot_conditional_variance_decomposition/#Plot-Attributes","page":"Variance Decomposition","title":"Plot Attributes","text":"The plot_attributes argument (default: Dict(), type: Dict) accepts a dictionary of attributes passed on to the plotting function. See the Plots.jl documentation for details.\n\nThe color palette can be customized using the plot_attributes argument. The following example defines a custom color palette (inspired by the European Commission's economic reports) to plot the FEVD using the Smets_Wouters_2007_linear model. First, define the custom color palette using hex color codes:\n\nec_color_palette =\n[\n    \"#FFD724\",  # \"Sunflower Yellow\"\n    \"#353B73\",  # \"Navy Blue\"\n    \"#2F9AFB\",  # \"Sky Blue\"\n    \"#B8AAA2\",  # \"Taupe Grey\"\n    \"#E75118\",  # \"Vermilion\"\n    \"#6DC7A9\",  # \"Mint Green\"\n    \"#F09874\",  # \"Coral\"\n    \"#907800\"   # \"Olive\"\n]\n\nNext, plot the FEVD using the custom color palette:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    plot_attributes = Dict(:palette => ec_color_palette))\n\n(Image: Smets and Wouters 2007 FEVD - custom color palette)\n\nThe colors of the shock contributions now follow the custom color palette.\n\nOther attributes such as the font family can also be modified (see here for GR font options):\n\nplot_fevd(Smets_Wouters_2007_linear,\n    plot_attributes = Dict(:fontfamily => \"computer modern\"))\n\n(Image: Smets and Wouters 2007 FEVD - custom font)\n\nAll text in the plot now uses the Computer Modern font. Note that font rendering inherits the constraints of the plotting backend (GR in this case).\n\nHere is another example that customizes the alpha (transparency) of the filled areas in the FEVD plots:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    plot_attributes = Dict(:fillalpha => .5))\n\n(Image: Smets and Wouters 2007 FEVD - custom fill alpha)","category":"section"},{"location":"plot_conditional_variance_decomposition/#Plots-Per-Page","page":"Variance Decomposition","title":"Plots Per Page","text":"The plots_per_page argument (default: 9, type: Int) controls the number of subplots per page. When the number of variables exceeds this value, multiple pages are created. The following example selects 6 variables and sets plots_per_page to 4, resulting in 2 pages with the first page having 4 subplots and the second page having 2 subplots:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    variables = [:inve, :c, :y, :pinf, :w, :lab],\n    plots_per_page = 4)\n\n(Image: Smets and Wouters 2007 FEVD - 4 plots per page)\n\nThe first page displays the first four variables (sorted alphabetically) with two subplots for each shock. The title indicates this is page 1 of 2.","category":"section"},{"location":"plot_conditional_variance_decomposition/#Display-Plots","page":"Variance Decomposition","title":"Display Plots","text":"The show_plots argument (default: true, type: Bool), when true, displays the plots; otherwise, they are only returned as an object.\n\nplot_fevd(Smets_Wouters_2007_linear,\n    show_plots = false)","category":"section"},{"location":"plot_conditional_variance_decomposition/#Saving-Plots","page":"Variance Decomposition","title":"Saving Plots","text":"The save_plots argument (default: false, type: Bool), when true, saves the plots to disk; otherwise, they are only displayed and returned as an object.\n\nRelated arguments control the saving behavior:\n\nsave_plots_format (default: :pdf, type: Symbol): output format of saved plots. See input formats compatible with GR for valid formats.\nsave_plots_path (default: \".\", type: String): path where plots are saved. If the path does not exist, it will be created automatically.\nsave_plots_name (default: \"fevd\", type: Union{String, Symbol}): prefix prepended to the filename when saving plots.\n\nEach plot is saved as a separate file with a name indicating the prefix, model name, shocks, and a sequential number for multiple plots (e.g., fevd__ModelName__1.pdf).\n\nThe following example saves all policy functions for the Smets_Wouters_2007_linear model as PNG files in the ../plots directory with fevd_plot as the filename prefix:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    save_plots = true,\n    save_plots_format = :png,\n    save_plots_path = \"./../plots\",\n    save_plots_name = :fevd_plot)\n\nThe plots appear in the specified folder with the specified prefix. Each plot is saved in a separate file with a name reflecting the model, the shock, and a sequential index when the number of variables exceeds the plots per page.","category":"section"},{"location":"plot_conditional_variance_decomposition/#Variable-and-Shock-Renaming-(rename-dictionary)","page":"Variance Decomposition","title":"Variable and Shock Renaming (rename dictionary)","text":"The rename_dictionary argument (default: Dict(), type: AbstractDict{<:Union{Symbol, String}, <:Union{Symbol, String}}) maps variable or shock symbols to custom display names in plots. This is particularly useful when comparing models with different variable naming conventions, allowing them to be displayed with consistent labels.\n\nFor example, to rename variables for clearer display:\n\nplot_fevd(Smets_Wouters_2007_linear,\n        rename_dictionary = Dict(\n            :y => \"Output\", \n            :pinfobs => \"Inflation\", \n            :robs => \"Interest Rate\", \n            :inve => \"Investment\", \n            :c => \"Consumption\", \n            :w => \"Wages\", \n            :lab => \"Labor\"\n        ))\n\n(Image: Smets and Wouters 2007 FEVD - rename dictionary)\n\nThe rename_dictionary accepts flexible type combinations for keys and values—both Symbol and String types work interchangeably:\n\n# All of these are valid and equivalent:\nDict(:y => \"Output\")              # Symbol key, String value\nDict(\"y\" => \"Output\")             # String key, String value\nDict(:y => :Output)               # Symbol key, Symbol value\nDict(\"y\" => :Output)              # String key, Symbol value\n\nThis flexibility is particularly useful for models like Backus_Kehoe_Kydland_1992, which uses String representations of variable and shock names (because of {}):\n\n# Define the Backus model (abbreviated for clarity)\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1-theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1/nu{co})\n        K{co}[0] = (1-delta{co})*K{co}[-1] + S{co}[0]\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n        A{co}[0] = (1-eta{co}) * A{co}[-1] + N{co}[0]\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1-alpha{co})*eta{co} * A{co}[-1]\n        U{co}[0] = (C{co}[0]^mu{co}*L{co}[0]^(1-mu{co}))^gamma{co}\n        psi{co} * mu{co} / C{co}[0]*U{co}[0] = LGM[0]\n        psi{co} * (1-mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1-theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co}*N{co}[0]^(1-theta{co}))^(-nu{co})*Y{co}[0]^(1+nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1-delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1-theta{co})) ^ (-nu{co})* Y{co}[+4]^(1+nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1+sigma{co} * Z{co}[0]^(-nu{co}-1)*Y{co}[+1]^(1+nu{co}))\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1]))/Y{co}[0]\n    end\n\n    (LAMBDA{H}[0]-1) = rho{H}{H}*(LAMBDA{H}[-1]-1) + rho{H}{F}*(LAMBDA{F}[-1]-1) + Z_E{H} * E{H}[x]\n    (LAMBDA{F}[0]-1) = rho{F}{F}*(LAMBDA{F}[-1]-1) + rho{F}{H}*(LAMBDA{H}[-1]-1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend\n\n# Backus model example showing String to String mapping\nplot_fevd(Backus_Kehoe_Kydland_1992,\n    rename_dictionary = Dict(\"K{H}\" => \"Capital (Home)\", \n                             \"K{F}\" => \"Capital (Foreign)\",\n                             \"Y{H}\" => \"Output (Home)\",\n                             \"Y{F}\" => \"Output (Foreign)\"))\n\n(Image: Backus, Kehoe, Kydland 1992 FEVD - rename dictionary)\n\nVariables or shocks not included in the dictionary retain their default names. The renaming applies to all plot elements including legends, axis labels, and tables.","category":"section"},{"location":"plot_conditional_variance_decomposition/#Verbose-Output","page":"Variance Decomposition","title":"Verbose Output","text":"The verbose argument (default: false, type: Bool), when true, enables verbose output related to solving the model\n\nplot_fevd(Smets_Wouters_2007_linear,\n    verbose = true)\n\nThe code outputs information about solving the steady state blocks. When parameters change, the first-order solution is recomputed; otherwise, it uses the cached solution:\n\nplot_fevd(Smets_Wouters_2007_linear,\n    parameters = :z_eg => 1.05,\n    verbose = true)\n# Parameter changes: \n#         z_eg    from 1.5        to 1.05\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 1.776217186138026e-21\n# Block: 2, - Solved using previous solution; residual norm: 6.83217016268833e-19\n# Quadratic matrix equation solver previous solution has tolerance: 2.25183977733317e-15","category":"section"},{"location":"plot_conditional_variance_decomposition/#Numerical-Tolerances","page":"Variance Decomposition","title":"Numerical Tolerances","text":"The tol argument (default: Tolerances(), type: Tolerances) defines various tolerances for the algorithm used to solve the model. See the Tolerances documentation for more details: ?Tolerances. The tolerances used by the numerical solvers can be adjusted. The Tolerances object allows setting tolerances for the non-stochastic steady state solver (NSSS), Sylvester equations, Lyapunov equation, and quadratic matrix equation (QME). For example, to set tighter tolerances (this example also changes parameters to force recomputation):\n\ncustom_tol = Tolerances(qme_acceptance_tol = 1e-12,\n    sylvester_acceptance_tol = 1e-12)\n\nplot_fevd(Smets_Wouters_2007_linear,\n    tol = custom_tol,\n    parameters = :z_eg => 1.055,\n    verbose = true)\n# Parameter changes: \n#         z_eg    from 1.05       to 1.055\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 1.776217186138026e-21\n# Block: 2, - Solved using previous solution; residual norm: 6.83217016268833e-19\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 2.25183977733317e-15\n\nThis is useful when higher precision is needed or when the default tolerances are insufficient for convergence. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_conditional_variance_decomposition/#Quadratic-Matrix-Equation-Solver","page":"Variance Decomposition","title":"Quadratic Matrix Equation Solver","text":"The quadratic_matrix_equation_algorithm argument (default: :schur, type: Symbol) specifies the algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling The quadratic matrix equation solver is used internally when solving the model to first order. Different algorithms are available. The :schur algorithm is generally faster and more reliable, while :doubling can be more precise in some cases (this example also changes parameters to force recomputation):\n\nplot_fevd(Smets_Wouters_2007_linear,\n    quadratic_matrix_equation_algorithm = :doubling,\n    parameters = :z_eg => 1.0555,\n    verbose = true)\n# Parameter changes: \n#         z_eg    from 1.055      to 1.0555\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 1.776217186138026e-21\n# Block: 2, - Solved using previous solution; residual norm: 6.83217016268833e-19\n# Quadratic matrix equation solver previous solution has tolerance: 2.25183977733317e-15\n\nFor most use cases, the default :schur algorithm is recommended. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"how-to/loops/#Programmatic-model-writing","page":"Programmatic model writing using for-loops","title":"Programmatic model writing","text":"Programmatic model writing is a powerful tool to write complex models using concise code. More specifically, the @model and @parameters macros allow for the use of indexed variables and for-loops.","category":"section"},{"location":"how-to/loops/#Model-block","page":"Programmatic model writing using for-loops","title":"Model block","text":"","category":"section"},{"location":"how-to/loops/#for-loops-for-time-indices","page":"Programmatic model writing using for-loops","title":"for loops for time indices","text":"In practice this means that this is no longer needed:\n\nY_annual[0] = Y[0] + Y[-1] + Y[-2] + Y[-3]\n\nbut instead this can be written:\n\nY_annual[0] = for lag in -3:0 Y[lag] end\n\nIn the background the package expands the for loop and adds up the elements for the different values of lag.\n\nIn case the elements should not be added up but multiplied this can be done:\n\nR_annual[0] = for operator = :*, lag in -3:0 R[lag] end","category":"section"},{"location":"how-to/loops/#for-loops-for-variables-/-parameter-specific-indices","page":"Programmatic model writing using for-loops","title":"for loops for variables / parameter specific indices","text":"Another use-case are models with repetitive equations such as multi-sector or multi-country models.\n\nFor example, defining the production function for two countries (home country H and foreign country F) would  look as follows without the use of programmatic features:\n\ny_H[0] = A_H[0] * k_H[-1]^alpha_H\ny_F[0] = A_F[0] * k_F[-1]^alpha_F\n\nand this can be written more conveniently using loops:\n\nfor co in [H, F] y{co}[0] = A{co}[0] * k{co}[-1]^alpha{co} end\n\nNote that the package internally writes out the for loop and creates two equations; one each for country H and F. The variables and parameters are indexed using the curly braces {}. These can also be used outside loops. When using more than one index it is important to make sure the indices are in the right order.","category":"section"},{"location":"how-to/loops/#Example-model-block","page":"Programmatic model writing using for-loops","title":"Example model block","text":"Putting these elements together the multi-country model equations of the Backus, Kehoe, and Kydland (1992) model can be written like this:\n\nusing MacroModelling\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1 - theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1 / nu{co})\n\n        K{co}[0] = (1 - delta{co}) * K{co}[-1] + S{co}[0]\n\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n\n        A{co}[0] = (1 - eta{co}) * A{co}[-1] + N{co}[0]\n\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1 - alpha{co}) * eta{co} * A{co}[-1]\n\n        U{co}[0] = (C{co}[0]^mu{co} * L{co}[0]^(1 - mu{co}))^gamma{co}\n\n        psi{co} * mu{co} / C{co}[0] * U{co}[0] = LGM[0]\n\n        psi{co} * (1 - mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1 - theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1 - theta{co}))^(-nu{co}) * Y{co}[0]^(1 + nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1 - delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1 - theta{co})) ^ (-nu{co}) * Y{co}[+4]^(1 + nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1 + sigma{co} * Z{co}[0]^(-nu{co} - 1) * Y{co}[+1]^(1 + nu{co}))\n\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1])) / Y{co}[0]\n    end\n\n    (LAMBDA{H}[0] - 1) = rho{H}{H} * (LAMBDA{H}[-1] - 1) + rho{H}{F} * (LAMBDA{F}[-1] - 1) + Z_E{H} * E{H}[x]\n\n    (LAMBDA{F}[0] - 1) = rho{F}{F} * (LAMBDA{F}[-1] - 1) + rho{F}{H} * (LAMBDA{H}[-1] - 1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend","category":"section"},{"location":"how-to/loops/#Parameter-block","page":"Programmatic model writing using for-loops","title":"Parameter block","text":"Having defined parameters and variables with indices in the model block parameter values can also be declared, including by means of calibration equations, in the parameter block.\n\nIn the above example the production function was defined for countries H and F. Implicitly there are two parameters alpha and their value can be defined individually by setting\n\nalpha{H} = 0.3\nalpha{F} = 0.3\n\nor jointly by writing\n\nalpha = 0.3\n\nBy not using the index, the package understands that there are two parameters with this name and different indices and will set both accordingly.\n\nThis logic also applies to calibration equations; for example:\n\ny{H}[ss] = 1 | alpha{H}\ny{F}[ss] = 1 | alpha{F}\n\nto find the value of alpha that corresponds to y being equal to 1 in the non-stochastic steady state. Alternatively indices can be omitted and the package understands that both indices are referred to:\n\ny[ss] = 1 | alpha\n\nMaking use of the indices a level of y for country H with alpha for country H could also be targeted and the ratio of the two ys targeted with the alpha for country F:\n\ny{H}[ss] = 1 | alpha{H}\ny{H}[ss] / y{F}[ss] = y_ratio | alpha{F}\ny_ratio =  0.9","category":"section"},{"location":"how-to/loops/#Example-parameter-block","page":"Programmatic model writing using for-loops","title":"Example parameter block","text":"Making use of this and continuing the example of the Backus, Kehoe and Kydland (1992) model the parameters can be defined as follows:\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend","category":"section"},{"location":"tutorials/rbc/#Write-your-first-model-simple-RBC","page":"Write your first simple model - RBC","title":"Write your first model - simple RBC","text":"This tutorial walks through the steps of writing down a model and analysing it. Prior knowledge of DSGE models and their solution in practical terms (e.g. having used a mod file with dynare) is useful in understanding this tutorial. For the purpose of this tutorial a simplified version of a real business cycle (RBC) model is used. The model laid out below examines capital accumulation, consumption, and random technological progress. Households maximise lifetime utility from consumption, weighing current against future consumption. Firms produce using capital and a stochastic technology factor, setting capital rental rates based on marginal productivity. The model integrates households' decisions, firms' production, and random technological shifts to understand economic growth and dynamics.","category":"section"},{"location":"tutorials/rbc/#RBC-derivation-of-model-equations","page":"Write your first simple model - RBC","title":"RBC - derivation of model equations","text":"Household's Problem: Households derive utility from consuming goods and discount future consumption. The decision they face every period is how much of their income to consume now versus how much to invest for future consumption.\n\nE_0 sum_t=0^infty beta^t ln(c_t)\n\nTheir budget constraint reflects that their available resources for consumption or investment come from returns on their owned capital (both from the rental rate and from undepreciated capital) and any profits distributed from firms.\n\nc_t + k_t = (1-delta) k_t-1 + R_t k_t-1 + Pi_t\n\nCombining the first order (optimality) conditions with respect to c_t and k_t shows that households balance the marginal utility of consuming one more unit today against the expected discounted marginal utility of consuming that unit in the future.\n\nfrac1c_t = beta E_t left (R_t+1 + 1 - delta) frac1c_t+1 right\n\nFirm's Problem: Firms rent capital from households to produce goods. Their profits, Pi_t, are the difference between their revenue from selling goods and their costs from renting capital. Competition ensures that profits are 0.\n\nPi_t = q_t - R_t k_t-1\n\nGiven the Cobb-Douglas production function with a stochastic technology process:\n\nq_t = e^z_t k_t-1^alpha\n\nThe FOC with respect to capital k_t determines the optimal amount of capital the firm should rent. It equates the marginal product of capital (how much additional output one more unit of capital would produce) to its cost (the rental rate).\n\nR_t = alpha e^z_t k_t-1^alpha-1\n\nMarket Clearing: This condition ensures that every good produced in the economy is either consumed by households or invested to augment future production capabilities.\n\nq_t = c_t + i_t\n\nWith:\n\ni_t = k_t - (1-delta)k_t-1\n\nEquations describing the dynamics of the economy:\n\nHousehold's Optimization (Euler Equation): Signifies the balance households strike between current and future consumption. The rental rate of capital has been substituted for.\n\nfrac1c_t = fracbetac_t+1 left( alpha e^z_t+1 k_t^alpha-1 + (1 - delta) right)\n\nCapital Accumulation: Charts the progression of capital stock over time.\n\nc_t + k_t = (1-delta)k_t-1 + q_t\n\nProduction: Describes the output generation from the previous period's capital stock, enhanced by current technology.\n\nq_t = e^z_t k_t-1^alpha\n\nTechnology Process: Traces the evolution of technological progress. Exogenous innovations are captured by epsilon^z_t.\n\nz_t = rho^z z_t-1 + sigma^z epsilon^z_t","category":"section"},{"location":"tutorials/rbc/#Define-the-model","page":"Write your first simple model - RBC","title":"Define the model","text":"The first step is always to name the model and write down the equations. Taking the RBC model described above this would go as follows.\n\nFirst, the package is loaded and then the @model macro is used to define the model. The first argument after @model is the model name and will be the name of the object in the global environment containing all information regarding the model. The second argument to the macro are the equations, which are written down between begin and end. One equation per line and timing of endogenous variables are expressed in the square brackets following the variable name. Exogenous variables (shocks) are followed by a keyword in square brackets indicating them being exogenous (in this case [x]). Note that names can leverage julias unicode capabilities (alpha can be written as α).\n\nusing MacroModelling\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n\n    q[0] = exp(z[0]) * k[-1]^α\n\n    z[0] = ρᶻ * z[-1] + σᶻ * ϵᶻ[x]\nend\n\nAfter the model is parsed some info on the model variables, and parameters are displayed.","category":"section"},{"location":"tutorials/rbc/#Define-the-parameters","page":"Write your first simple model - RBC","title":"Define the parameters","text":"Next the parameters of the model need to be added. The macro @parameters takes care of this:\n\n@parameters RBC begin\n    σᶻ= 0.01\n    ρᶻ= 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nParameter definitions are similar to assigning values in julia. Note that one parameter definition per line is required.\n\nGiven the equations and parameters, the package will first attempt to solve the system of nonlinear equations symbolically (including possible calibration equations - see next tutorial for an example). If an analytical solution is not possible, numerical solution methods are used to try and solve it. There is no guarantee that a solution can be found, but it is highly likely, given that a solution exists. The problem setup tries to incorporate parts of the structure of the problem, e.g. bounds on variables: if one equation contains log(k) it must be that k > 0. Nonetheless, the user can also provide useful information such as variable bounds or initial guesses. Bounds can be set by adding another expression to the parameter block e.g.: c > 0. Large values are typically a problem for numerical solvers. Therefore, providing a guess for these values will increase the speed of the solver. Guesses can be provided as a Dict after the model name and before the parameter definitions block, e.g.: @parameters RBC guess = Dict(k => 10) begin ... end.","category":"section"},{"location":"tutorials/rbc/#Delayed-parameter-definition","page":"Write your first simple model - RBC","title":"Delayed parameter definition","text":"Not all parameters need to be defined in the @parameters macro. Calibration equations (using the | syntax) and parameters defined as functions of other parameters must be declared here, but simple parameter value assignments (e.g., α = 0.5) can be deferred and provided later by passing them to any function that accepts the parameters argument (e.g., get_irf, get_steady_state, simulate).\n\nParameter ordering: When some parameters are not defined upfront, the parameter vector is ordered as follows: declared parameters come first (in their declaration order), followed by missing parameters (in alphabetical order). This matters when passing parameter values by position rather than by name.\n\nThe example above with delayed parameter definition would work as follows. The model is defined as before:\n\nusing MacroModelling\n@model RBC_delayed begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n\n    q[0] = exp(z[0]) * k[-1]^α\n\n    z[0] = ρᶻ * z[-1] + σᶻ * ϵᶻ[x]\nend\n\nbut in the parameter definition only the calibration equations and parameters defined as functions of other parameters are defined, so in this case we can leave it empty:\n\n@parameters RBC_delayed begin\nend\n\nthe package warns that the model has been set up with incomplete parameter definitions and provides the missing parameters.\n\nWe can then provide the missing parameters when calling functions that accept the parameters argument, for example to retrieve IRFs:\n\nget_irf(RBC_delayed, parameters = (:σᶻ => 0.01, :ρᶻ => 0.2, :δ => 0.02, :α => 0.5, :β => 0.95))\n\nNote that only now that all parameters have been defined the package can attempt to solve the model. The steady state problem and derivatives are taken only once all missing parameters have been provided, as the order of the parameters follows declaration order. This functionality effectively allows to load parameter values from an external source (e.g. a CSV file) and pass them to the model without having to redefine the model.","category":"section"},{"location":"tutorials/rbc/#Plot-impulse-response-functions-(IRFs)","page":"Write your first simple model - RBC","title":"Plot impulse response functions (IRFs)","text":"A useful output to analyse are IRFs for the exogenous shocks. Calling plot_irf (different names for the same function are also supported: plot_irfs, or plot_IRF) will take care of this. Note that the StatsPlots package needs to be imported once before the first plot. In the background the package solves (symbolically in this simple case) for the non-stochastic steady state (SS) and calculates the first order perturbation solution.\n\nimport StatsPlots\nplot_irf(RBC)\n\n(Image: RBC IRF)\n\nWhen the model is solved the first time (in this case by calling plot_irf), the package breaks down the steady state problem into independent blocks and first attempts to solve them symbolically and if that fails numerically.\n\nThe plot shows the responses of the endogenous variables (c, k, q, and z) to a one standard deviation positive (indicated by Shock⁺ in chart title) unanticipated shock in  eps_z. Therefore there are as many subplots as there are combinations of shocks and endogenous variables (which are impacted by the shock). Plots are composed of up to 9 subplots and the plot title shows the model name followed by the name of the shock and which plot is being displayed out of the plots for this shock (e.g. (1/3) means the first out of three plots for this shock is shown). Subplots show the sorted endogenous variables with the left y-axis showing the level of the respective variable and the right y-axis showing the percent deviation from the SS (if variable is strictly positive). The horizontal black line marks the SS.","category":"section"},{"location":"tutorials/rbc/#Explore-other-parameter-values","page":"Write your first simple model - RBC","title":"Explore other parameter values","text":"Experimenting with the model can be especially insightful in the early phase of development. The package facilitates this process as much as possible. Typically, users try different parameter values to see how the IRFs change. This can be done by using the parameters argument of the plot_irf function. Pass a Pair with the Symbol of the parameter (prefixed by :) and its new value to the parameter argument (for example :α => 0.3).\n\nplot_irf(RBC, parameters = :α => 0.3)\n\n(Image: IRF plot)\n\nFirst, the package finds the new steady state, solves the model dynamics around it and saves the new parameters and solution in the model object. Second, note that the shape of the curves in the plot and the y-axis values changed. Updating the plot for new parameters is significantly faster than calling it the first time. This is because the first call triggers compilations of the model functions, and once compiled the user benefits from the performance of the specialised compiled code.","category":"section"},{"location":"tutorials/rbc/#Plot-model-simulation","page":"Write your first simple model - RBC","title":"Plot model simulation","text":"Another insightful output is simulations of the model. The plot_simulations function can be used here. Note that the StatsPlots package needs to be imported once before the first plot. To the same effect the plot_irf function can be used and in the shocks argument :simulate is specified to simulate the model and the periods argument set to 100.\n\nplot_simulations(RBC)\n\n(Image: Simulate RBC)\n\nThe plots show the models endogenous variables in response to random draws for all exogenous shocks over 100 periods.","category":"section"},{"location":"tutorials/rbc/#Plot-specific-series-of-shocks","page":"Write your first simple model - RBC","title":"Plot specific series of shocks","text":"To examine a specific series of shocks and the resulting responses of the endogenous variables, pass a Matrix or a KeyedArray (the KeyedArray type is provided by the AxisKeys package) containing the shock series to the shocks argument of the plot_irf function:\n\nshock_series = zeros(1,4)\nshock_series[1,2] = 1\nshock_series[1,4] = -1\nplot_irf(RBC, shocks = shock_series)\n\n(Image: Series of shocks RBC)\n\nThe plot shows the two shocks hitting the economy in periods 2 and 4 and then continues the simulation for 40 more quarters.","category":"section"},{"location":"tutorials/rbc/#Model-statistics","page":"Write your first simple model - RBC","title":"Model statistics","text":"The package solves for the SS automatically and the SS values can be seen in the plots. To see the SS values get_steady_state can be called:\n\nget_steady_state(RBC)\n\nto get the SS and the derivatives of the SS with respect to the model parameters. The first column of the returned matrix shows the SS while the second to last columns show the derivatives of the SS values (indicated in the rows) with respect to the parameters (indicated in the columns). For example, the derivative of k with respect to β is 165.319. This means that if β is increased by 1, k would increase by 165.319 approximately. How this plays out can be seen by changing β from 0.95 to 0.951 (a change of +0.001):\n\nget_steady_state(RBC,parameters = :β => .951)\n\nNote that get_steady_state like all other get functions has the parameters argument. Hence, for whatever output is being examined the parameters of the model can be changed.\n\nThe new value of β changed the SS as expected and k increased by 0.168. The elasticity (0.168/0.001) comes close to the partial derivative previously calculated. The derivatives help understanding the effect of parameter changes on the steady state and make for easier navigation of the parameter space.","category":"section"},{"location":"tutorials/rbc/#Standard-deviations","page":"Write your first simple model - RBC","title":"Standard deviations","text":"Next to the SS the model implied standard deviations of the model can also be displayed. get_standard_deviation takes care of this. Additionally the parameter values will be set to what they were in the beginning by passing on a Tuple of Pairs containing the Symbols of the parameters to be changed and their new (initial) values (e.g. (:α => 0.5, :β => .95)).\n\nget_standard_deviation(RBC, parameters = (:α => 0.5, :β => .95))\n\nThe function returns the model implied standard deviations of the model variables and their derivatives with respect to the model parameters. For example, the derivative of the standard deviation of c with resect to δ is -0.384. In other words, the standard deviation of c decreases with increasing δ.","category":"section"},{"location":"tutorials/rbc/#Correlations","page":"Write your first simple model - RBC","title":"Correlations","text":"Another useful statistic is the model implied correlation of variables. get_correlation is used for this:\n\nget_correlation(RBC)","category":"section"},{"location":"tutorials/rbc/#Autocorrelations","page":"Write your first simple model - RBC","title":"Autocorrelations","text":"Last but not least, the model implied autocorrelations of model variables can be examined using the get_autocorrelation function:\n\nget_autocorrelation(RBC)","category":"section"},{"location":"tutorials/rbc/#Model-solution","page":"Write your first simple model - RBC","title":"Model solution","text":"A further insightful output are the policy and transition functions of the first order perturbation solution. To retrieve the solution the function get_solution can be called:\n\nget_solution(RBC)\n\nThe solution provides information about how past states and present shocks impact present variables. The first row contains the SS for the variables denoted in the columns. The second to last rows contain the past states, with the time index ₍₋₁₎, and present shocks, with exogenous variables denoted by ₍ₓ₎. For example, the immediate impact of a shock to eps_z on q is 0.0688.\n\nThere is also the possibility to visually inspect the solution. Note that the StatsPlots package needs to be imported once before the first plot. The plot_solution function can be used:\n\nplot_solution(RBC, :k)\n\n(Image: RBC solution)\n\nThe chart shows the first order perturbation solution mapping from the past state k to the present variables of the model. The state variable covers a range of two standard deviations around the non-stochastic steady state and all other states remain in the non-stochastic steady state.","category":"section"},{"location":"tutorials/rbc/#Obtain-array-of-IRFs-or-model-simulations","page":"Write your first simple model - RBC","title":"Obtain array of IRFs or model simulations","text":"Last but not least simulated time series of the model or IRFs might be of interest without plotting them. For IRFs this is possible by calling get_irf:\n\nget_irf(RBC)\n\nwhich returns a 3-dimensional KeyedArray (provided by the AxisKeys package) with variables (absolute deviations from the relevant steady state by default) in rows, the period in columns, and the shocks as the third dimension.\n\nFor simulations this is possible by calling simulate:\n\nsimulate(RBC)\n\nwhich returns the simulated data in levels in a 3-dimensional KeyedArray (provided by the AxisKeys package) of the same structure as for the IRFs.","category":"section"},{"location":"tutorials/rbc/#Conditional-forecasts","page":"Write your first simple model - RBC","title":"Conditional forecasts","text":"Conditional forecasting is a useful tool to incorporate for example forecasts into a model and then add shocks on top.\n\nFor example the model dynamics might be of interest given a path for c for the first 4 quarters and the next quarter a negative shock to eps_z arrives. This can be implemented using the get_conditional_forecast function and visualised with the plot_conditional_forecast function.\n\nFirst, the conditions on the endogenous variables are defined as deviations from the non-stochastic steady state (c in this case) using a KeyedArray from the AxisKeys package (check get_conditional_forecast for other ways to define the conditions):\n\nusing AxisKeys\nconditions = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,4),Variables = [:c], Periods = 1:4)\nconditions[1:4] .= [-.01,0,.01,.02];\n\nNote that all other endogenous variables not part of the KeyedArray (provided by the AxisKeys package) are also not conditioned on.\n\nNext, the conditions on the shocks (eps_z in this case) are defined using a SparseArrayCSC from the SparseArrays package (check get_conditional_forecast for other ways to define the conditions on the shocks):\n\nusing SparseArrays\nshocks = spzeros(1,5)\nshocks[1,5] = -1;\n\nNote that for the first 4 periods the shock has no predetermined value and is determined by the conditions on the endogenous variables.\n\nFinally the conditional forecast can be obtained:\n\nget_conditional_forecast(RBC, conditions, shocks = shocks, conditions_in_levels = false)\n\nThe function returns a KeyedArray (provided by the AxisKeys package) with the values of the endogenous variables and shocks matching the conditions exactly.\n\nThe conditional forecast can also be plotted. Note that the StatsPlots package needs to be imported once before the first plot. In order to plot this can be used:\n\nplot_conditional_forecast(RBC, conditions, shocks = shocks, conditions_in_levels = false)\n\n(Image: RBC conditional forecast)\n\nand conditions_in_levels = false needs to be set since the conditions are defined in deviations.\n\nNote that the stars indicate the values the model is conditioned on.","category":"section"},{"location":"plot_conditional_forecast/#Conditional-Forecasting","page":"Conditional Forecasts","title":"Conditional Forecasting","text":"Conditional forecasting allows generating model projections conditional on future paths for endogenous variables or exogenous shocks. The conditions are fulfilled by contemporaneous shocks only and there is no effect today from conditions in the future. The plot_conditional_forecast function visualizes these conditional forecasts, showing how the model variables evolve.\n\nFirst, define and load a model:\n\n@model Gali_2015_chapter_3_nonlinear begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0])\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_nonlinear begin\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\nend\n\nCalling plot_conditional_forecast requires specifying conditions on endogenous variables. For example, conditioning on Y = 1.0 in the first period can be implemented as follows:\n\nconditions = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                Variables = [:Y], \n                Periods = [1])\nconditions[1,1] = 1.0\n\nGiven the model and conditions the conditional forecast can be plotted as follows:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,  \n                            conditions)\n\n(Image: Gali 2015 conditional forecast)\n\nThe function plots the paths of each endogenous variable conditional on fulfilling the specified conditions. If there was a condition provided for a variable it is represented by a marker (also indicated in the legend below the subplots). The title of the overall plot indicates the model name, and page number (if multiple pages are needed) and the title of each subplot indicates the variable name.","category":"section"},{"location":"plot_conditional_forecast/#Combine-or-compare-conditional-forecasts-with-plot_conditional_forecast!","page":"Conditional Forecasts","title":"Combine or compare conditional forecasts with plot_conditional_forecast!","text":"The plot_conditional_forecast! function (note the exclamation mark !) adds additional conditional forecasts to an existing plot created with plot_conditional_forecast, enabling direct comparison between different scenarios. Any input argument that affects the model's output (such as conditions, shocks, solution algorithm, parameter values, or initial states) can be varied to compare how these changes influence the conditional forecasts. See the respective subsections below (e.g., Conditions, Shocks, Solution Algorithm, Parameter Values) for details on specific arguments.\n\nWhen using plot_conditional_forecast!, the new conditional forecast can be either overlaid for comparison (default) or stacked to show cumulative effects, depending on the plot_type argument (see Plot Type). Condition markers adopt the corresponding line color for easy identification.\n\nLegend and table behavior:\n\nWhen inputs differ in one dimension (e.g., only the algorithm changes), the legend displays the value of that input dimension for each line (e.g., :first_order, :second_order).\nWhen inputs differ in multiple dimensions (e.g., both conditions and parameters change), the legend shows sequential numbers (1, 2, 3, ...) with a running ID to reference different sets of conditions and inputs. A table below the plot details all input differences for each numbered scenario.\nAdditional tables below show the relevant steady state values for each scenario to help identify differences across solution methods or parameter values.\n\nExample with single input difference:\n\nWhen only one input differs (e.g., parameter values), the legend shows the parameter values directly:\n\n# Set up conditions\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                    Variables = [:Y], \n                    Periods = 1:1)\nconditions_ka[1,1] = 1.0\n\n# Plot conditional forecast with baseline parameters\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = :β => 0.99)\n\n# Add conditional forecast with different discount factor\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                          conditions_ka,\n                          parameters = :β => 0.95)\n\n(Image: Gali 2015 conditional forecast - comparing β values)\n\nThe legend will display the β values (0.99 and 0.95) to identify each forecast.\n\nThe subplot y-axis labels change depending on the steady state values for each scenario. If the steady state values differ for a variable across scenarios, the y-axis label will indicate that the lines are in absolute deviations from the steady state. In that case no percent deviation is shown on the secondary y-axis, as the steady state values differ. In case the steady state values are the same across scenarios, the y-axis label indicates absolute levels on the primary y-axis and if the values are strictly positive the secondary y-axis shows the percent deviation scale.\n\nExample with multiple input differences:\n\nWhen multiple inputs differ (e.g., both algorithm and parameters), the legend shows sequential numbers and a table details the differences:\n\n# Plot with baseline settings\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = :β => 0.99)\n\n# Add with different algorithm AND parameters\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                          conditions_ka,\n                          parameters = :β => 0.95,\n                          algorithm = :second_order)\n\n(Image: Gali 2015 conditional forecast - comparing β values across algorithms)\n\nThe legend will show 1 and 2, with a table below the plot listing the parameter and algorithm values for each scenario.","category":"section"},{"location":"plot_conditional_forecast/#Conditions-(Required)","page":"Conditional Forecasts","title":"Conditions (Required)","text":"The conditions argument [Type: Union{Matrix{Union{Nothing,Float64}}, SparseMatrixCSC{Float64}, KeyedArray{Union{Nothing,Float64}}, KeyedArray{Float64}}] defines conditions for which to find the corresponding shocks. The input can have multiple formats, but for all types of entries the first dimension corresponds to variables and the second dimension to the number of periods. The conditions can be specified using a matrix of type Matrix{Union{Nothing,Float64}}. In this case the conditions are matrix elements of type Float64 and all remaining (free) entries are nothing.\n\nThe number of endogenous variables can be retrieved as follows:\n\nget_variables(Gali_2015_chapter_3_nonlinear)\n# 23-element Vector{String}:\n#  \"A\"\n#  \"C\"\n#  \"MC\"\n#  \"M_real\"\n#  \"N\"\n#  \"Pi\"\n#  \"Pi_star\"\n#  \"Q\"\n#  \"R\"\n#  \"S\"\n#  \"W_real\"\n#  \"Y\"\n#  \"Z\"\n#  \"i_ann\"\n#  \"log_N\"\n#  \"log_W_real\"\n#  \"log_y\"\n#  \"nu\"\n#  \"pi_ann\"\n#  \"r_real_ann\"\n#  \"realinterest\"\n#  \"x_aux_1\"\n#  \"x_aux_2\"\n\nConditioning Y for 8 periods on a given path means setting the elements in the 12th row:\n\nconditions = Matrix{Union{Nothing,Float64}}(undef,23,8)\nconditions[12,1] = 1.0\nconditions[12,2] = 1.1\nconditions[12,3] = 1.2\nconditions[12,4] = 1.3\nconditions[12,5] = 1.4\nconditions[12,6] = 1.5\nconditions[12,7] = 1.6\nconditions[12,8] = 1.7\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,  \n                            conditions)\n\n(Image: Gali 2015 conditional forecast 10 periods)\n\nThe plot shows the conditional paths and the specified conditions. The last page displays the shocks used to enforce these paths. Because there is a single condition per period and three available shocks, the combination of the three shocks with the smallest magnitudes is selected.\n\n(Image: Gali 2015 conditional forecast 10 periods)\n\nA SparseMatrixCSC{Float64} can also be used as input. In this case only non-zero elements are taken as conditions. Note that conditioning variables to be zero using a SparseMatrixCSC{Float64} as input is not possible (use other input formats to do so). The conditions in this example also include restrictions for the variable R = 1.0 (second element) in period 9:\n\nconditions_sp = spzeros(23,8)\nconditions_sp[12,1] = 1.0\nconditions_sp[12,2] = 1.1\nconditions_sp[12,3] = 1.2\nconditions_sp[12,4] = 1.3\nconditions_sp[12,5] = 1.4\nconditions_sp[12,6] = 1.5\nconditions_sp[12,7] = 1.6\nconditions_sp[12,8] = 1.7\n\nconditions_sp[9,8] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,  \n                            conditions_sp)\n\n(Image: Gali 2015 conditional forecast sparse matrix input)\n\nThe paths on both variables are enforced and in the 8th period the paths of the endogenous variables and shocks differ to the previous example.\n\nThis becomes even clearer by overlaying the two conditional forecasts with their different conditions:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,  \n                            conditions)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,  \n                            conditions_sp)\n\n(Image: Gali 2015 conditional forecast overlay)\n\nThe differences between the two become now clearly visible. Note that there are only 6 subplots per plot and at the bottom the legend now features the two set of conditions using a running ID to reference them, and the marker for the conditions also takes on the color of the line.\n\nAnother possibility to input conditions is by using a KeyedArray. The KeyedArray type is provided by the AxisKeys package. A KeyedArray{Union{Nothing,Float64}} can be used where, similar to Matrix{Union{Nothing,Float64}}, all entries of type Float64 are recognised as conditions and all other entries have to be nothing. Furthermore, in the primary axis a subset of variables (of type Symbol or String) for which conditions are specified can be included and all other variables are considered free. The same goes for the case when using KeyedArray{Float64}} as input, whereas in this case the conditions for the specified variables bind for all periods specified in the KeyedArray, because there are no nothing entries permitted with this type.\n\nThe benefit of using a KeyedArray is that there is no need to look up the variables. Conditioning on multiple variables in multiple periods works as follows:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka)\n\n(Image: Gali 2015 conditional forecast KeyedArray input)","category":"section"},{"location":"plot_conditional_forecast/#Shocks","page":"Conditional Forecasts","title":"Shocks","text":"The shocks argument [Default: nothing, Type: Union{Matrix{Union{Nothing,Float64}}, SparseMatrixCSC{Float64}, KeyedArray{Union{Nothing,Float64}}, KeyedArray{Float64}, Nothing}] allows the user to condition on the shocks in addition to the endogenous variables. This argument allows the user to include certain (known) shock values. By entering restrictions on the shocks in this way, the problem to match the conditions on endogenous variables is restricted to the remaining free (unknown) shocks in the respective period.\n\nThe input can have multiple formats, but for all types of entries, the first dimension corresponds to shocks and the second dimension to the number of periods. shocks can be specified using a matrix of type Matrix{Union{Nothing,Float64}}. In this case the shocks are matrix elements of type Float64 and all remaining (free) entries are nothing.\n\nGiven conditions on Y for the first 8 periods, the shocks can be restricted to fulfill these conditions by setting all but one shock to zero. The number of shocks can be retrieved as follows:\n\nget_shocks(Gali_2015_chapter_3_nonlinear)\n# 3-element Vector{String}:\n#  \"eps_a\"\n#  \"eps_nu\"\n#  \"eps_z\"\n\nSetting the shock values for the last two shocks to 0 can be done like this:\n\nshocks = Matrix{Union{Nothing,Float64}}(undef,3,8)\nshocks[2,:] .= 0\nshocks[3,:] .= 0\n\nTogether with the conditions the conditional forecast can then be plotted:\n\nconditions = Matrix{Union{Nothing,Float64}}(undef,23,8)\nconditions[12,1] = 1.0\nconditions[12,2] = 1.1\nconditions[12,3] = 1.2\nconditions[12,4] = 1.3\nconditions[12,5] = 1.4\nconditions[12,6] = 1.5\nconditions[12,7] = 1.6\nconditions[12,8] = 1.7\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions,\n                         shocks = shocks)\n\n(Image: Gali 2015 conditional forecast - shocks)\n\n(Image: Gali 2015 conditional forecast - shocks)\n\nNote the very large shock magnitudes of the first shock and the condition markers on the shocks indicating that the other two shocks were conditioned to be zero. Contrasting this with the version without the conditions of the shocks also highlights the difference in outcomes depending on which shocks can be used to enforce the conditions on the endogenous variables.\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions,\n                         shocks = shocks)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions)\n\n(Image: Gali 2015 conditional forecast - with and without shocks)\n\nThe paths clearly differ and are even directionally different due to the restriction on only the first shocks being able to fulfill the conditions on the endogenous variables.\n\nA SparseMatrixCSC{Float64} can also be used as input. In this case only non-zero elements are taken as certain shock values. Note that conditioning shocks to be zero using a SparseMatrixCSC{Float64} as input is not possible (use other input formats to do so).\n\nUsing the previous example for the conditions on multiple variables across multiple periods, the same can be done for the shocks:\n\nshocks_sp = spzeros(3,3)\nshocks_sp[1,1] = 0.1\nshocks_sp[2,2] = 0.1\nshocks_sp[3,3] = 0.1\n\nGiven this non-zero path for the shocks, two of the three shocks remain to fulfill the conditions. There was one condition per period so that the least square solution will be selected:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         shocks = shocks_sp)\n\n(Image: Gali 2015 conditional forecast - shocks sparse input)\n\nThis mixture of known and unknown shocks, and known conditions on endogenous variables allows for substantial flexibility.\n\nAnother possibility to input known shocks is by using a KeyedArray. The KeyedArray type is provided by the AxisKeys package. A KeyedArray{Union{Nothing,Float64}} can be used where, similar to Matrix{Union{Nothing,Float64}}, all entries of type Float64 are recognised as known shocks and all other entries have to be nothing. Furthermore, in the primary axis a subset of shocks (of type Symbol or String) for which values are specified can be included and all other shocks are considered free. The same goes for the case when using KeyedArray{Float64}} as input, whereas in this case the values for the specified shocks bind for all periods specified in the KeyedArray, because there are no nothing entries permitted with this type.\n\nWorking with the same conditions the shocks can be restricted to zero using this input type. Doing so for one shock per period works as follows:\n\nshocks_ka = KeyedArray(Matrix{Float64}(undef,1,3),\n                    Variables = [:eps_a], \n                    Periods = 1:3)\nshocks_ka .= 0.0\n\nCombined with conditions on the endogenous variables the conditional forecast can be plotted:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         shocks = shocks_ka)\n\n(Image: Gali 2015 conditional forecast - shocks KeyedArray input)\n\nTo see the influence of the shocks (which is similar to conditional forecasts) compare the last two examples. One scenario has non zero shocks and the other zero shocks they condition on:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         shocks = shocks_ka)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         shocks = shocks_sp)\n\n(Image: Gali 2015 conditional forecast - shocks KeyedArray input)","category":"section"},{"location":"plot_conditional_forecast/#Solution-Algorithm","page":"Conditional Forecasts","title":"Solution Algorithm","text":"Conditional forecasts can be plotted using different solution algorithms. The following example uses a second-order perturbation solution:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         algorithm = :second_order)\n\n(Image: Gali 2015 conditional forecast - second order)\n\nThe most notable difference is that at second order, dynamics are observed for S, which remains constant at first order (under certainty equivalence). Additionally, the steady state levels change because the stochastic steady state incorporates precautionary behavior (see horizontal lines). This has consequences for the conditions as they are in levels.\n\nTo compare the two solution methods side by side, use plot_conditional_forecast! to add to an existing plot:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         algorithm = :second_order)\n\n(Image: Gali 2015 conditional forecast - first and second order)\n\nThe plots now show both solution methods overlaid. The first-order solution is shown in blue, the second-order solution in orange, as indicated in the legend below the plot. Note that the steady state levels can be different for the two solution methods. For variables where the relevant steady state is the same for both methods (e.g., S), the level appears on the left axis and percentage deviations on the right axis. For variables where the steady state differs between methods (e.g., R), only absolute level deviations (abs. Δ) appear on the left axis. The relevant steady state levels are shown in a table below the plot for reference (rounded to help identify differences). The relevant steady state also implies that the conditions vary in terms of distance to steady state and thereby in the shocks they require for them to be fulfilled. For the variable Y the conditions given a first order solution imply a lower absolute deviation from the relevant steady state than for the second order solution.\n\nAdditional solution methods can be added to the same plot:\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         algorithm = :pruned_third_order)\n\n(Image: Gali 2015 conditional forecast - multiple orders)\n\nNote that the pruned third-order solution incorporates time-varying risk and the dynamics differ relative to lower order solutions. The additional solution appears as another colored line with corresponding entries in both the legend and the steady state table below.","category":"section"},{"location":"plot_conditional_forecast/#Initial-State","page":"Conditional Forecasts","title":"Initial State","text":"The initial_state argument (default: [0.0], type: Union{Vector{Vector{Float64}},Vector{Float64}}) defines the starting point for the model. For pruned solution algorithms, the initial state can be provided as multiple state vectors (Vector{Vector{Float64}}). In this case, the initial state must be specified in deviations from the non-stochastic steady state. For all other cases, specify the initial state in levels. For pruned solution algorithms with a Vector{Float64} initial state, only the first-order initial state vector is affected. The initial state defines the starting point for the conditional forecast and must contain all model variables, including any leads or lags. To obtain the correct ordering and number of variables, call get_irf(𝓂, shocks = :none, variables = :all, periods = 1), which returns a KeyedArray with all variables in the correct order. The KeyedArray type is provided by the AxisKeys package. For example:\n\ninit_state = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true)\n\nOnly state variables will have an impact on the conditional forecast. To check which variables are state variables:\n\nget_state_variables(Gali_2015_chapter_3_nonlinear)\n# 4-element Vector{String}:\n#  \"A\"\n#  \"S\"\n#  \"Z\"\n#  \"nu\"\n\nNow modify the initial state and set nu to 0.1:\n\ninit_state(:nu,:,:) .= 0.1\n\nThe modified initial state can now be input into the plot_conditional_forecast function as a Vector. Furthermore, in the following example the conditions are shifted 10 periods into the future:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,13),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:13)\nconditions_ka[1,11] = 1.0\nconditions_ka[2,12] = 1.0\nconditions_ka[3,13] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         initial_state = vec(init_state))\n\n(Image: Gali 2015 conditional forecast - custom initial state)\n\nNote how the initial state drives the dynamics until the conditions come in after period 10.\n\nFor pruned solution methods the initial state can also be given as multiple state vectors (Vector{Vector{Float64}}). When providing a vector of vectors, values must be specified as differences from the non-stochastic steady state. When providing only one vector, values must be in levels, with the initial state having its full nonlinear effect in the first period. Using a vector of vectors allows setting the pruned higher-order auxiliary state vectors. While this can be useful in some cases, note that these higher-order auxiliary state vectors have only a linear impact in the first period. Start by assembling the vector of vectors:\n\ninit_state_pruned_3rd_in_diff = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true) - get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    algorithm = :pruned_third_order,\n    levels = true)\n# 3-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n# ↓   Variables ∈ 23-element Vector{Symbol}\n# →   Periods ∈ 1-element UnitRange{Int64}\n# ◪   Shocks ∈ 1-element Vector{Symbol}\n# And data, 23×1×1 Array{Float64, 3}:\n# [:, :, 1] ~ (:, :, :none):\n#                    (1)\n#   (:A)               0.0\n#   (:C)               0.01899564383140051\n#   (:MC)              0.26061783703451824\n#   (:M_real)          0.014844948179111417\n#   (:N)               0.0256329467464953\n#   (:Pi)             -0.0013592503942323475\n#   (:Pi_star)        -0.0040777511826968205\n#   (:Q)              -0.00023912532361458627\n#   (:R)               0.0002649588073291298\n#   (:S)               3.3306690738754696e-16\n#   (:W_real)          0.18508712654020898\n#   (:Y)               0.01899564383140051\n#   (:Z)               0.0\n#   (:i_ann)           0.0010068434678508487\n#   (:log_N)           0.024432922221986165\n#   (:log_W_real)      0.1404893027764202\n#   (:log_y)           0.018324691666489368\n#   (:nu)             -1.3404049553225972e-17\n#   (:pi_ann)         -0.005437001576929203\n#   (:r_real_ann)      0.008306969164175088\n#   (:realinterest)    0.002186044516888197\n#   (:x_aux_1)        -0.7618262640813329\n#   (:x_aux_2)        -0.371793344047362\n\nFirst- and third-order dynamics don't affect the steady state through risk, so they are zero. The second-order steady state includes the risk adjustment. Assemble the vectors for the third order case:\n\ninit_states_pruned_3rd_vec = [\n    zero(vec(init_state_pruned_3rd_in_diff)),\n    vec(init_state_pruned_3rd_in_diff),\n    zero(vec(init_state_pruned_3rd_in_diff)),\n]\n\nThen set nu to 0.1 in the first order terms. Inspecting init_state_pruned_3rd_in_diff shows that nu is the 18th variable in the vector:\n\ninit_states_pruned_3rd_vec[1][18] = 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         initial_state = init_states_pruned_3rd_vec,\n                         algorithm = :pruned_third_order)\n\n(Image: Gali 2015 conditional forecast - pruned 3rd order initial state vector)\n\nAlternatively, a simple vector can be used for the initial state. In this case the values must be in levels and the impact of the initial state is assumed to have the full nonlinear effect in the first period:\n\ninit_state_pruned_3rd = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true,\n    algorithm = :pruned_third_order)\n\ninit_state_pruned_3rd(:nu, :,  :) .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         initial_state = vec(init_state_pruned_3rd),\n                         algorithm = :pruned_third_order)\n\nCompare this with the first-order versions, each starting from their respective steady states.\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         initial_state = vec(init_state))\n\n(Image: Gali 2015 conditional forecast - initial state (first and pruned third order))\n\nThis shows that the pruned third-order solution changes the dynamics due to the nonlinear solution and it's effect on the absolute difference between the steady state and the conditions on endogenous variables.","category":"section"},{"location":"plot_conditional_forecast/#Simulation-Periods","page":"Conditional Forecasts","title":"Simulation Periods","text":"The periods argument (default: 40, type: Int) specifies the number of periods after the end of the conditions for which to calculate the output. When a matrix of shocks is provided, the last period for which a shock or shock condition is provided is considered. To set the number of periods to 10:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,13),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:13)\nconditions_ka[1,11] = 1.0\nconditions_ka[2,12] = 1.0\nconditions_ka[3,13] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         periods = 10)\n\n(Image: Gali 2015 conditional forecast - 10 periods)\n\nThe x-axis automatically adjusts to show only 23 periods as this corresponds to the last period with a condition plus the 10 periods defined in the argument.\n\nThe following example uses a shock matrix with the last input in period 20, sets the periods argument to 30, and compares it to the previous 10-period plot:\n\nshocks_ka = KeyedArray(Matrix{Float64}(undef,1,20),\n                Variables = [:eps_a], \n                Periods = 1:20)\nshocks_ka .= 0.0\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         shocks = shocks_ka,\n                         periods = 30)\n\n(Image: Gali 2015 conditional forecast - mixed period lengths)\n\nThe x-axis adjusts to 50 periods, with the first plot ending after 23 periods and the second plot ending after 50 periods. The legend indicates which color corresponds to which combination of shocks and periods.","category":"section"},{"location":"plot_conditional_forecast/#Variables-to-Plot","page":"Conditional Forecasts","title":"Variables to Plot","text":"The variables argument (default: :all_excluding_obc) specifies for which variables to show results. Variable names can be specified as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc includes all variables except auxiliary variables and those related to occasionally binding constraints (OBC). :all_excluding_obc includes all variables except those related to occasionally binding constraints. :all includes all variables.\n\nSpecific variables can be selected to plot. The following example selects only output (Y) and inflation (Pi) using a Vector of Symbols:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = [:Y, :Pi])\n\n(Image: Gali 2015 conditional forecast - selected variables (Y, Pi))\n\nThe plot now displays the two selected variables (sorted alphabetically) and the plots enforcing the conditions on endogenous variables. The other two variables for which conditions were provided are not shown.\n\nThe same can be done using a Tuple:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = (:Y, :Pi))\n\na Matrix:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = [:Y :Pi])\n\nor providing the variable names as Strings:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = [\"Y\", \"Pi\"])\n\nor a single variable as a Symbol:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = :Y)\n\nor as a String:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = \"Y\")\n\nThen there are some predefined options:\n\n:all_excluding_auxiliary_and_obc (default) plots all variables except auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = :all_excluding_auxiliary_and_obc)\n\n:all_excluding_obc plots all variables except those used to enforce occasionally binding constraints (OBC).\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         variables = :all_excluding_obc)\n\nTo see auxiliary variables, use a model that defines them. The FS2000 model can be used:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nSince both c and P appear in t+2, they generate auxiliary variables in the model. Plotting the conditional forecast for all variables excluding OBC-related ones means auxiliary variables are shown:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:P, :R, :c], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(FS2000,\n                         conditions_ka,\n                         variables = :all_excluding_obc)\n\n(Image: FS2000 conditional forecast - e_a shock with auxiliary variables)\n\nBoth c and P appear twice: once as the variable itself and once as an auxiliary variable with the ᴸ⁽¹⁾ superscript, representing the value of the variable in t+1 as expected in t.\n\n:all plots all variables including auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nUse the Gali_2015_chapter_3 model with an effective lower bound (note the use of the max function in the Taylor rule):\n\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\n    R > 1.0001\nend\n\nPlotting the conditional forecast for all variables including OBC-related ones reveals the OBC-related auxiliary variables:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:C, :R, :Y], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_obc,\n                         conditions_ka,\n                         variables = :all)\n\n(Image: Gali 2015 OBC conditional forecast - with OBC variables)\n\nThe OBC-related variables appear in the last subplot, but note that OBCs are ignored with conditional forecasting.","category":"section"},{"location":"plot_conditional_forecast/#Parameter-Values","page":"Conditional Forecasts","title":"Parameter Values","text":"When no parameters are provided, the solution uses the previously defined parameter values. Parameters can be provided as a Vector of values, or as a Vector or Tuple of Pairs mapping parameter Symbols or Strings to values. The solution is recalculated when new parameter values differ from the previous ones.\n\nStart by changing the discount factor β from 0.99 to 0.95:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = :β => 0.95)\n\n(Image: Gali 2015 conditional forecast - `β = 0.95`)\n\nThe steady states and dynamics changed as a result of changing the discount factor, also because the absolute deviation of the conditons on the endogenous variables from the relevant steady state changed. To better visualize the differences between β = 0.99 and β = 0.95, the two conditional forecasts can be overlaid (compared). Since parameter changes are permanent, first reset β = 0.99 before overlaying the conditional forecast with β = 0.95 on top of it:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = :β => 0.99)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = :β => 0.95)\n\n(Image: Gali 2015 conditional forecast - comparing β values)\n\nThe legend below the plot indicates which color corresponds to which β value, with the table underneath showing the relevant steady states. Note that both the steady states and dynamics differ across the two β values, even when the steady state remains the same (e.g., for Y).\n\nMultiple parameters can also be changed simultaneously to compare the results to previous plots. This example changes β to 0.97 and τ to 0.5 using a Tuple of Pairs and define the variables with Symbols:\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = (:β => 0.97, :τ => 0.5))\n\n(Image: Gali 2015 conditional forecast - multiple parameter changes)\n\nSince the plot function calls now differ in multiple input arguments, the legend indicates which color corresponds to which input combination, with the table showing steady states for all three combinations. The change in steady state for the latest change means substantially different absolute differences relevant for the conditions and therefore also different size of shocks to enforce the conditions.\n\nA Vector of Pairs can also be used:\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = [:β => 0.98, :τ => 0.25])\n\nAlternatively, use a Vector of parameter values in the order they were defined in the model. To obtain them:\n\nparams = get_parameters(Gali_2015_chapter_3_nonlinear, values = true)\n# 16-element Vector{Pair{String, Float64}}:\n#       \"σ\" => 1.0\n#       \"φ\" => 5.0\n#     \"ϕᵖⁱ\" => 1.5\n#      \"ϕʸ\" => 0.125\n#       \"θ\" => 0.75\n#     \"ρ_ν\" => 0.5\n#     \"ρ_z\" => 0.5\n#     \"ρ_a\" => 0.9\n#       \"β\" => 0.95\n#       \"η\" => 3.77\n#       \"α\" => 0.25\n#       \"ϵ\" => 9.0\n#       \"τ\" => 0.5\n#   \"std_a\" => 0.01\n#   \"std_z\" => 0.05\n#  \"std_nu\" => 0.0025\n\nparam_vals = [p[2] for p in params]\n# 16-element Vector{Float64}:\n#  1.0\n#  5.0\n#  1.5\n#  0.125\n#  0.75\n#  0.5\n#  0.5\n#  0.9\n#  0.95\n#  3.77\n#  0.25\n#  9.0\n#  0.5\n#  0.01\n#  0.05\n#  0.0025\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka,\n                         parameters = param_vals)","category":"section"},{"location":"plot_conditional_forecast/#Conditions-in-levels","page":"Conditional Forecasts","title":"Conditions in levels","text":"Conditions are assumed to be in levels by default. They can also be provided in differences to the relevant steady state (non-stochastic or stochastic steady state).\n\nStarting with conditions in levels:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                    Variables = [:Y], \n                    Periods = 1:1)\nconditions_ka[1,1] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_ka)\n\nMoving to defining conditions in absolute deviation from the relevant steady state:\n\nconditions_in_dev_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                            Variables = [:Y], \n                            Periods = 1:1)\nconditions_in_dev_ka[1,1] = -0.05\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                         conditions_in_dev_ka,\n                         conditions_in_levels = false)\n\n(Image: Gali 2015 conditional forecast - conditions not in levels)\n\nThe same works for higher order solutions, where then the conditions are interpreted as in difference to the stochastic steady state. The influence of risk and the nonlinear solution can be seen by overlaying the second order solution on top of the first order solution:\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n                         conditions_in_dev_ka,\n                         conditions_in_levels = false,\n                         algorithm = :second_order)\n\n(Image: Gali 2015 conditional forecast - conditions not in levels (1st and 2nd order))","category":"section"},{"location":"plot_conditional_forecast/#Plot-Labels","page":"Conditional Forecasts","title":"Plot Labels","text":"The label argument (type: Union{String,Symbol,Real}) controls labels that appear in plots when using the plot_conditional_forecast! function to overlay multiple conditional forecasts. By default, labels take on the values of the one dimensional input that differs and are sequential numbers in case the input differs along more than one dimension. Furthermore, custom labels can be provided using this argument. Acceptable inputs are a String, Symbol, or a Real.\n\nCustom labels are particularly useful when inputs differ in complex ways (e.g., shock matrices or multiple input changes). For example, let's compare the conditional forecast of the Gali_2015_chapter_3_nonlinear model for a 1 standard deviation eps_a shock with β = 0.99 and τ = 0 to the conditional forecast with β = 0.95 and τ = 0.5 using custom labels String input:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                    Variables = [:Y], \n                    Periods = 1:1)\nconditions_ka[1,1] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.99, :τ => 0.0),\n    label = \"Std. params\")\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.95, :τ => 0.5),\n    label = \"Alt. params\")\n\n(Image: Gali 2015 conditional forecast - custom labels)\n\nThe legend now displays the custom label names instead of sequential numbers (1 and 2). Additionally, the tables showing input differences and steady states use the custom labels in the first column instead of sequential numbers.\n\nThe same result can be achieved using Symbols (though they are less expressive):\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.99, :τ => 0.0),\n    label = :standard)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.95, :τ => 0.5),\n    label = :alternative)\n\nor with Real inputs:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.99, :τ => 0.0),\n    label = 0.99)\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = (:β => 0.95, :τ => 0.5),\n    label = 0.95)","category":"section"},{"location":"plot_conditional_forecast/#Plot-Type","page":"Conditional Forecasts","title":"Plot Type","text":"The plot_type argument (default: :compare, type: Symbol) determines how conditional forecasts are visualized when multiple scenarios are displayed. Two options are available:\n\n:compare - Displays conditional forecasts as separate lines for comparison across scenarios\n:stack - Stacks conditional forecasts on top of each other to show cumulative effects\n\nThe :stack option is particularly useful when analyzing scenarios composed of differnt conditions or shock inputs. The :compare option is better suited for comparing conditional forecasts across different parameter values or model specifications.","category":"section"},{"location":"plot_conditional_forecast/#Using-:stack-to-layer-scenarios","page":"Conditional Forecasts","title":"Using :stack to layer scenarios","text":"When analyzing a scenario composed of different conditions or shocks, :stack visualizes the cumulative impact. For example, plot two conditions on endogenous variables:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false)\n\nconditions_ka2 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,2,10),\n                    Variables = [:Y,:R], \n                    Periods = 1:10)\nconditions_ka2[1,:] .= -0.1\nconditions_ka2[2,:] .= 0.0\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka2,\n    conditions_in_levels = false,\n    plot_type = :stack)\n\n(Image: Gali 2015 conditional forecast - stacked)\n\nThe :stack visualization shows how each condition contributes to the combined path, with the second condition's effect layered on top of the first, and the solid black line representing the total effect.","category":"section"},{"location":"plot_conditional_forecast/#Using-:compare-for-scenario-comparisons","page":"Conditional Forecasts","title":"Using :compare for scenario comparisons","text":"When comparing conditional forecasts across different scenarios, :compare displays the paths as separate lines:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),\n                    Variables = [:R], \n                    Periods = 1:1)\nconditions_ka .= 1.0\n\n# Baseline parameterization\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = :β => 0.99)\n\n# Alternative parameterization for comparison\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = :β => 0.95,\n    plot_type = :compare)\n\n(Image: Gali 2015 conditional forecast - comparing β values)\n\nThe :compare option (the default) makes it easy to see how parameter changes affect the conditional forecast for the same conditions on endogenous variables.","category":"section"},{"location":"plot_conditional_forecast/#Plot-Attributes","page":"Conditional Forecasts","title":"Plot Attributes","text":"The plot_attributes argument (default: Dict(), type: Dict) accepts a dictionary of attributes passed on to the plotting function. See the Plots.jl documentation for details.\n\nThe color palette can be customized using the plot_attributes argument. The following example defines a custom color palette (inspired by the European Commission's economic reports) to plot and stack multiple conditional forecasts for the Gali_2015_chapter_3_nonlinear model. First, define the custom color palette using hex color codes:\n\nec_color_palette =\n[\n    \"#FFD724\",  # \"Sunflower Yellow\"\n    \"#353B73\",  # \"Navy Blue\"\n    \"#2F9AFB\",  # \"Sky Blue\"\n    \"#B8AAA2\",  # \"Taupe Grey\"\n    \"#E75118\",  # \"Vermilion\"\n    \"#6DC7A9\",  # \"Mint Green\"\n    \"#F09874\",  # \"Coral\"\n    \"#907800\"   # \"Olive\"\n]\n\nThen plot the first conditional forecast:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false)\n\nFinally, overlay another conditional forecast using the custom color palette:\n\nconditions_ka2 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,2,10),\n                    Variables = [:Y,:R], \n                    Periods = 1:10)\nconditions_ka2[1,:] .= -0.1\nconditions_ka2[2,:] .= 0.0\n\n# Add second shock to show cumulative effect\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka2,\n    conditions_in_levels = false,\n    plot_attributes = Dict(:palette => ec_color_palette),\n    plot_type = :stack)\n\n(Image: Gali 2015 conditional forecast - custom color palette)\n\nThe colors of the bars now follow the custom color palette.\n\nOther attributes such as the font family can also be modified (see here for GR font options):\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    plot_attributes = Dict(:fontfamily => \"computer modern\"))\n\n(Image: Gali 2015 conditional forecast - custom font)\n\nAll text in the plot now uses the Computer Modern font. Note that font rendering inherits the constraints of the plotting backend (GR in this case).","category":"section"},{"location":"plot_conditional_forecast/#Plots-Per-Page","page":"Conditional Forecasts","title":"Plots Per Page","text":"The plots_per_page argument (default: 9, type: Int) controls the number of subplots per page. When the number of variables exceeds this value, multiple pages are created. The following example selects 9 variables and sets plots_per_page to 2:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false,\n    variables = [:Y, :Pi, :R, :C, :N, :W_real, :MC, :i_ann, :A],\n    plots_per_page = 2)\n\n(Image: Gali 2015 conditional forecast - 2 plots per page)\n\nThe first four pages display two variables (sorted alphabetically). The title indicates the current page and the total number of pages.","category":"section"},{"location":"plot_conditional_forecast/#Display-Plots","page":"Conditional Forecasts","title":"Display Plots","text":"The show_plots argument (default: true, type: Bool), when true, displays the plots; otherwise, they are only returned as an object.\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false,\n    show_plots = false)","category":"section"},{"location":"plot_conditional_forecast/#Saving-Plots","page":"Conditional Forecasts","title":"Saving Plots","text":"The save_plots argument (default: false, type: Bool), when true, saves the plots to disk; otherwise, they are only displayed and returned as an object.\n\nRelated arguments control the saving behavior:\n\nsave_plots_format (default: :pdf, type: Symbol): output format of saved plots. See input formats compatible with GR for valid formats.\nsave_plots_path (default: \".\", type: String): path where plots are saved. If the path does not exist, it will be created automatically.\nsave_plots_name (default: \"conditional_forecast\", type: Union{String, Symbol}): prefix prepended to the filename when saving plots.\n\nEach plot is saved as a separate file with a name indicating the prefix, model name, shocks, and a sequential number for multiple plots (e.g., conditional_forecast__ModelName__1.pdf).\n\nThe following example saves all conditional forecasts for the Gali_2015_chapter_3_nonlinear model as PNG files in the ../plots directory with cond_fcst as the filename prefix:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false,\n    save_plots = true,\n    save_plots_format = :png,\n    save_plots_path = \"./../plots\",\n    save_plots_name = :cond_fcst)\n\nThe plots appear in the specified folder with the specified prefix. Each plot is saved in a separate file with a name reflecting the model, and a sequential index when the number of variables exceeds the plots per page.","category":"section"},{"location":"plot_conditional_forecast/#Variable-and-Shock-Renaming-(rename-dictionary)","page":"Conditional Forecasts","title":"Variable and Shock Renaming (rename dictionary)","text":"The rename_dictionary argument (default: Dict(), type: AbstractDict{<:Union{Symbol, String}, <:Union{Symbol, String}}) maps variable or shock symbols to custom display names in plots. This is particularly useful when comparing models with different variable naming conventions, allowing them to be displayed with consistent labels.\n\nFor example, to rename variables for clearer display:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.1\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false,\n    rename_dictionary = Dict(:Y => \"Output\", :Pi => \"Inflation\", :R => \"Interest Rate\"))\n\n(Image: Gali 2015 conditional forecast - rename dictionary)\n\nThis feature is especially valuable when overlaying conditional forecasts from different models. Consider comparing FS2000 (which uses lowercase variable names like c) with Gali_2015_chapter_3_nonlinear (which uses uppercase variable names like C). The rename_dictionary allows harmonizing these names when plotting them together:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:P, :R, :c], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.01\nconditions_ka[2,2] = 1.02\nconditions_ka[3,3] = 1.03\n\nplot_conditional_forecast(FS2000,\n                         conditions_ka,\n                         rename_dictionary = Dict(\n                            :c => \"Consumption\", \n                            :y => \"Output\", \n                            :R => \"Interest Rate\"\n                         ))\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.01\n\nplot_conditional_forecast!(Gali_2015_chapter_3_nonlinear,\n    conditions_ka1,\n    conditions_in_levels = false,\n    rename_dictionary = Dict(\n        :C => \"Consumption\", \n        :Y => \"Output\", \n        :R => \"Interest Rate\"\n        ))\n\n(Image: FS2000 and Gali 2015 conditional forecast - multiple models with rename dictionary)\n\nBoth models now appear in the plot with consistent, readable labels, making comparison straightforward.\n\nThe rename_dictionary also works with shocks. For example, Gali_2015_chapter_3_nonlinear has shocks eps_a and eps_nu, while FS2000 has e_a and e_m. To compare these with consistent labels:\n\nconditions_ka1 = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,10),\n                    Variables = [:Y], \n                    Periods = 1:10)\nconditions_ka1 .= 0.01\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n                            conditions_ka1,\n                            conditions_in_levels = false,\n                            rename_dictionary = Dict(\n                                :eps_a => \"Technology Shock\", \n                                :eps_nu => \"Monetary Policy Shock\"\n                                ))\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:P, :R, :c], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.01\nconditions_ka[2,2] = 1.02\nconditions_ka[3,3] = 1.03\n\nplot_conditional_forecast!(FS2000,\n                         conditions_ka,\n                         rename_dictionary = Dict(\n                            :e_a => \"Technology Shock\", \n                            :e_m => \"Monetary Policy Shock\"\n                            ))\n\n(Image: FS2000 and Gali 2015 conditional forecast - multiple models with shock rename dictionary)\n\nThe rename_dictionary accepts flexible type combinations for keys and values—both Symbol and String types work interchangeably:\n\n# All of these are valid and equivalent:\nDict(:Y => \"Output\")              # Symbol key, String value\nDict(\"Y\" => \"Output\")             # String key, String value\nDict(:Y => :Output)               # Symbol key, Symbol value\nDict(\"Y\" => :Output)              # String key, Symbol value\n\nThis flexibility is particularly useful for models like Backus_Kehoe_Kydland_1992, which uses String representations of variable and shock names (because of {}):\n\n# Define the Backus model (abbreviated for clarity)\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1-theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1/nu{co})\n        K{co}[0] = (1-delta{co})*K{co}[-1] + S{co}[0]\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n        A{co}[0] = (1-eta{co}) * A{co}[-1] + N{co}[0]\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1-alpha{co})*eta{co} * A{co}[-1]\n        U{co}[0] = (C{co}[0]^mu{co}*L{co}[0]^(1-mu{co}))^gamma{co}\n        psi{co} * mu{co} / C{co}[0]*U{co}[0] = LGM[0]\n        psi{co} * (1-mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1-theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co}*N{co}[0]^(1-theta{co}))^(-nu{co})*Y{co}[0]^(1+nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1-delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1-theta{co})) ^ (-nu{co})* Y{co}[+4]^(1+nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1+sigma{co} * Z{co}[0]^(-nu{co}-1)*Y{co}[+1]^(1+nu{co}))\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1]))/Y{co}[0]\n    end\n\n    (LAMBDA{H}[0]-1) = rho{H}{H}*(LAMBDA{H}[-1]-1) + rho{H}{F}*(LAMBDA{F}[-1]-1) + Z_E{H} * E{H}[x]\n    (LAMBDA{F}[0]-1) = rho{F}{F}*(LAMBDA{F}[-1]-1) + rho{F}{H}*(LAMBDA{H}[-1]-1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend\n\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,2,2),\n                    Variables = [\"C{H}\", \"C{F}\"], \n                    Periods = 1:2)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\n\nplot_conditional_forecast(Backus_Kehoe_Kydland_1992,\n    conditions_ka,\n    rename_dictionary = Dict(\"C{H}\" => \"Home Consumption\", \n                             \"C{F}\" => \"Foreign Consumption\",\n                             \"Y{H}\" => \"Home Output\",\n                             \"Y{F}\" => \"Foreign Output\"))\n\n(Image: Backus, Kehoe, Kydland 1992 conditional forecast - E{H} shock with rename dictionary)\n\nVariables or shocks not included in the dictionary retain their default names. The renaming applies to all plot elements including legends, axis labels, and tables.","category":"section"},{"location":"plot_conditional_forecast/#Verbose-Output","page":"Conditional Forecasts","title":"Verbose Output","text":"The verbose argument (default: false, type: Bool), when true, enables verbose output related to solving the model\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    verbose = true)\n\nThe code outputs information about solving the steady state blocks. When parameters change, the first-order solution is recomputed; otherwise, it uses the cached solution:\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    parameters = :β => 0.955,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.95       to 0.955\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.3825585462666584e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16","category":"section"},{"location":"plot_conditional_forecast/#Numerical-Tolerances","page":"Conditional Forecasts","title":"Numerical Tolerances","text":"The tol argument (default: Tolerances(), type: Tolerances) defines various tolerances for the algorithm used to solve the model. See the Tolerances documentation for more details: ?Tolerances. The tolerances used by the numerical solvers can be adjusted. The Tolerances object allows setting tolerances for the non-stochastic steady state solver (NSSS), Sylvester equations, Lyapunov equation, and quadratic matrix equation (QME). For example, to set tighter tolerances (this example also changes parameters to force recomputation):\n\ncustom_tol = Tolerances(qme_acceptance_tol = 1e-12,\n    sylvester_acceptance_tol = 1e-12)\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    tol = custom_tol,\n    algorithm = :second_order,\n    parameters = :β => 0.9555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.955      to 0.9555\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Sylvester equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 6.494758134185766e-17; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n\nThis is useful when higher precision is needed or when the default tolerances are insufficient for convergence. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_conditional_forecast/#Quadratic-Matrix-Equation-Solver","page":"Conditional Forecasts","title":"Quadratic Matrix Equation Solver","text":"The quadratic_matrix_equation_algorithm argument (default: :schur, type: Symbol) specifies the algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling The quadratic matrix equation solver is used internally when solving the model to first order. Different algorithms are available. The :schur algorithm is generally faster and more reliable, while :doubling can be more precise in some cases (this example also changes parameters to force recomputation):\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    quadratic_matrix_equation_algorithm = :doubling,\n    parameters = :β => 0.95555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.9555     to 0.95555\n# New parameters changed the steady state.\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver: doubling - converged: true in 8 iterations to tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor most use cases, the default :schur algorithm is recommended. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_conditional_forecast/#Sylvester-Equation-Solver","page":"Conditional Forecasts","title":"Sylvester Equation Solver","text":"[Default: selector that uses :doubling for smaller problems and switches to :bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: Algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. The input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solution's Sylvester equation. When only one element is provided, it corresponds to the second-order perturbation solution's Sylvester equation. The algorithm to use can be specified for solving Sylvester equations in higher-order solutions. For example, select the :bartels_stewart algorithm for solving the second-order perturbation problem:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    algorithm = :second_order,\n    sylvester_algorithm = :bartels_stewart,\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: -1; reached tol: 6.19336731775721e-17; algorithm: bartels_stewart\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor third-order solutions, different algorithms can be specified for the second- and third-order Sylvester equations using a Tuple:\n\nconditions_ka = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,3,3),\n                    Variables = [:R, :Y, :MC], \n                    Periods = 1:3)\nconditions_ka[1,1] = 1.0\nconditions_ka[2,2] = 1.0\nconditions_ka[3,3] = 1.0\n\nplot_conditional_forecast(Gali_2015_chapter_3_nonlinear,\n    conditions_ka,\n    algorithm = :third_order,\n    sylvester_algorithm = (:doubling, :bicgstab),\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: 23; reached tol: 8.328904812714592e-17; algorithm: bicgstab\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nThe choice of algorithm affects both speed and precision: :doubling and :bartels_stewart are generally faster, while :bicgstab, :dqgmres, and :gmres are better for large sparse problems. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"call_index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"api/#MacroModelling.SS","page":"API","title":"MacroModelling.SS","text":"See get_steady_state\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.SSS-Tuple","page":"API","title":"MacroModelling.SSS","text":"Wrapper for get_steady_state with stochastic = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.autocorr","page":"API","title":"MacroModelling.autocorr","text":"See get_autocorrelation\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.check_residuals","page":"API","title":"MacroModelling.check_residuals","text":"See get_non_stochastic_steady_state_residuals\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.corr","page":"API","title":"MacroModelling.corr","text":"See get_correlation\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.cov","page":"API","title":"MacroModelling.cov","text":"Wrapper for get_moments with covariance = true and non_stochastic_steady_state = false, variance = false, standard_deviation = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.export_dynare","page":"API","title":"MacroModelling.export_dynare","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.export_mod_file","page":"API","title":"MacroModelling.export_mod_file","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.export_model","page":"API","title":"MacroModelling.export_model","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.export_to_dynare","page":"API","title":"MacroModelling.export_to_dynare","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.fevd","page":"API","title":"MacroModelling.fevd","text":"See get_conditional_variance_decomposition\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_IRF","page":"API","title":"MacroModelling.get_IRF","text":"See get_irf\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_SS","page":"API","title":"MacroModelling.get_SS","text":"See get_steady_state\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_SSS-Tuple","page":"API","title":"MacroModelling.get_SSS","text":"Wrapper for get_steady_state with stochastic = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_autocorr","page":"API","title":"MacroModelling.get_autocorr","text":"See get_autocorrelation\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_autocorrelation-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_autocorrelation","text":"get_autocorrelation(\n    𝓂;\n    autocorrelation_periods,\n    parameters,\n    algorithm,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm,\n    verbose,\n    tol\n)\n\n\nReturn the autocorrelations of endogenous variables using the first, pruned second, or pruned third order perturbation solution. \n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nautocorrelation_periods [Default: 1:5, Type: UnitRange{Int}]: periods for which to return the autocorrelation\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows and autocorrelation periods in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_autocorrelation(RBC)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Autocorrelation_periods ∈ 5-element UnitRange{Int64}\nAnd data, 4×5 Matrix{Float64}:\n        (1)         (2)         (3)         (4)         (5)\n  (:c)    0.966974    0.927263    0.887643    0.849409    0.812761\n  (:k)    0.971015    0.931937    0.892277    0.853876    0.817041\n  (:q)    0.32237     0.181562    0.148347    0.136867    0.129944\n  (:z)    0.2         0.04        0.008       0.0016      0.00032\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_calibrated_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_calibrated_parameters","text":"get_calibrated_parameters(𝓂; values)\n\n\nReturns the parameters (and optionally the values) which are determined by a calibration equation. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nvalues [Default: false, Type: Bool]: return the values together with the parameter names.\n\nReturns\n\nVector{String} of the calibrated parameters or Vector{Pair{String, Float64}} of the calibrated parameters and values if values is set to true.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_calibrated_parameters(RBC)\n# output\n1-element Vector{String}:\n \"δ\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_calibration_equation_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_calibration_equation_parameters","text":"get_calibration_equation_parameters(𝓂)\n\n\nReturns the parameters used in calibration equations which are not used in the equations of the model (see capital_to_output in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_calibration_equation_parameters(RBC)\n# output\n1-element Vector{String}:\n \"capital_to_output\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_calibration_equations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_calibration_equations","text":"get_calibration_equations(𝓂)\n\n\nReturn the calibration equations declared in the @parameters block. Calibration equations are additional equations which are part of the non-stochastic steady state problem. The additional equation is matched with a calibated parameter which is part of the equations declared in the @model block and can be retrieved with: get_calibrated_parameters\n\nIn case programmatic model writing was used this function returns the parsed equations (see loop over shocks in example).\n\nNote that the output assumes the equations are equal to 0. As in, k / (q * 4) - capital_to_output implies k / (q * 4) - capital_to_output = 0 and therefore: k / (q * 4) = capital_to_output.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the calibration equations. \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_calibration_equations(RBC)\n# output\n1-element Vector{String}:\n \"k / (q * 4) - capital_to_output\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_conditional_forecast-Tuple{MacroModelling.ℳ, Union{KeyedArray{Union{Nothing, Float64}}, KeyedArray{Float64}, SparseArrays.SparseMatrixCSC{Float64}, Matrix{Union{Nothing, Float64}}}}","page":"API","title":"MacroModelling.get_conditional_forecast","text":"get_conditional_forecast(\n    𝓂,\n    conditions;\n    shocks,\n    initial_state,\n    periods,\n    parameters,\n    variables,\n    conditions_in_levels,\n    algorithm,\n    levels,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the conditional forecast given restrictions on endogenous variables and shocks (optional). By default, the values represent absolute deviations from the relevant steady state (see levels for details). The non-stochastic steady state (NSSS) is relevant for first order solutions and the stochastic steady state for higher order solutions. A constrained minimisation problem is solved to find the combination of shocks with the smallest squared magnitude fulfilling the conditions.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\nconditions [Type: Union{Matrix{Union{Nothing,Float64}}, SparseMatrixCSC{Float64}, KeyedArray{Union{Nothing,Float64}}, KeyedArray{Float64}}]: conditions for which to find the corresponding shocks. The input can have multiple formats, but for all types of entries, the first dimension corresponds to variables and the second dimension to the number of periods. The conditions can be specified using a matrix of type Matrix{Union{Nothing,Float64}}. In this case the conditions are matrix elements of type Float64 and all remaining (free) entries are nothing. A SparseMatrixCSC{Float64} can also be used as input. In this case only non-zero elements are taken as conditions. Note that conditioning variables to be zero using a SparseMatrixCSC{Float64} as input is not possible (use other input formats to do so). Another possibility to input conditions is by using a KeyedArray. The KeyedArray type is provided by the AxisKeys package. A KeyedArray{Union{Nothing,Float64}} can be used where, similar to Matrix{Union{Nothing,Float64}}, all entries of type Float64 are recognised as conditions and all other entries have to be nothing. Furthermore, in the primary axis a subset of variables (of type Symbol or String) for which conditions are specified can be included and all other variables are considered free. The same goes for the case when using KeyedArray{Float64}} as input, whereas in this case the conditions for the specified variables bind for all periods specified in the KeyedArray, because there are no nothing entries permitted with this type.\n\nKeyword Arguments\n\nshocks [Default: nothing, Type: Union{Matrix{Union{Nothing,Float64}}, SparseMatrixCSC{Float64}, KeyedArray{Union{Nothing,Float64}}, KeyedArray{Float64}, Nothing}]: known values of shocks. This argument allows including certain shock values. By entering restrictions on the shocks in this way the problem to match the conditions on endogenous variables is restricted to the remaining free shocks in the respective period. The input can have multiple formats, but for all types of entries, the first dimension corresponds to shocks and the second dimension to the number of periods. shocks can be specified using a matrix of type Matrix{Union{Nothing,Float64}}. In this case the shocks are matrix elements of type Float64 and all remaining (free) entries are nothing. A SparseMatrixCSC{Float64} can also be used as input. In this case only non-zero elements are taken as certain shock values. Note that conditioning shocks to be zero using a SparseMatrixCSC{Float64} as input is not possible (use other input formats to do so). Another possibility to input known shocks is by using a KeyedArray. The KeyedArray type is provided by the AxisKeys package. A KeyedArray{Union{Nothing,Float64}} can be used where, similar to Matrix{Union{Nothing,Float64}}, all entries of type Float64 are recognised as known shocks and all other entries have to be nothing. Furthermore, in the primary axis a subset of shocks (of type Symbol or String) for which values are specified can be included and all other shocks are considered free. The same goes for the case when using KeyedArray{Float64}} as input, whereas in this case the values for the specified shocks bind for all periods specified in the KeyedArray, because there are no nothing entries permitted with this type.\ninitial_state [Default: [0.0], Type: Union{Vector{Vector{Float64}},Vector{Float64}}]: The initial state defines the starting point for the model. In the case of pruned solution algorithms the initial state can be given as multiple state vectors (Vector{Vector{Float64}}). For multiple state vectors the initial state vectors must be given in deviations from the non-stochastic steady state. In all other cases (incl. for pruned solutions) the initial state must be given in levels. If a pruned solution algorithm is selected and initial_state is a Vector{Float64} then it impacts the first order initial state vector only. The state includes all variables as well as exogenous variables in leads or lags if present. get_irf(𝓂, shocks = :none, variables = :all, periods = 1, levels = true) returns a KeyedArray with all variables in levels. The KeyedArray type is provided by the AxisKeys package.\nperiods [Default: 40, Type: Int]: the total number of periods is the sum of the argument provided here and the maximum of periods of the shocks or conditions argument.\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nvariables [Default: all_excluding_obc]: variables for which to show the results. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). all_excluding_obc contains all shocks less those related to auxiliary variables. all will contain all variables.\nconditions_in_levels [Default: true, Type: Bool]: indicator whether the conditions are provided in levels. If true the input to the conditions argument will have the relevant steady state subtracted (non-stochastic or stochastic steady state depending on the solution algorithm).\nlevels [Default: false, Type: Bool]: return levels or absolute deviations from the relevant steady state corresponding to the solution algorithm (e.g. stochastic steady state for higher order solution algorithms).\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables  and shocks in rows, and periods in columns.\n\nExamples\n\nusing MacroModelling\nusing SparseArrays, AxisKeys\n\n@model RBC_CME begin\n    y[0]=A[0]*k[-1]^alpha\n    1/c[0]=beta*1/c[1]*(alpha*A[1]*k[0]^(alpha-1)+(1-delta))\n    1/c[0]=beta*1/c[1]*(R[0]/Pi[+1])\n    R[0] * beta =(Pi[0]/Pibar)^phi_pi\n    A[0]*k[-1]^alpha=c[0]+k[0]-(1-delta*z_delta[0])*k[-1]\n    z_delta[0] = 1 - rho_z_delta + rho_z_delta * z_delta[-1] + std_z_delta * delta_eps[x]\n    A[0] = 1 - rhoz + rhoz * A[-1]  + std_eps * eps_z[x]\nend\n\n@parameters RBC_CME begin\n    alpha = .157\n    beta = .999\n    delta = .0226\n    Pibar = 1.0008\n    phi_pi = 1.5\n    rhoz = .9\n    std_eps = .0068\n    rho_z_delta = .9\n    std_z_delta = .005\nend\n\n# c is conditioned to deviate by 0.01 in period 1 and y is conditioned to deviate by 0.02 in period 2\nconditions = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,2,2),Variables = [:c,:y], Periods = 1:2)\nconditions[1,1] = .01\nconditions[2,2] = .02\n\n# in period 2 second shock (eps_z) is conditioned to take a value of 0.05\nshocks = Matrix{Union{Nothing,Float64}}(undef,2,1)\nshocks[1,1] = .05\n\nget_conditional_forecast(RBC_CME, conditions, shocks = shocks, conditions_in_levels = false)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables_and_shocks ∈ 9-element Vector{Symbol}\n→   Periods ∈ 42-element UnitRange{Int64}\nAnd data, 9×42 Matrix{Float64}:\n                (1)            (2)           …  (41)            (42)\n  (:A)            0.0313639      0.0134792         0.000221372     0.000199235\n  (:Pi)           0.000780257    0.00020929       -0.000146071    -0.000140137\n  (:R)            0.00117156     0.00031425       -0.000219325    -0.000210417\n  (:c)            0.01           0.00600605        0.00213278      0.00203751\n  (:k)            0.034584       0.0477482   …     0.0397631       0.0380482\n  (:y)            0.0446375      0.02              0.00129544      0.001222\n  (:z_delta)      0.00025        0.000225          3.69522e-6      3.3257e-6\n  (:delta_eps)    0.05           0.0               0.0             0.0\n  (:eps_z)        4.61234       -2.16887           0.0             0.0\n\n# The same can be achieved with the other input formats:\n# conditions = Matrix{Union{Nothing,Float64}}(undef,7,2)\n# conditions[4,1] = .01\n# conditions[6,2] = .02\n\n# using SparseArrays\n# conditions = spzeros(7,2)\n# conditions[4,1] = .01\n# conditions[6,2] = .02\n\n# shocks = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,1,1),Variables = [:delta_eps], Periods = [1])\n# shocks[1,1] = .05\n\n# using SparseArrays\n# shocks = spzeros(2,1)\n# shocks[1,1] = .05\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_conditional_variance_decomposition-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_conditional_variance_decomposition","text":"get_conditional_variance_decomposition(\n    𝓂;\n    periods,\n    parameters,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the conditional variance decomposition of endogenous variables with regards to the shocks using the linearised solution. \n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nperiods [Default: [1:20...,Inf], Type: Union{Vector{Int},Vector{Float64},UnitRange{Int64}}]: vector of periods for which to calculate the conditional variance decomposition. If the vector contains Inf, also the unconditional variance decomposition is calculated (same output as get_variance_decomposition).\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows, shocks in columns, and periods as the third dimension.\n\nExamples\n\nusing MacroModelling\n\n@model RBC_CME begin\n    y[0]=A[0]*k[-1]^alpha\n    1/c[0]=beta*1/c[1]*(alpha*A[1]*k[0]^(alpha-1)+(1-delta))\n    1/c[0]=beta*1/c[1]*(R[0]/Pi[+1])\n    R[0] * beta =(Pi[0]/Pibar)^phi_pi\n    A[0]*k[-1]^alpha=c[0]+k[0]-(1-delta*z_delta[0])*k[-1]\n    z_delta[0] = 1 - rho_z_delta + rho_z_delta * z_delta[-1] + std_z_delta * delta_eps[x]\n    A[0] = 1 - rhoz + rhoz * A[-1]  + std_eps * eps_z[x]\nend\n\n@parameters RBC_CME begin\n    alpha = .157\n    beta = .999\n    delta = .0226\n    Pibar = 1.0008\n    phi_pi = 1.5\n    rhoz = .9\n    std_eps = .0068\n    rho_z_delta = .9\n    std_z_delta = .005\nend\n\nget_conditional_variance_decomposition(RBC_CME)\n# output\n3-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 7-element Vector{Symbol}\n→   Shocks ∈ 2-element Vector{Symbol}\n◪   Periods ∈ 21-element Vector{Float64}\nAnd data, 7×2×21 Array{Float64, 3}:\n[showing 3 of 21 slices]\n[:, :, 1] ~ (:, :, 1.0):\n              (:delta_eps)  (:eps_z)\n  (:A)         0.0           1.0\n  (:Pi)        0.00158668    0.998413\n  (:R)         0.00158668    0.998413\n  (:c)         0.0277348     0.972265\n  (:k)         0.00869568    0.991304\n  (:y)         0.0           1.0\n  (:z_delta)   1.0           0.0\n\n[:, :, 11] ~ (:, :, 11.0):\n              (:delta_eps)  (:eps_z)\n  (:A)         5.88653e-32   1.0\n  (:Pi)        0.0245641     0.975436\n  (:R)         0.0245641     0.975436\n  (:c)         0.0175249     0.982475\n  (:k)         0.00869568    0.991304\n  (:y)         7.63511e-5    0.999924\n  (:z_delta)   1.0           0.0\n\n[:, :, 21] ~ (:, :, Inf):\n              (:delta_eps)  (:eps_z)\n  (:A)         9.6461e-31    1.0\n  (:Pi)        0.0156771     0.984323\n  (:R)         0.0156771     0.984323\n  (:c)         0.0134672     0.986533\n  (:k)         0.00869568    0.991304\n  (:y)         0.000313462   0.999687\n  (:z_delta)   1.0           0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_corr","page":"API","title":"MacroModelling.get_corr","text":"See get_correlation\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_correlation-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_correlation","text":"get_correlation(\n    𝓂;\n    parameters,\n    algorithm,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm,\n    verbose,\n    tol\n)\n\n\nReturn the correlations of endogenous variables using the first, pruned second, or pruned third order perturbation solution. \n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows and columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_correlation(RBC)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   𝑉𝑎𝑟𝑖𝑎𝑏𝑙𝑒𝑠 ∈ 4-element Vector{Symbol}\nAnd data, 4×4 Matrix{Float64}:\n        (:c)       (:k)       (:q)       (:z)\n  (:c)   1.0        0.999812   0.550168   0.314562\n  (:k)   0.999812   1.0        0.533879   0.296104\n  (:q)   0.550168   0.533879   1.0        0.965726\n  (:z)   0.314562   0.296104   0.965726   1.0\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_cov","page":"API","title":"MacroModelling.get_cov","text":"Wrapper for get_moments with covariance = true and non_stochastic_steady_state = false, variance = false, standard_deviation = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_covariance-Tuple","page":"API","title":"MacroModelling.get_covariance","text":"Wrapper for get_moments with covariance = true and non_stochastic_steady_state = false, variance = false, standard_deviation = false, derivatives = false.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_dynamic_auxiliary_variables-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_dynamic_auxiliary_variables","text":"get_dynamic_auxiliary_variables(𝓂)\n\n\nReturns the auxiliary variables, without timing subscripts, part of the augmented system of equations describing the model dynamics. Augmented means that, in case of variables with leads or lags larger than 1, or exogenous shocks with leads or lags, the system is augemented by auxiliary variables containing variables or shocks in lead or lag. Because the original equations included variables with leads or lags certain expression cannot be negative (e.g. given log(c/q) an auxiliary variable is created for c/q).\n\nSee get_dynamic_equations for more details on the auxiliary variables and equations.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the auxiliary parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_dynamic_auxiliary_variables(RBC)\n# output\n3-element Vector{String}:\n \"kᴸ⁽⁻²⁾\"\n \"kᴸ⁽⁻³⁾\"\n \"kᴸ⁽⁻¹⁾\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_dynamic_equations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_dynamic_equations","text":"get_dynamic_equations(𝓂)\n\n\nReturn the augmented system of equations describing the model dynamics. Augmented means that, when variables have leads or lags with absolute value larger than 1, or exogenous shocks have leads or lags, auxiliary equations containing lead/lag variables are added. The augmented system contains only variables in the present [0], future [1], or past [-1]. For example, Δk_4q[0] = log(k[0]) - log(k[-3]) contains k[-3]. Introducing two auxiliary variables (kᴸ⁽⁻¹⁾ and kᴸ⁽⁻²⁾, where ᴸ denotes the lead/lag operator) and augmenting the system with kᴸ⁽⁻²⁾[0] = kᴸ⁽⁻¹⁾[-1] and kᴸ⁽⁻¹⁾[0] = k[-1] ensures that all timing indices have absolute value at most 1: Δk_4q[0] - (log(k[0]) - log(kᴸ⁽⁻²⁾[-1])).\n\nIn case programmatic model writing was used this function returns the parsed equations (see loop over shocks in example).\n\nNote that the output assumes the equations are equal to 0. As in, kᴸ⁽⁻¹⁾[0] - k[-1] implies kᴸ⁽⁻¹⁾[0] - k[-1] = 0 and therefore: kᴸ⁽⁻¹⁾[0] = k[-1].\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the dynamic model equations. \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_dynamic_equations(RBC)\n# output\n12-element Vector{String}:\n \"1 / c[0] - (β / c[1]) * (α * ex\" ⋯ 25 bytes ⋯ \" - 1) + (1 - exp(z{δ}[1]) * δ))\"\n \"(c[0] + k[0]) - ((1 - exp(z{δ}[0]) * δ) * k[-1] + q[0])\"\n \"q[0] - exp(z{TFP}[0]) * k[-1] ^ α\"\n \"eps_news{TFP}[0] - eps_news{TFP}[x]\"\n \"z{TFP}[0] - (ρ{TFP} * z{TFP}[-1] + σ{TFP} * (eps{TFP}[x] + eps_news{TFP}[-1]))\"\n \"eps_news{δ}[0] - eps_news{δ}[x]\"\n \"z{δ}[0] - (ρ{δ} * z{δ}[-1] + σ{δ} * (eps{δ}[x] + eps_news{δ}[-1]))\"\n \"Δc_share[0] - (log(c[0] / q[0]) - log(c[-1] / q[-1]))\"\n \"kᴸ⁽⁻³⁾[0] - kᴸ⁽⁻²⁾[-1]\"\n \"kᴸ⁽⁻²⁾[0] - kᴸ⁽⁻¹⁾[-1]\"\n \"kᴸ⁽⁻¹⁾[0] - k[-1]\"\n \"Δk_4q[0] - (log(k[0]) - log(kᴸ⁽⁻³⁾[-1]))\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_equations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_equations","text":"get_equations(𝓂)\n\n\nReturn the equations of the model. In case programmatic model writing was used this function returns the parsed equations (see loop over shocks in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the parsed equations. \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_equations(RBC)\n# output\n7-element Vector{String}:\n \"1 / c[0] = (β / c[1]) * (α * ex\" ⋯ 25 bytes ⋯ \" - 1) + (1 - exp(z{δ}[1]) * δ))\"\n \"c[0] + k[0] = (1 - exp(z{δ}[0]) * δ) * k[-1] + q[0]\"\n \"q[0] = exp(z{TFP}[0]) * k[-1] ^ α\"\n \"z{TFP}[0] = ρ{TFP} * z{TFP}[-1]\" ⋯ 18 bytes ⋯ \"TFP}[x] + eps_news{TFP}[x - 1])\"\n \"z{δ}[0] = ρ{δ} * z{δ}[-1] + σ{δ} * (eps{δ}[x] + eps_news{δ}[x - 1])\"\n \"Δc_share[0] = log(c[0] / q[0]) - log(c[-1] / q[-1])\"\n \"Δk_4q[0] = log(k[0]) - log(k[-4])\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_estimated_shocks-Tuple{MacroModelling.ℳ, KeyedArray{Float64}}","page":"API","title":"MacroModelling.get_estimated_shocks","text":"get_estimated_shocks(\n    𝓂,\n    data;\n    parameters,\n    algorithm,\n    filter,\n    warmup_iterations,\n    data_in_levels,\n    smooth,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the estimated shocks based on the inversion filter (depending on the filter keyword argument), or Kalman filter or smoother (depending on the smooth keyword argument) using the provided data and (non-)linear solution of the model. By default MacroModelling chooses the Kalman filter for first order solutions and the inversion filter for higher order ones, and only enables smoothing when the Kalman filter is used. Data is by default assumed to be in levels unless data_in_levels is set to false.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nfilter [Default: selector that chooses kalman in case algorithm = first_order and :inversion otherwise, Type: Symbol]: filter used to compute the variables and shocks given the data, model, and parameters. The Kalman filter only works for linear problems, whereas the inversion filter (:inversion) works for linear and nonlinear models. If a nonlinear solution algorithm is selected and the default is used, the inversion filter is applied automatically.\ndata_in_levels [Default: true, Type: Bool]: indicator whether the data is provided in levels. If true the input to the data argument will have the non-stochastic steady state subtracted.\nsmooth [Default: selector that enables smoothing when filter = kalman and disables it otherwise, Type: Bool]: whether to return smoothed (true) or filtered (false) shocks/variables. Smoothing is only available for the Kalman filter. The inversion filter only returns filtered shocks/variables, so the default turns smoothing off in that case.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with shocks in rows, and periods in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulation = simulate(RBC)\n\nget_estimated_shocks(RBC,simulation([:c],:,:simulate))\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Shocks ∈ 1-element Vector{Symbol}\n→   Periods ∈ 40-element UnitRange{Int64}\nAnd data, 1×40 Matrix{Float64}:\n               (1)          (2)         (3)         (4)         …  (37)         (38)        (39)         (40)\n  (:eps_z₍ₓ₎)    0.0603617    0.614652   -0.519048    0.711454       -0.873774     1.27918    -0.929701    -0.2255\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_estimated_variable_standard_deviations-Tuple{MacroModelling.ℳ, KeyedArray{Float64}}","page":"API","title":"MacroModelling.get_estimated_variable_standard_deviations","text":"get_estimated_variable_standard_deviations(\n    𝓂,\n    data;\n    parameters,\n    data_in_levels,\n    smooth,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the standard deviations of the Kalman smoother or filter (depending on the smooth keyword argument) estimates of the model variables based on the provided data and first order solution of the model. For the default settings this function relies on the Kalman filter and therefore keeps smoothing enabled. Data is by default assumed to be in levels unless data_in_levels is set to false.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\ndata_in_levels [Default: true, Type: Bool]: indicator whether the data is provided in levels. If true the input to the data argument will have the non-stochastic steady state subtracted.\nsmooth [Default: selector that enables smoothing when filter = kalman and disables it otherwise, Type: Bool]: whether to return smoothed (true) or filtered (false) shocks/variables. Smoothing is only available for the Kalman filter. The inversion filter only returns filtered shocks/variables, so the default turns smoothing off in that case.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with standard deviations in rows, and periods in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulation = simulate(RBC)\n\nget_estimated_variable_standard_deviations(RBC,simulation([:c],:,:simulate))\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Standard_deviations ∈ 4-element Vector{Symbol}\n→   Periods ∈ 40-element UnitRange{Int64}\nAnd data, 4×40 Matrix{Float64}:\n        (1)           (2)            (3)            (4)            …  (38)            (39)            (40)\n  (:c)    1.23202e-9    1.84069e-10    8.23181e-11    8.23181e-11        8.23181e-11     8.23181e-11     0.0\n  (:k)    0.00509299    0.000382934    2.87922e-5     2.16484e-6         1.6131e-9       9.31323e-10     1.47255e-9\n  (:q)    0.0612887     0.0046082      0.000346483    2.60515e-5         1.31709e-9      1.31709e-9      9.31323e-10\n  (:z)    0.00961766    0.000723136    5.43714e-5     4.0881e-6          3.08006e-10     3.29272e-10     2.32831e-10\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_estimated_variables-Tuple{MacroModelling.ℳ, KeyedArray{Float64}}","page":"API","title":"MacroModelling.get_estimated_variables","text":"get_estimated_variables(\n    𝓂,\n    data;\n    parameters,\n    algorithm,\n    filter,\n    warmup_iterations,\n    data_in_levels,\n    levels,\n    smooth,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the estimated variables (in levels by default, see levels keyword argument) based on the inversion filter (depending on the filter keyword argument), or Kalman filter or smoother (depending on the smooth keyword argument) using the provided data and (non-)linear solution of the model. With the default options the Kalman filter is applied to first order solutions, while the inversion filter is used for higher order methods; smoothing is activated automatically only when the Kalman filter is available. Data is by default assumed to be in levels unless data_in_levels is set to false.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nfilter [Default: selector that chooses kalman in case algorithm = first_order and :inversion otherwise, Type: Symbol]: filter used to compute the variables and shocks given the data, model, and parameters. The Kalman filter only works for linear problems, whereas the inversion filter (:inversion) works for linear and nonlinear models. If a nonlinear solution algorithm is selected and the default is used, the inversion filter is applied automatically.\ndata_in_levels [Default: true, Type: Bool]: indicator whether the data is provided in levels. If true the input to the data argument will have the non-stochastic steady state subtracted.\nlevels [Default: true, Type: Bool]: return levels or absolute deviations from the relevant steady state corresponding to the solution algorithm (e.g. stochastic steady state for higher order solution algorithms).\nsmooth [Default: selector that enables smoothing when filter = kalman and disables it otherwise, Type: Bool]: whether to return smoothed (true) or filtered (false) shocks/variables. Smoothing is only available for the Kalman filter. The inversion filter only returns filtered shocks/variables, so the default turns smoothing off in that case.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows, and periods in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulation = simulate(RBC)\n\nget_estimated_variables(RBC,simulation([:c],:,:simulate))\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Periods ∈ 40-element UnitRange{Int64}\nAnd data, 4×40 Matrix{Float64}:\n        (1)           (2)           (3)           (4)          …  (37)          (38)            (39)           (40)\n  (:c)    5.92901       5.92797       5.92847       5.92048          5.95845       5.95697         5.95686        5.96173\n  (:k)   47.3185       47.3087       47.3125       47.2392          47.6034       47.5969         47.5954        47.6402\n  (:q)    6.87159       6.86452       6.87844       6.79352          7.00476       6.9026          6.90727        6.95841\n  (:z)   -0.00109471   -0.00208056    4.43613e-5   -0.0123318        0.0162992     0.000445065     0.00119089     0.00863586\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_fevd","page":"API","title":"MacroModelling.get_fevd","text":"See get_conditional_variance_decomposition\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_first_order_solution-Tuple","page":"API","title":"MacroModelling.get_first_order_solution","text":"Wrapper for get_solution with algorithm = :first_order.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_forecast_error_variance_decomposition","page":"API","title":"MacroModelling.get_forecast_error_variance_decomposition","text":"See get_conditional_variance_decomposition\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_girf-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_girf","text":"Wrapper for get_irf with generalised_irf = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_irf-Union{Tuple{MacroModelling.ℳ}, Tuple{R}} where R<:Real","page":"API","title":"MacroModelling.get_irf","text":"get_irf(\n    𝓂;\n    periods,\n    algorithm,\n    parameters,\n    variables,\n    shocks,\n    negative_shock,\n    generalised_irf,\n    generalised_irf_warmup_iterations,\n    generalised_irf_draws,\n    initial_state,\n    levels,\n    shock_size,\n    ignore_obc,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn impulse response functions (IRFs) of the model. By default, the values represent absolute deviations from the relevant steady state (see levels for details). The non-stochastic steady state (NSSS) is relevant for first order solutions and the stochastic steady state for higher order solutions.\n\nIf the model contains occasionally binding constraints and ignore_obc = false they are enforced using shocks.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nperiods [Default: 40, Type: Int]: number of periods for which to calculate the output. In case a matrix of shocks was provided, periods defines how many periods after the series of shocks the output continues.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nvariables [Default: all_excluding_obc]: variables for which to show the results. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). all_excluding_obc contains all shocks less those related to auxiliary variables. all will contain all variables.\nshocks [Default: all_excluding_obc]: shocks for which to calculate the IRFs. Inputs can be a shock name passed on as either a Symbol or String (e.g. :y, or \"y\"), or Tuple, Matrix or Vector of String or Symbol. :simulate triggers random draws of all shocks (excluding occasionally binding constraints (obc) related shocks). all_excluding_obc will contain all shocks but not the obc related ones. all will contain also the obc related shocks. A series of shocks can be passed on using either a Matrix{Float64}, or a KeyedArray{Float64} as input with shocks (Symbol or String) in rows and periods in columns. The KeyedArray type is provided by the AxisKeys package. The period of the simulation will correspond to the length of the input in the period dimension + the number of periods defined in periods. If the series of shocks is input as a KeyedArray{Float64} make sure to name the rows with valid shock names of type Symbol. Any shocks not part of the model will trigger a warning. :none in combination with an initial_state can be used for deterministic simulations.\nnegative_shock [Default: false, Type: Bool]: if true, calculates IRFs for a negative shock. Only affects shocks that are not passed on as a Matrix or KeyedArray or set to :none.\ngeneralised_irf [Default: false, Type: Bool]: calculate generalised IRFs. Relevant for nonlinear (higher order perturbation) solutions only. Reference steady state for deviations is the stochastic steady state. initial_state has no effect on generalised IRFs. Occasionally binding constraint are not respected for generalised IRF.\ngeneralised_irf_warmup_iterations [Default: 100, Type: Int]: number of warm-up iterations used to draw the baseline paths in the generalised IRF simulation. Only applied when generalised_irf = true.\ngeneralised_irf_draws [Default: 50, Type: Int]: number of Monte Carlo draws used to compute the generalised IRF. Only applied when generalised_irf = true.\ninitial_state [Default: [0.0], Type: Union{Vector{Vector{Float64}},Vector{Float64}}]: The initial state defines the starting point for the model. In the case of pruned solution algorithms the initial state can be given as multiple state vectors (Vector{Vector{Float64}}). For multiple state vectors the initial state vectors must be given in deviations from the non-stochastic steady state. In all other cases (incl. for pruned solutions) the initial state must be given in levels. If a pruned solution algorithm is selected and initial_state is a Vector{Float64} then it impacts the first order initial state vector only. The state includes all variables as well as exogenous variables in leads or lags if present. get_irf(𝓂, shocks = :none, variables = :all, periods = 1, levels = true) returns a KeyedArray with all variables in levels. The KeyedArray type is provided by the AxisKeys package.\nlevels [Default: false, Type: Bool]: return levels or absolute deviations from the relevant steady state corresponding to the solution algorithm (e.g. stochastic steady state for higher order solution algorithms).\nshock_size [Default: 1, Type: Real]: size of the shocks in standard deviations. Only affects shocks that are not passed on as a Matrix or KeyedArray or set to :none. A negative value will flip the sign of the shock.\nignore_obc [Default: false, Type: Bool]: solve the model ignoring the occasionally binding constraints.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows, periods in columns, and shocks as the third dimension.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_irf(RBC)\n# output\n3-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Periods ∈ 40-element UnitRange{Int64}\n◪   Shocks ∈ 1-element Vector{Symbol}\nAnd data, 4×40×1 Array{Float64, 3}:\n[:, :, 1] ~ (:, :, :eps_z):\n        (1)           (2)           …  (39)            (40)\n  (:c)    0.00674687    0.00729773        0.00146962      0.00140619\n  (:k)    0.0620937     0.0718322         0.0146789       0.0140453\n  (:q)    0.0688406     0.0182781         0.00111425      0.00106615\n  (:z)    0.01          0.002             2.74878e-29     5.49756e-30\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_irf-Union{Tuple{S}, Tuple{MacroModelling.ℳ, Vector{S}}} where S<:Real","page":"API","title":"MacroModelling.get_irf","text":"get_irf(\n    𝓂,\n    parameters;\n    periods,\n    variables,\n    shocks,\n    negative_shock,\n    initial_state,\n    levels,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm\n)\n\n\nReturn impulse response functions (IRFs) of the model. Function to use when differentiating IRFs with respect to parameters.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\nparameters [Type: Vector]: Parameter values in alphabetical order (sorted by parameter name).\n\nKeyword Arguments\n\nperiods [Default: 40, Type: Int]: number of periods for which to calculate the output. In case a matrix of shocks was provided, periods defines how many periods after the series of shocks the output continues.\nvariables [Default: all_excluding_obc]: variables for which to show the results. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). all_excluding_obc contains all shocks less those related to auxiliary variables. all will contain all variables.\nshocks [Default: all_excluding_obc]: shocks for which to calculate the IRFs. Inputs can be a shock name passed on as either a Symbol or String (e.g. :y, or \"y\"), or Tuple, Matrix or Vector of String or Symbol. :simulate triggers random draws of all shocks (excluding occasionally binding constraints (obc) related shocks). all_excluding_obc will contain all shocks but not the obc related ones. all will contain also the obc related shocks. A series of shocks can be passed on using either a Matrix{Float64}, or a KeyedArray{Float64} as input with shocks (Symbol or String) in rows and periods in columns. The KeyedArray type is provided by the AxisKeys package. The period of the simulation will correspond to the length of the input in the period dimension + the number of periods defined in periods. If the series of shocks is input as a KeyedArray{Float64} make sure to name the rows with valid shock names of type Symbol. Any shocks not part of the model will trigger a warning. :none in combination with an initial_state can be used for deterministic simulations.\nnegative_shock [Default: false, Type: Bool]: if true, calculates IRFs for a negative shock. Only affects shocks that are not passed on as a Matrix or KeyedArray or set to :none.\ninitial_state [Default: [0.0], Type: Vector{Float64}]: The initial state defines the starting point for the model (in levels, not deviations). The state includes all variables as well as exogenous variables in leads or lags if present. get_irf(𝓂, shocks = :none, variables = :all, periods = 1) returns a KeyedArray with all variables. The KeyedArray type is provided by the AxisKeys package.\nlevels [Default: false, Type: Bool]: return levels or absolute deviations from the relevant steady state corresponding to the solution algorithm (e.g. stochastic steady state for higher order solution algorithms).\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nArray{<:AbstractFloat, 3} with variables in rows, periods in columns, and shocks as the third dimension.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_irf(RBC, RBC.parameter_values)\n# output\n4×40×1 Array{Float64, 3}:\n[:, :, 1] =\n 0.00674687  0.00729773  0.00715114  0.00687615  …  0.00146962   0.00140619\n 0.0620937   0.0718322   0.0712153   0.0686381      0.0146789    0.0140453\n 0.0688406   0.0182781   0.00797091  0.0057232      0.00111425   0.00106615\n 0.01        0.002       0.0004      8.0e-5         2.74878e-29  5.49756e-30\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_irfs","page":"API","title":"MacroModelling.get_irfs","text":"See get_irf\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_jump_variables-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_jump_variables","text":"get_jump_variables(𝓂)\n\n\nReturns the jump variables of the model. Jump variables occur in the future and not in the past or occur in all three: past, present, and future.\n\nIn case programmatic model writing was used this function returns the parsed variables (see z in example).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the jump variables.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_jump_variables(RBC)\n# output\n3-element Vector{String}:\n \"c\"\n \"z{TFP}\"\n \"z{δ}\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_loglikelihood-Union{Tuple{U}, Tuple{S}, Tuple{MacroModelling.ℳ, KeyedArray{Float64}, Vector{S}}} where {S<:Real, U<:AbstractFloat}","page":"API","title":"MacroModelling.get_loglikelihood","text":"get_loglikelihood(\n    𝓂,\n    data,\n    parameter_values;\n    algorithm,\n    filter,\n    on_failure_loglikelihood,\n    warmup_iterations,\n    presample_periods,\n    initial_covariance,\n    filter_algorithm,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    lyapunov_algorithm,\n    sylvester_algorithm,\n    verbose\n)\n\n\nReturn the loglikelihood of the model given the data and parameters provided. The loglikelihood is either calculated based on the inversion or the Kalman filter (depending on the filter keyword argument). By default the package selects the Kalman filter for first order solutions and the inversion filter for nonlinear (higher order) solution algorithms. The data must be provided as a KeyedArray{Float64} with the names of the variables to be matched in rows and the periods in columns. The KeyedArray type is provided by the AxisKeys package.\n\nThis function is differentiable (so far for the Kalman filter only) and can be used in gradient based sampling or optimisation.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\nparameter_values [Type: Vector]: Parameter values.\n\nKeyword Arguments\n\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nfilter [Default: selector that chooses kalman in case algorithm = first_order and :inversion otherwise, Type: Symbol]: filter used to compute the variables and shocks given the data, model, and parameters. The Kalman filter only works for linear problems, whereas the inversion filter (:inversion) works for linear and nonlinear models. If a nonlinear solution algorithm is selected and the default is used, the inversion filter is applied automatically.\npresample_periods [Default: 0, Type: Int]: periods at the beginning of the data for which the loglikelihood is discarded.\ninitial_covariance [Default: :theoretical, Type: Symbol]: defines the method to initialise the Kalman filters covariance matrix. It can be initialised with the theoretical long run values (option :theoretical) or large values (10.0) along the diagonal (option :diagonal).\non_failure_loglikelihood [Default: -Inf, Type: AbstractFloat]: value to return if the loglikelihood calculation fails. Setting this to a finite value can avoid errors in codes that rely on finite loglikelihood values, such as e.g. slice samplers (in Pigeons.jl).\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\n<:AbstractFloat loglikelihood \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulated_data = simulate(RBC)\n\nget_loglikelihood(RBC, simulated_data([:k], :, :simulate), RBC.parameter_values)\n# output\n58.24780188977981\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_mean-Tuple","page":"API","title":"MacroModelling.get_mean","text":"Wrapper for get_moments with mean = true, and non_stochastic_steady_state = false, variance = false, standard_deviation = false, covariance = false\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_missing_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_missing_parameters","text":"get_missing_parameters(𝓂)\n\n\nReturns the parameters which are required by the model but have not been assigned values in the @parameters block. These parameters must be provided via the parameters keyword argument in functions like get_irf, get_SS, simulate, etc. before the model can be solved.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the missing parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC_incomplete begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC_incomplete begin\n    std_z = 0.01\n    ρ = 0.2\n    # Note: α, β, δ are not defined\nend\n\nget_missing_parameters(RBC_incomplete)\n# output\n3-element Vector{String}:\n \"α\"\n \"β\"\n \"δ\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_model_estimates-Tuple{MacroModelling.ℳ, KeyedArray{Float64}}","page":"API","title":"MacroModelling.get_model_estimates","text":"get_model_estimates(\n    𝓂,\n    data;\n    parameters,\n    algorithm,\n    filter,\n    warmup_iterations,\n    data_in_levels,\n    levels,\n    smooth,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the vertical concatenation of get_estimated_variables and get_estimated_shocks as a single KeyedArray with a common first axis named Estimates and the second axis Periods. Variables appear first, followed by shocks.\n\nAll keyword arguments are forwarded to the respective functions. See the docstrings of get_estimated_variables and get_estimated_shocks for details.\n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nfilter [Default: selector that chooses kalman in case algorithm = first_order and :inversion otherwise, Type: Symbol]: filter used to compute the variables and shocks given the data, model, and parameters. The Kalman filter only works for linear problems, whereas the inversion filter (:inversion) works for linear and nonlinear models. If a nonlinear solution algorithm is selected and the default is used, the inversion filter is applied automatically.\ndata_in_levels [Default: true, Type: Bool]: indicator whether the data is provided in levels. If true the input to the data argument will have the non-stochastic steady state subtracted.\nlevels [Default: true, Type: Bool]: return levels or absolute deviations from the relevant steady state corresponding to the solution algorithm (e.g. stochastic steady state for higher order solution algorithms).\nsmooth [Default: selector that enables smoothing when filter = kalman and disables it otherwise, Type: Bool]: whether to return smoothed (true) or filtered (false) shocks/variables. Smoothing is only available for the Kalman filter. The inversion filter only returns filtered shocks/variables, so the default turns smoothing off in that case.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables followed by shocks in rows, and periods in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulation = simulate(RBC)\n\nget_model_estimates(RBC,simulation([:c],:,:simulate))\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables_and_shocks ∈ 5-element Vector{Symbol}\n→   Periods ∈ 40-element UnitRange{Int64}\nAnd data, 5×40 Matrix{Float64}:\n               (1)          (2)           (3)           (4)          …  (37)           (38)           (39)           (40)\n  (:c)           5.94335      5.94676       5.94474       5.95135          5.93773        5.94333        5.94915        5.95473\n  (:k)          47.4603      47.4922       47.476        47.5356          47.4079        47.4567        47.514         47.5696\n  (:q)           6.89873      6.92782       6.87844       6.96043          6.85055        6.9403         6.95556        6.96064\n  (:z)           0.0014586    0.00561728   -0.00189203    0.0101896       -0.00543334     0.00798437     0.00968602     0.00981981\n  (:eps_z₍ₓ₎)    0.12649      0.532556     -0.301549      1.0568     …    -0.746981       0.907104       0.808914       0.788261\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_moments-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_moments","text":"get_moments(\n    𝓂;\n    parameters,\n    non_stochastic_steady_state,\n    mean,\n    standard_deviation,\n    variance,\n    covariance,\n    variables,\n    derivatives,\n    parameter_derivatives,\n    algorithm,\n    silent,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm,\n    verbose,\n    tol\n)\n\n\nReturn the first and second moments of endogenous variables using the first, pruned second, or pruned third order perturbation solution. By default returns: non-stochastic steady state (NSSS), and standard deviations, but can optionally return variances, and covariance matrix. Derivatives of the moments (except for covariance) can also be provided by setting derivatives to true.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nnon_stochastic_steady_state [Default: true, Type: Bool]: switch to return SS of endogenous variables\nmean [Default: false, Type: Bool]: switch to return mean of endogenous variables (the mean for the linearised solutoin is the NSSS)\nstandard_deviation [Default: true, Type: Bool]: switch to return standard deviation of endogenous variables\nvariance [Default: false, Type: Bool]: switch to return variance of endogenous variables\ncovariance [Default: false, Type: Bool]: switch to return covariance matrix of endogenous variables\nvariables [Default: all_excluding_obc]: variables for which to show the results. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). all_excluding_obc contains all shocks less those related to auxiliary variables. all will contain all variables.\nderivatives [Default: true, Type: Bool]: calculate derivatives with respect to the parameters.\nparameter_derivatives [Default: :all]: parameters for which to calculate partial derivatives. Inputs can be a parameter name passed on as either a Symbol or String (e.g. :alpha, or \"alpha\"), or Tuple, Matrix or Vector of String or Symbol. :all will include all parameters.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nDict{Symbol,KeyedArray} containing the selected moments. All moments have variables as rows and the moment as the first column followed by partial derivatives wrt parameters. The KeyedArray type is provided by the AxisKeys package.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nmoments = get_moments(RBC);\n\nmoments[:non_stochastic_steady_state]\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Steady_state_and_∂steady_state∂parameter ∈ 6-element Vector{Symbol}\nAnd data, 4×6 Matrix{Float64}:\n        (:Steady_state)  (:std_z)  (:ρ)     (:δ)      (:α)       (:β)\n  (:c)   5.93625          0.0       0.0   -116.072    55.786     76.1014\n  (:k)  47.3903           0.0       0.0  -1304.95    555.264   1445.93\n  (:q)   6.88406          0.0       0.0    -94.7805   66.8912   105.02\n  (:z)   0.0              0.0       0.0      0.0       0.0        0.0\n\nmoments[:standard_deviation]\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Standard_deviation_and_∂standard_deviation∂parameter ∈ 6-element Vector{Symbol}\nAnd data, 4×6 Matrix{Float64}:\n        (:Standard_deviation)  (:std_z)  …  (:δ)       (:α)       (:β)\n  (:c)   0.0266642              2.66642     -0.384359   0.2626     0.144789\n  (:k)   0.264677              26.4677      -5.74194    2.99332    6.30323\n  (:q)   0.0739325              7.39325     -0.974722   0.726551   1.08\n  (:z)   0.0102062              1.02062      0.0        0.0        0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_non_stochastic_steady_state-Tuple","page":"API","title":"MacroModelling.get_non_stochastic_steady_state","text":"Wrapper for get_steady_state with stochastic = false.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_non_stochastic_steady_state_residuals-Tuple{MacroModelling.ℳ, Union{Dict{String, Float64}, Dict{Symbol, Float64}, KeyedArray{Float64, 1}, Vector{Float64}}}","page":"API","title":"MacroModelling.get_non_stochastic_steady_state_residuals","text":"get_non_stochastic_steady_state_residuals(\n    𝓂,\n    values;\n    parameters,\n    tol,\n    verbose\n)\n\n\nCalculate the residuals of the non-stochastic steady state equations of the model for a given set of values. Values not provided, will be filled with the non-stochastic steady state values corresponding to the current parameters.\n\nArguments\n\n𝓂: object created by @model and @parameters.\nvalues [Type: Union{Vector{Float64}, Dict{Symbol, Float64}, Dict{String, Float64}, KeyedArray{Float64, 1}}]: A Vector, Dict, or KeyedArray containing the values of the variables and calibrated parameters in the non-stochastic steady state equations (including calibration equations). The KeyedArray type is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) containing the absolute values of the residuals of the non-stochastic steady state equations.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    k[ss] / q[ss] = 2.5 | α\n    β = 0.95\nend\n\nsteady_state = SS(RBC, derivatives = false)\n\nget_non_stochastic_steady_state_residuals(RBC, steady_state)\n# output\n1-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Equation ∈ 5-element Vector{Symbol}\nAnd data, 5-element Vector{Float64}:\n (:Equation₁)             0.0\n (:Equation₂)             0.0\n (:Equation₃)             0.0\n (:Equation₄)             0.0\n (:CalibrationEquation₁)  0.0\n\nget_non_stochastic_steady_state_residuals(RBC, [1.1641597, 3.0635781, 1.2254312, 0.0, 0.18157895])\n# output\n1-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Equation ∈ 5-element Vector{Symbol}\nAnd data, 5-element Vector{Float64}:\n (:Equation₁)             2.7360991250446887e-10\n (:Equation₂)             6.199999980083248e-8\n (:Equation₃)             2.7897102183871425e-8\n (:Equation₄)             0.0\n (:CalibrationEquation₁)  8.160392850342646e-8\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_nonnegativity_auxiliary_variables-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_nonnegativity_auxiliary_variables","text":"get_nonnegativity_auxiliary_variables(𝓂)\n\n\nReturns the auxiliary variables, without timing subscripts, added to the non-stochastic steady state problem because certain expression cannot be negative (e.g. given log(c/q) an auxiliary variable is created for c/q).\n\nSee get_steady_state_equations for more details on the auxiliary variables and equations.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the auxiliary parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_nonnegativity_auxiliary_variables(RBC)\n# output\n2-element Vector{String}:\n \"➕₁\"\n \"➕₂\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_parameters","text":"get_parameters(𝓂; values)\n\n\nReturns the parameters (and optionally the values) which have an impact on the model dynamics but do not depend on other parameters and are not determined by calibration equations. \n\nIn case programmatic model writing was used this function returns the parsed parameters (see σ in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nvalues [Default: false, Type: Bool]: return the values together with the parameter names.\n\nReturns\n\nVector{String} of the parameters or Vector{Pair{String, Float64}} of parameters and values if values is set to true.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_parameters(RBC)\n# output\n7-element Vector{String}:\n \"σ{TFP}\"\n \"σ{δ}\"\n \"ρ{TFP}\"\n \"ρ{δ}\"\n \"capital_to_output\"\n \"alpha\"\n \"β\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_parameters_defined_by_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_parameters_defined_by_parameters","text":"get_parameters_defined_by_parameters(𝓂)\n\n\nReturns the parameters which are defined by other parameters which are not necessarily used in the equations of the model (see α in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_parameters_defined_by_parameters(RBC)\n# output\n1-element Vector{String}:\n \"α\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_parameters_defining_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_parameters_defining_parameters","text":"get_parameters_defining_parameters(𝓂)\n\n\nReturns the parameters which define other parameters in the @parameters block which are not necessarily used in the equations of the model (see alpha in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_parameters_defining_parameters(RBC)\n# output\n1-element Vector{String}:\n \"alpha\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_parameters_in_equations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_parameters_in_equations","text":"get_parameters_in_equations(𝓂)\n\n\nReturns the parameters contained in the model equations. Note that these parameters might be determined by other parameters or calibration equations defined in the @parameters block.\n\nIn case programmatic model writing was used this function returns the parsed parameters (see σ in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_parameters_in_equations(RBC)\n# output\n7-element Vector{String}:\n \"α\"\n \"β\"\n \"δ\"\n \"ρ{TFP}\"\n \"ρ{δ}\"\n \"σ{TFP}\"\n \"σ{δ}\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_perturbation_solution-Tuple","page":"API","title":"MacroModelling.get_perturbation_solution","text":"See get_solution\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_residuals","page":"API","title":"MacroModelling.get_residuals","text":"See get_non_stochastic_steady_state_residuals\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_second_order_solution-Tuple","page":"API","title":"MacroModelling.get_second_order_solution","text":"Wrapper for get_solution with algorithm = :second_order.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_shock_decomposition-Tuple{MacroModelling.ℳ, KeyedArray{Float64}}","page":"API","title":"MacroModelling.get_shock_decomposition","text":"get_shock_decomposition(\n    𝓂,\n    data;\n    parameters,\n    algorithm,\n    filter,\n    data_in_levels,\n    warmup_iterations,\n    smooth,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the shock decomposition in absolute deviations from the relevant steady state. The non-stochastic steady state (NSSS) is relevant for first order solutions and the stochastic steady state for higher order solutions. The deviations are based on the Kalman smoother or filter (depending on the smooth keyword argument) or inversion filter using the provided data and solution of the model. When the defaults are used, the filter is selected automatically—Kalman for first order solutions and inversion otherwise—and smoothing is only enabled when the Kalman filter is active. Data is by default assumed to be in levels unless data_in_levels is set to false.\n\nIn case of pruned second and pruned third order perturbation algorithms the decomposition additionally contains a term Nonlinearities. This term represents the nonlinear interaction between the states in the periods after the shocks arrived and in the case of pruned third order, the interaction between (pruned second order) states and contemporaneous shocks.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\ndata [Type: KeyedArray]: data matrix with variables (String or Symbol) in rows and periods in columns. Periods can have any format and will be used for the output. KeyedArray is provided by the AxisKeys package.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nfilter [Default: selector that chooses kalman in case algorithm = first_order and :inversion otherwise, Type: Symbol]: filter used to compute the variables and shocks given the data, model, and parameters. The Kalman filter only works for linear problems, whereas the inversion filter (:inversion) works for linear and nonlinear models. If a nonlinear solution algorithm is selected and the default is used, the inversion filter is applied automatically.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\ndata_in_levels [Default: true, Type: Bool]: indicator whether the data is provided in levels. If true the input to the data argument will have the non-stochastic steady state subtracted.\nsmooth [Default: selector that enables smoothing when filter = kalman and disables it otherwise, Type: Bool]: whether to return smoothed (true) or filtered (false) shocks/variables. Smoothing is only available for the Kalman filter. The inversion filter only returns filtered shocks/variables, so the default turns smoothing off in that case.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows, shocks in columns, and periods as the third dimension.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nsimulation = simulate(RBC)\n\nget_shock_decomposition(RBC,simulation([:c],:,:simulate))\n# output\n3-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 4-element Vector{Symbol}\n→   Shocks ∈ 2-element Vector{Symbol}\n◪   Periods ∈ 40-element UnitRange{Int64}\nAnd data, 4×2×40 Array{Float64, 3}:\n[showing 3 of 40 slices]\n[:, :, 1] ~ (:, :, 1):\n        (:eps_z₍ₓ₎)   (:Initial_values)\n  (:c)   0.000407252  -0.00104779\n  (:k)   0.00374808   -0.0104645\n  (:q)   0.00415533   -0.000807161\n  (:z)   0.000603617  -1.99957e-6\n\n[:, :, 21] ~ (:, :, 21):\n        (:eps_z₍ₓ₎)  (:Initial_values)\n  (:c)   0.026511    -0.000433619\n  (:k)   0.25684     -0.00433108\n  (:q)   0.115858    -0.000328764\n  (:z)   0.0150266    0.0\n\n[:, :, 40] ~ (:, :, 40):\n        (:eps_z₍ₓ₎)  (:Initial_values)\n  (:c)   0.0437976   -0.000187505\n  (:k)   0.4394      -0.00187284\n  (:q)   0.00985518  -0.000142164\n  (:z)  -0.00366442   8.67362e-19\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_shocks-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_shocks","text":"get_shocks(𝓂)\n\n\nReturns the exogenous shocks.\n\nIn case programmatic model writing was used this function returns the parsed variables (see eps in example).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the exogenous shocks.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_shocks(RBC)\n# output\n4-element Vector{String}:\n \"eps_news{TFP}\"\n \"eps_news{δ}\"\n \"eps{TFP}\"\n \"eps{δ}\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_simulation-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_simulation","text":"Wrapper for get_irf with shocks = :simulate. Function returns values in levels by default.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_simulations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_simulations","text":"Wrapper for get_irf with shocks = :simulate. Function returns values in levels by default.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_solution-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_solution","text":"get_solution(\n    𝓂;\n    parameters,\n    algorithm,\n    silent,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm\n)\n\n\nReturn the solution of the model. In the linear case it returns the non-stochastic steady state (NSSS) followed by the linearised solution of the model. In the nonlinear case (higher order perturbation) the function returns a multidimensional array with the endogenous variables as the second dimension and the state variables, shocks, and perturbation parameter (:Volatility) as the other dimensions.\n\nThe values of the output represent the NSSS in the case of a linear solution and below it the effect that deviations from the NSSS of the respective past states, shocks, and perturbation parameter have (perturbation parameter = 1) on the present value (NSSS deviation) of the model variables.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with the endogenous variables including the auxiliary endogenous and exogenous variables (due to leads and lags > 1) as columns. The rows and other dimensions (depending on the chosen perturbation order) include the NSSS for the linear case only, followed by the states, and exogenous shocks. Subscripts following variable names indicate the timing (e.g. variable₍₋₁₎  indicates the variable being in the past). Superscripts indicate leads or lags (e.g. variableᴸ⁽²⁾ indicates the variable being in lead by two periods). If no super- or subscripts follow the variable name, the variable is in the present.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_solution(RBC)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Steady_state__States__Shocks ∈ 4-element Vector{Symbol}\n→   Variables ∈ 4-element Vector{Symbol}\nAnd data, 4×4 adjoint(::Matrix{Float64}) with eltype Float64:\n                   (:c)         (:k)        (:q)        (:z)\n  (:Steady_state)   5.93625     47.3903      6.88406     0.0\n  (:k₍₋₁₎)          0.0957964    0.956835    0.0726316  -0.0\n  (:z₍₋₁₎)          0.134937     1.24187     1.37681     0.2\n  (:eps_z₍ₓ₎)       0.00674687   0.0620937   0.0688406   0.01\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_solution-Union{Tuple{S}, Tuple{MacroModelling.ℳ, Vector{S}}} where S<:Real","page":"API","title":"MacroModelling.get_solution","text":"get_solution(\n    𝓂,\n    parameters;\n    algorithm,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm\n)\n\n\nReturn the components of the solution of the model: non-stochastic steady state (NSSS), and solution martrices corresponding to the order of the solution. Note that all returned objects have the variables in rows and the solution matrices have as columns the state variables followed by the perturbation/volatility parameter for higher order solution matrices and lastly the exogenous shocks. Higher order perturbation matrices are sparse and have the Kronecker product of the forementioned elements as columns. The last element, a Boolean indicates whether the solution is numerically accurate. Function to use when differentiating IRFs with respect to parameters.\n\nArguments\n\n𝓂: object created by @model and @parameters.\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\n\nKeyword Arguments\n\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nTuple consisting of a Vector containing the NSSS, followed by a Matrix containing the first order solution matrix. In case of higher order solutions, SparseMatrixCSC represent the higher order solution matrices. The last element is a Bool indicating the correctness of the solution provided.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_solution(RBC, RBC.parameter_values)\n# output\n([5.936252888048724, 47.39025414828808, 6.884057971014486, 0.0], \n [0.09579643002421227 0.1349373930517757 0.006746869652588215; \n  0.9568351489231555 1.241874201151121 0.06209371005755664; \n  0.07263157894736819 1.376811594202897 0.06884057971014486; \n  0.0 0.19999999999999998 0.01], true)\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_ss","page":"API","title":"MacroModelling.get_ss","text":"See get_steady_state\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_standard_deviation-Tuple","page":"API","title":"MacroModelling.get_standard_deviation","text":"Wrapper for get_moments with standard_deviation = true and non_stochastic_steady_state = false, variance = false, covariance = false.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_state_variables-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_state_variables","text":"get_state_variables(𝓂)\n\n\nReturns the state variables of the model. State variables occur in the past and not in the future or occur in all three: past, present, and future.\n\nIn case programmatic model writing was used this function returns the parsed variables (see z in example).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the state variables.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_state_variables(RBC)\n# output\n10-element Vector{String}:\n \"c\"\n \"eps_news{TFP}\"\n \"eps_news{δ}\"\n \"k\"\n \"kᴸ⁽⁻²⁾\"\n \"kᴸ⁽⁻³⁾\"\n \"kᴸ⁽⁻¹⁾\"\n \"q\"\n \"z{TFP}\"\n \"z{δ}\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_statistics-Union{Tuple{T}, Tuple{Any, Vector{T}}} where T","page":"API","title":"MacroModelling.get_statistics","text":"get_statistics(\n    𝓂,\n    parameter_values;\n    parameters,\n    non_stochastic_steady_state,\n    mean,\n    standard_deviation,\n    variance,\n    covariance,\n    autocorrelation,\n    autocorrelation_periods,\n    algorithm,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm,\n    lyapunov_algorithm,\n    verbose,\n    tol\n)\n\n\nReturn the first and second moments of endogenous variables using either the linearised solution or the pruned second or pruned third order perturbation solution. By default returns a Dict with: non-stochastic steady state (NSSS), and standard deviations, but can also return variances, and covariance matrix. Values are returned in the order given for the specific moment. Function to use when differentiating model moments with respect to parameters.\n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\nparameter_values [Type: Vector]: Parameter values. If parameter_names is not explicitly defined, parameter_values are assumed to correspond to the parameters and the order of the parameters declared in the @parameters block.\n\nKeyword Arguments\n\nparameters [Type: Vector{Symbol}]: Corresponding names in the same order as parameter_values.\nnon_stochastic_steady_state [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the NSSS of selected variables. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all shocks less those related to auxiliary variables. :all will contain all variables.\nmean [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the mean of selected variables (the mean for the linearised solution is the NSSS). Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all shocks less those related to auxiliary variables. :all will contain all variables.\nstandard_deviation [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the standard deviation of selected variables. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all shocks less those related to auxiliary variables. :all will contain all variables.\nvariance [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the variance of selected variables. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all shocks less those related to auxiliary variables. :all will contain all variables.\ncovariance [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the covariance of selected variables. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. For grouped covariance computation, pass a Vector of Vectors (e.g. [[:y, :c], [:k, :i]]) to compute covariances only within each group, returning a single covariance matrix where cross-group covariances are set to zero. This allows more granular control over which covariances to compute. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all variables less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all variables less those related to occasionally binding constraints. :all will contain all variables.\nautocorrelation [Default: Symbol[], Type: Union{Symbol_input,String_input}]: variables for which to show the autocorrelation of selected variables. Inputs can be a variable name passed on as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc contains all shocks less those related to auxiliary variables and related to occasionally binding constraints (obc). :all_excluding_obc contains all shocks less those related to auxiliary variables. :all will contain all variables.\nautocorrelation_periods [Default: 1:5, Type = UnitRange{Int}]: periods for which to return the autocorrelation of selected variables\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nDict with the name of the statistics and the corresponding vectors (NSSS, mean, standard deviation, variance) or matrices (covariance, autocorrelation).\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_statistics(RBC, RBC.parameter_values, parameters = RBC.parameters, standard_deviation = RBC.var)\n# output\nDict{Symbol, AbstractArray{Float64}} with 1 entry:\n  :standard_deviation => [0.0266642, 0.264677, 0.0739325, 0.0102062]\n\n# For grouped covariance (computing covariances only within specified groups):\nget_statistics(RBC, RBC.parameter_values, covariance = [[:c, :k], [:y, :i]])\n# output\nDict{Symbol, AbstractArray{Float64}} with 1 entry:\n  :covariance => [...4x4 matrix with c-k covariances filled, y-i covariances filled, and cross-group elements set to zero...]\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_std","page":"API","title":"MacroModelling.get_std","text":"Wrapper for get_moments with standard_deviation = true and non_stochastic_steady_state = false, variance = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_stdev","page":"API","title":"MacroModelling.get_stdev","text":"Wrapper for get_moments with standard_deviation = true and non_stochastic_steady_state = false, variance = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_steady_state-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_steady_state","text":"get_steady_state(\n    𝓂;\n    parameters,\n    derivatives,\n    stochastic,\n    algorithm,\n    parameter_derivatives,\n    return_variables_only,\n    verbose,\n    silent,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    sylvester_algorithm\n)\n\n\nReturn the (non-stochastic) steady state, calibrated parameters, and derivatives with respect to model parameters.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nderivatives [Default: true, Type: Bool]: calculate derivatives with respect to the parameters.\nparameter_derivatives [Default: :all]: parameters for which to calculate partial derivatives. Inputs can be a parameter name passed on as either a Symbol or String (e.g. :alpha, or \"alpha\"), or Tuple, Matrix or Vector of String or Symbol. :all will include all parameters.\nstochastic [Default: false, Type: Bool]: return stochastic steady state using second order perturbation if no other higher order perturbation algorithm is provided in algorithm.\nreturn_variables_only [Default: false, Type: Bool]: return only variables and not calibrated parameters.\nalgorithm [Default: first_order, Type: Symbol]: algorithm to solve for the dynamics of the model. Available algorithms: :first_order, :second_order, :pruned_second_order, :third_order, :pruned_third_order\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nsylvester_algorithm [Default: selector that uses doubling for smaller problems and switches to bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. Input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solutions' Sylvester equation. If only one element is provided it corresponds to the second order perturbation solutions' Sylvester equation.\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows. The columns show the (non-stochastic) steady state and parameters for which derivatives are taken. \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nget_steady_state(RBC)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables_and_calibrated_parameters ∈ 4-element Vector{Symbol}\n→   Steady_state_and_∂steady_state∂parameter ∈ 6-element Vector{Symbol}\nAnd data, 4×6 Matrix{Float64}:\n        (:Steady_state)  (:std_z)  (:ρ)     (:δ)      (:α)       (:β)\n  (:c)   5.93625          0.0       0.0   -116.072    55.786     76.1014\n  (:k)  47.3903           0.0       0.0  -1304.95    555.264   1445.93\n  (:q)   6.88406          0.0       0.0    -94.7805   66.8912   105.02\n  (:z)   0.0              0.0       0.0      0.0       0.0        0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_steady_state_equations-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_steady_state_equations","text":"get_steady_state_equations(𝓂)\n\n\nReturn the non-stochastic steady state (NSSS) equations of the model. The difference to the equations as they were written in the @model block is that exogenous shocks are set to 0, time subscripts are eliminated (e.g. c[-1] becomes c), trivial simplifications are carried out (e.g. log(k) - log(k) = 0), and auxiliary variables are added for expressions that cannot become negative. \n\nAuxiliary variables facilitate the solution of the NSSS problem. The package substitutes expressions which cannot become negative with auxiliary variables and adds another equation to the system of equations determining the NSSS. For example, log(c/q) cannot be negative and c/q is substituted by an auxiliary variable ➕₁ and an additional equation is added: ➕₁ = c / q.\n\nNote that the output assumes the equations are equal to 0. As in, -z{δ} * ρ{δ} + z{δ} implies -z{δ} * ρ{δ} + z{δ} = 0 and therefore: z{δ} * ρ{δ} = z{δ}.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the NSSS equations. \n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_steady_state_equations(RBC)\n# output\n9-element Vector{String}:\n \"(-β * ((k ^ (α - 1) * α * exp(z{TFP}) - δ * exp(z{δ})) + 1)) / c + 1 / c\"\n \"((c - k * (-δ * exp(z{δ}) + 1)) + k) - q\"\n \"-(k ^ α) * exp(z{TFP}) + q\"\n \"-z{TFP} * ρ{TFP} + z{TFP}\"\n \"-z{δ} * ρ{δ} + z{δ}\"\n \"➕₁ - c / q\"\n \"➕₂ - c / q\"\n \"(Δc_share - log(➕₁)) + log(➕₂)\"\n \"Δk_4q - 0\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_stochastic_steady_state-Tuple","page":"API","title":"MacroModelling.get_stochastic_steady_state","text":"Wrapper for get_steady_state with stochastic = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_third_order_solution-Tuple","page":"API","title":"MacroModelling.get_third_order_solution","text":"Wrapper for get_solution with algorithm = :third_order.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_var","page":"API","title":"MacroModelling.get_var","text":"Wrapper for get_moments with variance = true and non_stochastic_steady_state = false, standard_deviation = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_var_decomp","page":"API","title":"MacroModelling.get_var_decomp","text":"See get_variance_decomposition\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.get_variables-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_variables","text":"get_variables(𝓂)\n\n\nReturns the variables of the model without timing subscripts and not including auxiliary variables.\n\nIn case programmatic model writing was used this function returns the parsed variables (see z in Examples).\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nVector{String} of the variables.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z{TFP}[1]) * k[0]^(α - 1) + (1 - exp(z{δ}[1]) * δ))\n    c[0] + k[0] = (1 - exp(z{δ}[0])δ) * k[-1] + q[0]\n    q[0] = exp(z{TFP}[0]) * k[-1]^α\n    for shock in [TFP, δ]\n        z{shock}[0] = ρ{shock} * z{shock}[-1] + σ{shock} * (eps{shock}[x] + eps_news{shock}[x-1])\n    end\n    Δc_share[0] = log(c[0]/q[0]) - log(c[-1]/q[-1])\n    Δk_4q[0] = log(k[0]) - log(k[-4])\nend\n\n@parameters RBC begin\n    σ = 0.01\n    ρ = 0.2\n    capital_to_output = 1.5\n    k[ss] / (4 * q[ss]) = capital_to_output | δ\n    alpha = .5\n    α = alpha\n    β = 0.95\nend\n\nget_variables(RBC)\n# output\n7-element Vector{String}:\n \"c\"\n \"k\"\n \"q\"\n \"z{TFP}\"\n \"z{δ}\"\n \"Δc_share\"\n \"Δk_4q\"\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_variance-Tuple","page":"API","title":"MacroModelling.get_variance","text":"Wrapper for get_moments with variance = true and non_stochastic_steady_state = false, standard_deviation = false, covariance = false.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.get_variance_decomposition-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.get_variance_decomposition","text":"get_variance_decomposition(\n    𝓂;\n    parameters,\n    verbose,\n    tol,\n    quadratic_matrix_equation_algorithm,\n    lyapunov_algorithm\n)\n\n\nReturn the variance decomposition of endogenous variables with regards to the shocks using the linearised solution. \n\nIf occasionally binding constraints are present in the model, they are not taken into account here. \n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nKeyword Arguments\n\nparameters [Default: nothing]: If nothing is provided, the solution is calculated for the parameters defined previously. Acceptable inputs are a Vector of parameter values, a Vector or Tuple of Pairs of the parameter Symbol or String and value. If the new parameter values differ from the previously defined the solution will be recalculated.\nquadratic_matrix_equation_algorithm [Default: schur, Type: Symbol]: algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling\nlyapunov_algorithm [Default: doubling, Type: Symbol]: algorithm to solve Lyapunov equation (A * X * A' + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :gmres\ntol [Default: Tolerances(), Type: Tolerances]: define various tolerances for the algorithm used to solve the model. See documentation of Tolerances for more details: ?Tolerances.\nverbose [Default: false, Type: Bool]: print information about results of the different solvers used to solve the model (non-stochastic steady state solver, Sylvester equations, Lyapunov equation, and quadratic matrix equation).\n\nReturns\n\nKeyedArray (from the AxisKeys package) with variables in rows, and shocks in columns.\n\nExamples\n\nusing MacroModelling\n\n@model RBC_CME begin\n    y[0]=A[0]*k[-1]^alpha\n    1/c[0]=beta*1/c[1]*(alpha*A[1]*k[0]^(alpha-1)+(1-delta))\n    1/c[0]=beta*1/c[1]*(R[0]/Pi[+1])\n    R[0] * beta =(Pi[0]/Pibar)^phi_pi\n    A[0]*k[-1]^alpha=c[0]+k[0]-(1-delta*z_delta[0])*k[-1]\n    z_delta[0] = 1 - rho_z_delta + rho_z_delta * z_delta[-1] + std_z_delta * delta_eps[x]\n    A[0] = 1 - rhoz + rhoz * A[-1]  + std_eps * eps_z[x]\nend\n\n@parameters RBC_CME begin\n    alpha = .157\n    beta = .999\n    delta = .0226\n    Pibar = 1.0008\n    phi_pi = 1.5\n    rhoz = .9\n    std_eps = .0068\n    rho_z_delta = .9\n    std_z_delta = .005\nend\n\nget_variance_decomposition(RBC_CME)\n# output\n2-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n↓   Variables ∈ 7-element Vector{Symbol}\n→   Shocks ∈ 2-element Vector{Symbol}\nAnd data, 7×2 Matrix{Float64}:\n              (:delta_eps)  (:eps_z)\n  (:A)         9.78485e-31   1.0\n  (:Pi)        0.0156771     0.984323\n  (:R)         0.0156771     0.984323\n  (:c)         0.0134672     0.986533\n  (:k)         0.00869568    0.991304\n  (:y)         0.000313462   0.999687\n  (:z_delta)   1.0           0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.has_missing_parameters-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.has_missing_parameters","text":"has_missing_parameters(𝓂)\n\n\nReturns whether the model has missing parameters that need to be provided before solving.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\nReturns\n\nBool indicating whether the model has missing parameters.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\nend\n\nhas_missing_parameters(RBC)\n# output\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.import_dynare","page":"API","title":"MacroModelling.import_dynare","text":"See translate_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.import_model","page":"API","title":"MacroModelling.import_model","text":"See translate_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.infer_step-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Number","page":"API","title":"MacroModelling.infer_step","text":"infer_step(x_axis)\n\nInfer the step for an axis.\n\nFor dates, if the last two points share the same day-of-month, the step is inferred in whole months (e.g. Month(1), Month(3), …). Otherwise the raw difference is used. For non time types, uses the plain difference.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.simulate-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.simulate","text":"Wrapper for get_irf with shocks = :simulate. Function returns values in levels by default.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.ss-Tuple","page":"API","title":"MacroModelling.ss","text":"See get_steady_state\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.sss-Tuple","page":"API","title":"MacroModelling.sss","text":"Wrapper for get_steady_state with stochastic = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.std","page":"API","title":"MacroModelling.std","text":"Wrapper for get_moments with standard_deviation = true and non_stochastic_steady_state = false, variance = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.stdev","page":"API","title":"MacroModelling.stdev","text":"Wrapper for get_moments with standard_deviation = true and non_stochastic_steady_state = false, variance = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.steady_state","page":"API","title":"MacroModelling.steady_state","text":"See get_steady_state\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.translate_dynare_file","page":"API","title":"MacroModelling.translate_dynare_file","text":"See translate_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.translate_mod_file-Tuple{AbstractString}","page":"API","title":"MacroModelling.translate_mod_file","text":"translate_mod_file(path_to_mod_file)\n\n\nReads in a dynare .mod-file, adapts the syntax, tries to capture parameter definitions, and writes a julia file in the same folder containing the model equations and parameters in MacroModelling.jl syntax. This function is not guaranteed to produce working code. It's purpose is to make it easier to port a model from dynare to MacroModelling.jl. \n\nThe recommended workflow is to use this function to translate a .mod-file, and then adapt the output so that it runs and corresponds to the input.\n\nNote that this function copies the .mod-file to a temporary folder and executes it there. All references within that .mod-file are therefore not valid (because those filesare not copied) and must be made copied into the .mod-file.\n\nArguments\n\npath_to_mod_file [Type: AbstractString]: path including filename of the .mod-file to be translated\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.var","page":"API","title":"MacroModelling.var","text":"Wrapper for get_moments with variance = true and non_stochastic_steady_state = false, standard_deviation = false, covariance = false.\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.write_dynare_file","page":"API","title":"MacroModelling.write_dynare_file","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.write_mod_file-Tuple{MacroModelling.ℳ}","page":"API","title":"MacroModelling.write_mod_file","text":"write_mod_file(m)\n\n\nWrites a dynare .mod-file in the current working directory. This function is not guaranteed to produce working code. It's purpose is to make it easier to port a model from MacroModelling.jl to dynare. \n\nThe recommended workflow is to use this function to write a .mod-file, and then adapt the output so that it runs and corresponds to the input.\n\nArguments\n\n𝓂: object created by @model and @parameters.\n\n\n\n\n\n","category":"method"},{"location":"api/#MacroModelling.write_to_dynare","page":"API","title":"MacroModelling.write_to_dynare","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.write_to_dynare_file","page":"API","title":"MacroModelling.write_to_dynare_file","text":"See write_mod_file\n\n\n\n\n\n","category":"function"},{"location":"api/#MacroModelling.@model-Tuple{Any, Vararg{Any}}","page":"API","title":"MacroModelling.@model","text":"Parses the model equations and assigns them to an object.\n\nArguments\n\n𝓂: name of the object to be created containing the model information.\nex: equations\n\nOptional arguments to be placed between 𝓂 and ex\n\nmax_obc_horizon [Default: 40, Type: Int]: maximum length of anticipated shocks and corresponding unconditional forecast horizon over which the occasionally binding constraint is to be enforced. Increase this number if no solution is found to enforce the constraint.\n\nVariables must be defined with their time subscript in square brackets. Endogenous variables can have the following:\n\npresent: c[0]\nnon-stochastic steady state: c[ss] instead of ss any of the following is also a valid flag for the non-stochastic steady state: ss, stst, steady, steadystate, steady_state, and the parser is case-insensitive (SS or sTst will work as well).\npast: c[-1] or any negative Integer: e.g. c[-12]\nfuture: c[1] or any positive Integer: e.g. c[16] or c[+16]\n\nSigned integers are recognised and parsed as such.\n\nExogenous variables (shocks) can have the following:\n\npresent: eps_z[x] instead of x any of the following is also a valid flag for exogenous variables: ex, exo, exogenous, and the parser is case-insensitive (Ex or exoGenous will work as well).\npast: eps_z[x-1]\nfuture: eps_z[x+1]\n\nParameters enter the equations without square brackets.\n\nIf an equation contains a max or min operator, the default dynamic (first order) solution of the model will enforce the occasionally binding constraint. This enforcement can be disabled by setting ignore_obc = true in the relevant function calls.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\nProgrammatic model writing\n\nParameters and variables can be indexed using curly braces: e.g. c{H}[0], eps_z{F}[x], or α{H}.\n\nfor loops can be used to write models programmatically. They can either be used to generate expressions where the time index or the index in curly braces is iterated over:\n\ngenerate equation with different indices in curly braces: for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\ngenerate multiple equations with different indices in curly braces: for co in [H, F] K{co}[0] = (1-delta{co}) * K{co}[-1] + S{co}[0] end\ngenerate equation with different time indices: Y_annual[0] = for lag in -3:0 Y[lag] end or R_annual[0] = for operator = :*, lag in -3:0 R[lag] end\n\nReturns\n\nNothing. The macro creates the model 𝓂 in the calling scope.\n\n\n\n\n\n","category":"macro"},{"location":"api/#MacroModelling.@parameters-Tuple{Any, Vararg{Any}}","page":"API","title":"MacroModelling.@parameters","text":"Adds parameter values and calibration equations to the previously defined model. Allows to provide an initial guess for the non-stochastic steady state (NSSS).\n\nArguments\n\n𝓂: name of the object previously created containing the model information.\nex: parameter, parameters values, and calibration equations\n\nParameters can be defined in either of the following ways:\n\nplain number: δ = 0.02\nexpression containing numbers: δ = 1/50\nexpression containing other parameters: δ = 2 * std_z in this case it is irrelevant if std_z is defined before or after. The definitions including other parameters are treated as a system of equations and solved accordingly.\nexpressions containing a target parameter and an equations with endogenous variables in the non-stochastic steady state, and other parameters, or numbers: k[ss] / (4 * q[ss]) = 1.5 | δ or α | 4 * q[ss] = δ * k[ss] in this case the target parameter will be solved simultaneously with the non-stochastic steady state using the equation defined with it.\n\nOptional arguments to be placed between 𝓂 and ex\n\nguess [Type: Dict{Symbol, <:Real}, Dict{String, <:Real}}]: Guess for the non-stochastic steady state. The keys must be the variable (and calibrated parameters) names and the values the guesses. Missing values are filled with standard starting values.\nverbose [Default: false, Type: Bool]: print more information about how the non-stochastic steady state is solved\nsilent [Default: false, Type: Bool]: do not print any information\nsymbolic [Default: false, Type: Bool]: try to solve the non-stochastic steady state symbolically and fall back to a numerical solution if not possible\nperturbation_order [Default: 1, Type: Int]: take derivatives only up to the specified order at this stage. When working with higher order perturbation later on, respective derivatives will be taken at that stage.\nsimplify [Default: true, Type: Bool]: whether to eliminate redundant variables and simplify the non-stochastic steady state (NSSS) problem. Setting this to false can speed up the process, but might make it harder to find the NSSS. If the model does not parse at all (at step 1 or 2), setting this option to false might solve it.\n\nDelayed parameter definition\n\nNot all parameters need to be defined in the @parameters macro. Calibration equations using the | syntax and parameters defined as functions of other parameters must be declared here, but simple parameter value assignments (e.g., α = 0.5) can be deferred and provided later by passing them to any function that accepts the parameters argument (e.g., get_irf, get_steady_state, simulate). \n\nParameter ordering: When some parameters are not defined in @parameters, the final parameter vector follows a specific order: first come the parameters defined in @parameters (in their declaration order), followed by any missing parameters (in alphabetical order). This ordering is important when passing parameter values by position rather than by name in subsequent function calls.\n\nExamples\n\nusing MacroModelling\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC verbose = true begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\n@model RBC_calibrated begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\n@parameters RBC_calibrated verbose = true guess = Dict(:k => 3) begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    k[ss] / q[ss] = 2.5 | α\n    β = 0.95\nend\n\nProgrammatic model writing\n\nVariables and parameters indexed with curly braces can be either referenced specifically (e.g. c{H}[ss]) or generally (e.g. alpha). If they are referenced generally the parse assumes all instances (indices) are meant. For example, in a model where alpha has two indices H and F, the expression alpha = 0.3 is interpreted as two expressions: alpha{H} = 0.3 and alpha{F} = 0.3. The same goes for calibration equations.\n\nReturns\n\nNothing. The macro assigns parameter values and calibration equations to 𝓂 in the calling scope.\n\n\n\n\n\n","category":"macro"},{"location":"tutorials/install/#Installation","page":"Installation","title":"Installation","text":"MacroModelling.jl requires julia version 1.10 or higher and an IDE is recommended (e.g. VS Code with the julia extension).\n\nOnce set up MacroModelling.jl can be installed by typing the following in the julia REPL:\n\nusing Pkg; Pkg.add(\"MacroModelling\")","category":"section"},{"location":"plot_irf/#Impulse-Response-Functions-(IRF)","page":"Impulse Response Functions","title":"Impulse Response Functions (IRF)","text":"Calling plot_irf computes IRFs for every exogenous shock and every endogenous variable by default, using the model's default solution method (first-order perturbation) and a one-standard-deviation positive shock.\n\nFirst, define and load a model:\n\n@model Gali_2015_chapter_3_nonlinear begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0])\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_nonlinear begin\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\nend\n\nNow, plot the IRFs using the default settings:\n\nplot_irf(Gali_2015_chapter_3_nonlinear)\n\n(Image: Gali 2015 IRF - eps_a shock)\n\nThe plots display every endogenous variable affected for each exogenous shock. Each page consists of multiple subplots, one per variable, and shows the response for a single shock at a time (mentioned in the title). The title includes the model name, shock identifier, sign of the impulse (positive by default), and the page indicator (e.g., (1/3)). Each subplot shows the steady state as a horizontal reference line (non-stochastic for first-order solutions, stochastic for higher orders). For strictly positive variables, a secondary axis displays percentage deviations.","category":"section"},{"location":"plot_irf/#Combine-or-compare-IRFs-with-plot_irf!","page":"Impulse Response Functions","title":"Combine or compare IRFs with plot_irf!","text":"The plot_irf! function (note the exclamation mark !) adds additional IRFs to an existing plot created with plot_irf, enabling direct comparison between different scenarios. Any input argument that affects the model's output (such as solution algorithm, parameter values, shocks, or initial states) can be varied to compare how these changes influence the impulse response functions. See the respective subsections below (e.g., Solution Algorithm, Parameter Values) for details on specific arguments.\n\nWhen using plot_irf!, the new IRF can be either overlaid for comparison (default) or stacked to show cumulative effects, depending on the plot_type argument (see Plot Type).\n\nLegend and table behavior:\n\nWhen inputs differ in one dimension (e.g., only the algorithm changes), the legend displays the value of that input dimension for each line (e.g., :first_order, :second_order).\nWhen inputs differ in multiple dimensions (e.g., both algorithm and parameters change), the legend shows sequential numbers (1, 2, 3, ...) and references a table below the plot that details all input differences for each numbered scenario.\nA separate table below shows the relevant steady state values for each scenario to help identify differences across solution methods or parameter values.\n\nExample with single input difference:\n\nWhen only one input differs (e.g., the solution algorithm), the legend shows the algorithm names directly:\n\n# Plot first-order solution\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a)\n\n# Add second-order solution to the same plot\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :second_order)\n\n(Image: Gali 2015 IRF - eps_a shock (first vs second order))\n\nThe legend will display :first_order and :second_order to identify each line.\n\nThe subplot y-axis labels change depending on the steady state values for each scenario. If the steady state values differ for a variable across scenarios, the y-axis label will indicate that the lines are in absolute deviations from the steady state. In that case no percent deviation is shown on the secondary y-axis, as the steady state values differ. In case the steady state values are the same across scenarios, the y-axis label indicates absolute levels on the primary y-axis and if the values are strictly positive the secondary y-axis shows the percent deviation scale.\n\nExample with multiple input differences:\n\nWhen multiple inputs differ (e.g., both algorithm and parameters), the legend shows sequential numbers and a table details the differences:\n\n# Plot with baseline parameters\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = :β => 0.99,\n    shocks = :eps_a)\n\n# Add with different algorithm AND parameters\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = :β => 0.95,\n    shocks = :eps_a,\n    algorithm = :second_order)\n\n(Image: Gali 2015 IRF - eps_a shock (comparing β values across algorithms))\n\nThe legend will show 1 and 2, with a table below the plot listing the parameter and algorithm values for each scenario.","category":"section"},{"location":"plot_irf/#Solution-Algorithm","page":"Impulse Response Functions","title":"Solution Algorithm","text":"IRFs can be plotted using different solution algorithms. The following example uses a second-order perturbation solution:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :second_order)\n\n(Image: Gali 2015 IRF - eps_a shock (second order))\n\nThe most notable difference is that at second order, dynamics are observed for S, which remains constant at first order (under certainty equivalence). Additionally, the steady state levels change because the stochastic steady state incorporates precautionary behavior (see horizontal lines).\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock (first order))\n\nTo compare the two solution methods side by side, use plot_irf! to add to an existing plot:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :second_order)\n\n(Image: Gali 2015 IRF - eps_a shock (first vs second order))\n\nThe plots now show both solution methods overlaid. The first-order solution is shown in blue, the second-order solution in red, as indicated in the legend below the plot. Note that the steady state levels can be different for the two solution methods. For variables where the relevant steady state is the same for both methods (e.g., A), the level appears on the left axis and percentage deviations on the right axis. For variables where the steady state differs between methods (e.g., C), only absolute level deviations (abs. Δ) appear on the left axis. The relevant steady state levels are shown in a table below the plot for reference (rounded to help identify differences).\n\nAdditional solution methods can be added to the same plot:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :pruned_third_order)\n\n(Image: Gali 2015 IRF - eps_a shock (multiple orders))\n\nNote that the pruned third-order solution incorporates time-varying risk and reverses the sign of the response for MC and N. The additional solution appears as another colored line with corresponding entries in both the legend and the steady state table below.","category":"section"},{"location":"plot_irf/#Initial-State","page":"Impulse Response Functions","title":"Initial State","text":"The initial_state argument (default: [0.0], type: Union{Vector{Vector{Float64}},Vector{Float64}}) defines the starting point for the model. For pruned solution algorithms, the initial state can be provided as multiple state vectors (Vector{Vector{Float64}}). In this case, the initial state must be specified in deviations from the non-stochastic steady state. For all other cases, specify the initial state in levels. For pruned solution algorithms with a Vector{Float64} initial state, only the first-order initial state vector is affected. The state includes all variables as well as exogenous variables in leads or lags if present. get_irf(𝓂, shocks = :none, variables = :all, periods = 1) returns a KeyedArray with all variables. The KeyedArray type is provided by the AxisKeys package.\n\nThe initial state defines the starting point for the IRF and must contain all model variables, including any leads or lags. To obtain the correct ordering and number of variables, call get_irf(𝓂, shocks = :none, variables = :all, periods = 1), which returns a KeyedArray with all variables in the correct order. The KeyedArray type is provided by the AxisKeys package. For example:\n\ninit_state = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true)\n\nOnly state variables will have an impact on the IRF. To check which variables are state variables:\n\nget_state_variables(Gali_2015_chapter_3_nonlinear)\n# 4-element Vector{String}:\n#  \"A\"\n#  \"S\"\n#  \"Z\"\n#  \"nu\"\n\nNow modify the initial state and set nu to 0.1:\n\ninit_state(:nu,:,:) .= 0.1\n\nThe modified initial state can now be input into the plot_irf function as a Vector:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state))\n\n(Image: Gali 2015 IRF - eps_a shock with custom initial state)\n\nNote that the example also defines the shock eps_a to show how the model reacts to a shock to A. For more details on the shocks argument see the corresponding section. This shows the difference in the IRF compared to starting from the non-stochastic steady state. Setting nu to a higher level effectively combines the effects of shocks to both nu and A. Since this uses a linear solution, these effects can be separated by stacking the components. Start with the IRF from the initial state as defined above:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    initial_state = vec(init_state))\n\n(Image: Gali 2015 IRF - no shock with initial state)\n\nthen stack the IRF from a shock to A on top of it:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    plot_type = :stack)\n\n(Image: Gali 2015 IRF - stacked initial state and eps_a shock)\n\nThe two components are shown with labels explained in the table below. The blue bars represent the first input (no shock, non-zero initial state), while the red bars correspond to the second input (starting from the steady state with an eps_a shock). Both components add up to the solid line that is the same as in the case of combining the eps_a shock with the initial state.\n\nThe same approach works for higher order solutions. Start with the second order solution. First, obtain the initial state in levels from the second order solution:\n\ninit_state_2nd = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true,\n    algorithm = :second_order)\n\nThen set nu to 0.1:\n\ninit_state_2nd(:nu, :, :) .= 0.1\n\nand plot the IRF for eps_a starting from this initial state:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state_2nd),\n    algorithm = :second_order)\n\nWhile these components can be stacked, they won't add up linearly due to the non-linear solution. Instead, the IRF behavior can be compared across the two solution methods:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state))\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state_2nd),\n    algorithm = :second_order)\n\n(Image: Gali 2015 IRF - eps_a shock with initial state (multiple solutions))\n\nThe legend shows two lines, with their input differences detailed in the table below. The first line corresponds to the initial state used for the first order solution as well as the IRF using the first order solution and the second line corresponds to the initial state used for the second order solution and using the second order solution. Note that the steady states differ between the two solution methods, which also affects the initial states (except for nu, which is set to 0.1 in both cases). A second table below the first one shows the relevant steady states for both solution methods. Since the relevant steady state of A is the same for both methods, the corresponding subplot shows the level on the left axis and percentage deviations on the right axis. For all other variables, the relevant steady state differs between methods, so only absolute level deviations appear (abs. Δ) on the left axis, with steady states listed in the table at the bottom.\n\nFor pruned solution methods the initial state can also be given as multiple state vectors (Vector{Vector{Float64}}). When providing a vector of vectors, values must be specified as differences from the non-stochastic steady state. When providing only one vector, values must be in levels, with the initial state having its full nonlinear effect in the first period. Using a vector of vectors allows setting the pruned higher-order auxiliary state vectors. While this can be useful in some cases, note that these higher-order auxiliary state vectors have only a linear impact in the first period. Start by assembling the vector of vectors:\n\ninit_state_pruned_3rd_in_diff = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true) - get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    algorithm = :pruned_third_order,\n    levels = true)\n# 3-dimensional KeyedArray(NamedDimsArray(...)) with keys:\n# ↓   Variables ∈ 23-element Vector{Symbol}\n# →   Periods ∈ 1-element UnitRange{Int64}\n# ◪   Shocks ∈ 1-element Vector{Symbol}\n# And data, 23×1×1 Array{Float64, 3}:\n# [:, :, 1] ~ (:, :, :none):\n#                    (1)\n#   (:A)               0.0\n#   (:C)               0.01899564383140051\n#   (:MC)              0.26061783703451824\n#   (:M_real)          0.014844948179111417\n#   (:N)               0.0256329467464953\n#   (:Pi)             -0.0013592503942323475\n#   (:Pi_star)        -0.0040777511826968205\n#   (:Q)              -0.00023912532361458627\n#   (:R)               0.0002649588073291298\n#   (:S)               3.3306690738754696e-16\n#   (:W_real)          0.18508712654020898\n#   (:Y)               0.01899564383140051\n#   (:Z)               0.0\n#   (:i_ann)           0.0010068434678508487\n#   (:log_N)           0.024432922221986165\n#   (:log_W_real)      0.1404893027764202\n#   (:log_y)           0.018324691666489368\n#   (:nu)             -1.3404049553225972e-17\n#   (:pi_ann)         -0.005437001576929203\n#   (:r_real_ann)      0.008306969164175088\n#   (:realinterest)    0.002186044516888197\n#   (:x_aux_1)        -0.7618262640813329\n#   (:x_aux_2)        -0.371793344047362\n\nFirst- and third-order dynamics don't affect the steady state through risk, so they are zero. The second-order steady state includes the risk adjustment. Assemble the vectors for the third order case:\n\ninit_states_pruned_3rd_vec = [\n    zero(vec(init_state_pruned_3rd_in_diff)),\n    vec(init_state_pruned_3rd_in_diff),\n    zero(vec(init_state_pruned_3rd_in_diff)),\n]\n\nThen set nu to 0.1 in the first order terms. Inspecting init_state_pruned_3rd_in_diff shows that nu is the 18th variable in the vector:\n\ninit_states_pruned_3rd_vec[1][18] = 0.1\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = init_states_pruned_3rd_vec,\n    algorithm = :pruned_third_order)\n\n(Image: Gali 2015 IRF - eps_a shock with pruned 3rd order vector)\n\nAlternatively, a simple vector can be used for the initial state. In this case the values must be in levels and the impact of the initial state is assumed to have the full nonlinear effect in the first period:\n\ninit_state_pruned_3rd = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true,\n    algorithm = :pruned_third_order)\n\ninit_state_pruned_3rd(:nu, :,  :) .= 0.1\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state_pruned_3rd),\n    algorithm = :pruned_third_order)\n\nCompare this with the second- and first-order versions, each starting from their respective steady states.\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state_2nd),\n    algorithm = :second_order)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    initial_state = vec(init_state))\n\n(Image: Gali 2015 IRF - eps_a shock with initial state (all solution methods))\n\nThis shows that the pruned third-order solution changes the dynamics while maintaining the same steady states as the second-order solution.","category":"section"},{"location":"plot_irf/#Shocks","page":"Impulse Response Functions","title":"Shocks","text":"The shocks argument (default: :all_excluding_obc) determines which IRFs to calculate. Shock names can be specified as either a Symbol or String (e.g., :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. :simulate triggers random draws of all shocks (excluding those related to occasionally binding constraints). :all_excluding_obc includes all shocks except OBC-related ones. :all also includes the OBC related shocks. A series of shocks can be passed using either a Matrix{Float64} or a KeyedArray{Float64}, with shocks (Symbol or String) in rows and periods in columns. The KeyedArray type is provided by the AxisKeys package. The simulation length equals the input length in the period dimension plus the number of periods specified in the periods argument. When using a KeyedArray{Float64}, ensure that rows are named with valid shock names of type Symbol or String. Any shocks not part of the model will trigger a warning. :none in combination with an initial_state can be used for deterministic simulations.\n\nIndividual shocks can be called by name:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock)\n\nThe same works if the shock name is input as a String:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = \"eps_a\")\n\nor multiple shocks at once (as String or Symbol):\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = [:eps_a, :eps_z])\n\n(Image: Gali 2015 IRF - eps_a shock)\n\n(Image: Gali 2015 IRF - eps_z shock)\n\nMultiple shocks can also be input as a Tuple:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = (:eps_a, :eps_z))\n\nor a Matrix:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = [:eps_a :eps_z])\n\nThen there are some predefined options:\n\n:all_excluding_obc (default) plots all shocks not used to enforce occasionally binding constraints (OBC).\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :all_excluding_obc)\n\n(Image: Gali 2015 IRF - eps_nu shock)\n\n:all plots all shocks including the OBC related ones.\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :all)\n\n:simulate triggers random draws of all shocks (excluding OBC-related shocks). The seed can be set to get reproducible results (e.g. import Random; Random.seed!(10)).\n\nAlternatively, the plot_simulation function can be used as a convenient wrapper. This is equivalent to calling plot_irf with shocks = :simulate and periods = 100.\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :simulate)\n\n# Equivalent to:\nplot_simulation(Gali_2015_chapter_3_nonlinear)\n\n(Image: Gali 2015 IRF - simulated shocks)\n\n:none can be used in combination with an initial_state for deterministic simulations. See the section on initial_state for more details. Start by getting the initial state in levels:\n\ninit_state = get_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    variables = :all,\n    periods = 1,\n    levels = true)\n\nOnly state variables will have an impact on the IRF. To check which variables are state variables:\n\nget_state_variables(Gali_2015_chapter_3_nonlinear)\n# 4-element Vector{String}:\n#  \"A\"\n#  \"S\"\n#  \"Z\"\n#  \"nu\"\n\nNow modify the initial state and set nu to 0.1:\n\ninit_state(:nu, :, :) .= 0.1\n\nNow input the modified initial state into the plot_irf function as a Vector and set shocks to :none:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :none,\n    initial_state = vec(init_state))\n\n(Image: Gali 2015 IRF - deterministic simulation from initial state)\n\nNote how this is similar to a shock to eps_nu but instead nu is set to 0.1 in the initial state and the model evolves deterministically from there. In the title the reference to the shock disappeared as it was set to :none.\n\nShocks can also be compared:\n\nshocks = get_shocks(Gali_2015_chapter_3_nonlinear)\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = shocks[1])\n\nfor s in shocks[2:end]\n    plot_irf!(Gali_2015_chapter_3_nonlinear,\n        shocks = s)\nend\n\n(Image: Gali 2015 IRF - all shocks compared)\n\nAll three shocks now appear overlaid in the same plot. The legend below the plot indicates which color corresponds to which shock and in the title the plot shows that all shocks are positive and includes multiple shocks.\n\nA series of shocks can be passed on using either a Matrix{Float64}, or a KeyedArray{Float64} as input with shocks (Symbol or String) in rows and periods in columns. Start with a KeyedArray:\n\nshocks = get_shocks(Gali_2015_chapter_3_nonlinear)\n\nn_periods = 3\n\nshock_keyedarray = KeyedArray(\n    zeros(length(shocks), n_periods),\n    Shocks = shocks,\n    Periods = 1:n_periods,\n)\n\nand then set a one standard deviation shock to eps_a in period 1, a negative 1/2 standard deviation shock to eps_z in period 2 and a 1/3 standard deviation shock to eps_nu in period 3:\n\nshock_keyedarray(\"eps_a\", [1]) .= 1\nshock_keyedarray(\"eps_z\", [2]) .= -1/2\nshock_keyedarray(\"eps_nu\", [3]) .= 1/3\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = shock_keyedarray)\n\n(Image: Gali 2015 IRF - shock series from KeyedArray)\n\nIn the title it is now mentioned that the input is a series of shocks and the values of the shock processes Z and nu move with the shifted timing and note that the impact of the eps_z shock has a - in front of it in the model definition, which is why they both move in the same direction. Note also that the number of periods is prolonged by the number of periods in the shock input. This example defines 3 periods of shocks and the default number of periods is 40, so the result shows 43 periods in total.\n\nThe same can be done with a Matrix:\n\nshock_matrix = zeros(length(shocks), n_periods)\n\nshock_matrix[1, 1] = 1\nshock_matrix[3, 2] = -1/2\nshock_matrix[2, 3] = 1/3\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = shock_matrix)\n\nIn certain circumstances a shock matrix might correspond to a certain scenario and when working with linear solutions, the IRF can be stacked for different scenarios or components of scenarios. Consider two scenarios defined by two different shock matrices:\n\nshock_matrix_1 = zeros(length(shocks), n_periods)\n\nshock_matrix_1[1, 1] = 1\nshock_matrix_1[3, 2] = -1/2\nshock_matrix_1[2, 3] = 1/3\n\n\nshock_matrix_2 = zeros(length(shocks), n_periods * 2)\n\nshock_matrix_2[1, 4] = -1\nshock_matrix_2[3, 5] = 1/2\nshock_matrix_2[2, 6] = -1/3\n\nPlot them on top of each other using the :stack option for the plot_type argument:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = shock_matrix_1)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = shock_matrix_2,\n    plot_type = :stack)\n\n(Image: Gali 2015 IRF - stacked shock matrices)\n\nThe blue bars correspond to the first shock matrix and the red to the second shock matrix and they are labeled accordingly in the legend below the plot. The solid line corresponds to the sum of both components. The result shows 46 periods as the second shock matrix has 6 periods and the first one 3 periods and the default number of periods is 40.","category":"section"},{"location":"plot_irf/#Simulation-Periods","page":"Impulse Response Functions","title":"Simulation Periods","text":"The periods argument (default: 40, type: Int) specifies the number of periods for which to calculate the output. When a matrix of shocks is provided, this defines how many periods to continue after the shock series. To set the number of periods to 10 (for the eps_a shock):\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    periods = 10,\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock (10 periods))\n\nThe x-axis automatically adjusts to show only 10 periods.\n\nThe following example uses a shock matrix with 15 periods as input, sets the periods argument to 20, and compares it to the previous 10-period plot:\n\nshock_matrix = zeros(length(shocks), 15)\n\nshock_matrix[1, 1] = .1\nshock_matrix[3, 5] = -1/2\nshock_matrix[2, 15] = 1/3\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = shock_matrix,\n    periods = 20)\n\n(Image: Gali 2015 IRF - mixed period lengths)\n\nThe x-axis adjusts to 35 periods, with the first plot ending after 10 periods and the second plot ending after 35 periods. The legend indicates which color corresponds to which shock, and the title shows that multiple shocks are in the plot.","category":"section"},{"location":"plot_irf/#Shock-Size","page":"Impulse Response Functions","title":"Shock Size","text":"The shock_size argument (default: 1.0, type: Real) controls the size of the shocks in standard deviations. Only affects shocks not provided as a Matrix or KeyedArray or set to :none. Negative values flip the sign of the shock.\n\nThe shock size can be set using the shock_size argument. The following example sets it to -2 standard deviations:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    shock_size = -2)\n\n(Image: Gali 2015 IRF - eps_a shock (size -2))\n\nNote how the shock's sign is flipped and the response magnitude is increased.","category":"section"},{"location":"plot_irf/#Negative-Shocks","page":"Impulse Response Functions","title":"Negative Shocks","text":"The negative_shock argument (default: false, type: Bool), when true, calculates IRFs for a negative shock. Only affects shocks not provided as a matrix or KeyedArray or set to :none.\n\nAlternatively, set negative_shock to true to obtain the IRF for a negative one-standard-deviation shock:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    negative_shock = true)\n\n(Image: Gali 2015 IRF - eps_z shock (negative))","category":"section"},{"location":"plot_irf/#Variables-to-Plot","page":"Impulse Response Functions","title":"Variables to Plot","text":"The variables argument (default: :all_excluding_obc) specifies for which variables to show results. Variable names can be specified as either a Symbol or String (e.g. :y or \"y\"), or Tuple, Matrix or Vector of String or Symbol. Any variables not part of the model will trigger a warning. :all_excluding_auxiliary_and_obc includes all variables except auxiliary variables and those related to occasionally binding constraints (OBC). :all_excluding_obc includes all variables except those related to occasionally binding constraints. :all includes all variables.\n\nSpecific variables can be selected to plot. The following example selects only output (Y) and inflation (Pi) using a Vector of Symbols:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = [:Y, :Pi])\n\n(Image: Gali 2015 IRF - selected variables (Y, Pi))\n\nThe plot now displays only the two selected variables (sorted alphabetically), with two subplots for each shock. The same can be done using a Tuple:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = (:Y, :Pi))\n\na Matrix:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = [:Y :Pi])\n\nor providing the variable names as Strings:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = [\"Y\", \"Pi\"])\n\nor a single variable as a Symbol:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = :Y)\n\nor as a String:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = \"Y\")\n\nThen there are some predefined options:\n\n:all_excluding_auxiliary_and_obc (default) plots all variables except auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = :all_excluding_auxiliary_and_obc)\n\n:all_excluding_obc plots all variables except those used to enforce occasionally binding constraints (OBC).\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = :all_excluding_obc)\n\nTo see auxiliary variables, use a model that defines them. The FS2000 model can be used:\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n    W[0] = l[0] / n[0]\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n    P[0] * c[0] = m[0]\n    m[0] - 1 + d[0] = l[0]\n    e[0] = exp(z_e_a  *  e_a[x])\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n    log_gy_obs[0] = log(gy_obs[0])\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\n@parameters FS2000 begin\n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nSince both c and P appear in t+2, they generate auxiliary variables in the model. Plotting the IRF for all variables excluding OBC-related ones means auxiliary variables are shown:\n\nplot_irf(FS2000, \n    variables = :all_excluding_obc)\n\n(Image: FS2000 IRF - e_a shock with auxiliary variables)\n\nBoth c and P appear twice: once as the variable itself and once as an auxiliary variable with the ᴸ⁽¹⁾ superscript, representing the value of the variable in t+1 as expected in t.\n\n:all plots all variables including auxiliary variables and those used to enforce occasionally binding constraints (OBC).\n\nUse the Gali_2015_chapter_3 model with an effective lower bound (note the use of the max function in the Taylor rule):\n\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n    R[0] = 1 / Q[0]\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n    R[0] = Pi[1] * realinterest[0]\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\n    C[0] = Y[0]\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n    log_y[0] = log(Y[0])\n    log_W_real[0] = log(W_real[0])\n    log_N[0] = log(N[0])\n    pi_ann[0] = 4 * log(Pi[0])\n    i_ann[0] = 4 * log(R[0])\n    r_real_ann[0] = 4 * log(realinterest[0])\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n    σ = 1\n    φ = 5\n    ϕᵖⁱ = 1.5\n    ϕʸ = 0.125\n    θ = 0.75\n    ρ_ν = 0.5\n    ρ_z = 0.5\n    ρ_a = 0.9\n    β = 0.99\n    η = 3.77\n    α = 0.25\n    ϵ = 9\n    τ = 0\n    std_a = .01\n    std_z = .05\n    std_nu = .0025\n    R > 1.0001\nend\n\nPlotting the IRF for all variables including OBC-related ones reveals the OBC-related auxiliary variables:\n\nplot_irf(Gali_2015_chapter_3_obc,\n    variables = :all)\n\n(Image: Gali 2015 OBC IRF - eps_z shock with OBC variables)\n\nThe OBC-related variables appear in the last subplot. Note that with the eps_z shock, the interest rate R hits the effective lower bound in period 1:\n\n(Image: Gali 2015 OBC IRF - eps_z shock hitting lower bound)\n\nThe effective lower bound is enforced using shocks to the equation containing the max statement. See the documentation for details on constructing occasionally binding constraints. For this specific model, examine the equations the parser generated to enforce the OBC:\n\nget_equations(Gali_2015_chapter_3_obc)\n# 68-element Vector{String}:\n#  \"W_real[0] = C[0] ^ σ * N[0] ^ φ\"\n#  \"Q[0] = ((β * (C[1] / C[0]) ^ -σ * Z[1]) / Z[0]) / Pi[1]\"\n#  \"R[0] = 1 / Q[0]\"\n#  \"Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\"\n#  \"R[0] = Pi[1] * realinterest[0]\"\n#  \"χᵒᵇᶜ⁺ꜝ¹ꜝˡ[0] = R̄ - R[0]\"\n#  ⋮\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁶⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁵⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽⁴⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁷⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁶⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽³⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁸⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁷⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽²⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁹⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁸⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽¹⁾[x]\"\n#  \"ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻⁴⁰⁾[0] = ϵᵒᵇᶜ⁺ꜝ¹ꜝᴸ⁽⁻³⁹⁾[-1] + activeᵒᵇᶜshocks * ϵᵒᵇᶜ⁺ꜝ¹ꜝ⁽⁰⁾[x]\"","category":"section"},{"location":"plot_irf/#Parameter-Values","page":"Impulse Response Functions","title":"Parameter Values","text":"When no parameters are provided, the solution uses the previously defined parameter values. Parameters can be provided as a Vector of values, or as a Vector or Tuple of Pairs mapping parameter Symbols or Strings to values. The solution is recalculated when new parameter values differ from the previous ones.\n\nStart by changing the discount factor β from 0.99 to 0.95:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = :β => 0.95,\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock (`β = 0.95`))\n\nThe steady states and dynamics changed as a result of changing the discount factor. To better visualize the differences between β = 0.99 and β = 0.95, the two IRFs can be overlaid (compared). Since parameter changes are permanent, first reset β = 0.99 before overlaying the IRF with β = 0.95 on top of it:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = :β => 0.99,\n    shocks = :eps_a)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = :β => 0.95,\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock comparing β values)\n\nThe legend below the plot indicates which color corresponds to which β value, with the table underneath showing the relevant steady states. Note that both the steady states and dynamics differ across the two β values, even when the steady state remains the same (e.g., for Y).\n\nMultiple parameters can also be changed simultaneously to compare the results to previous plots. This example changes β to 0.97 and τ to 0.5 using a Tuple of Pairs and define the variables with Symbols:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.97, :τ => 0.5),\n    shocks = :eps_a)\n\n(Image: Gali 2015 IRF - eps_a shock with multiple parameter changes)\n\nSince the plot function calls now differ in multiple input arguments, the legend indicates which color corresponds to which input combination, with the table showing steady states for all three combinations.\n\nA Vector of Pairs can also be used:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = [:β => 0.98, :τ => 0.25],\n    shocks = :eps_a)\n\nAlternatively, use a Vector of parameter values in the order they were defined in the model. To obtain them:\n\nparams = get_parameters(Gali_2015_chapter_3_nonlinear, values = true)\n# 16-element Vector{Pair{String, Float64}}:\n#       \"σ\" => 1.0\n#       \"φ\" => 5.0\n#     \"ϕᵖⁱ\" => 1.5\n#      \"ϕʸ\" => 0.125\n#       \"θ\" => 0.75\n#     \"ρ_ν\" => 0.5\n#     \"ρ_z\" => 0.5\n#     \"ρ_a\" => 0.9\n#       \"β\" => 0.95\n#       \"η\" => 3.77\n#       \"α\" => 0.25\n#       \"ϵ\" => 9.0\n#       \"τ\" => 0.5\n#   \"std_a\" => 0.01\n#   \"std_z\" => 0.05\n#  \"std_nu\" => 0.0025\n\nparam_vals = [p[2] for p in params]\n# 16-element Vector{Float64}:\n#  1.0\n#  5.0\n#  1.5\n#  0.125\n#  0.75\n#  0.5\n#  0.5\n#  0.9\n#  0.95\n#  3.77\n#  0.25\n#  9.0\n#  0.5\n#  0.01\n#  0.05\n#  0.0025\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = param_vals,\n    shocks = :eps_a)","category":"section"},{"location":"plot_irf/#Ignoring-Occasionally-Binding-Constraints","page":"Impulse Response Functions","title":"Ignoring Occasionally Binding Constraints","text":"The ignore_obc argument (default: false, type: Bool), when true, ignores occasionally binding constraints (OBC) even if they are part of the model. This is useful for comparing dynamics with and without OBC. For models with defined OBC, use the ignore_obc argument to ignore them. The following example compares the IRF of the Gali_2015_chapter_3_obc model with and without OBC. First, examine the IRF for a 3-standard-deviation eps_z shock with OBC enforced. See the shock_size and variables sections for more details on these input arguments. Since OBC is enforced by default, call:\n\nplot_irf(Gali_2015_chapter_3_obc,\n    shocks = :eps_z,\n    variables = [:Y, :R, :Pi, :C],\n    shock_size = 3)\n\n(Image: Gali 2015 OBC IRF - eps_z shock with OBC)\n\nThen overlay the IRF ignoring the OBC:\n\nplot_irf!(Gali_2015_chapter_3_obc,\n    shocks = :eps_z,\n    variables = [:Y, :R, :Pi, :C],\n    shock_size = 3,\n    ignore_obc = true)\n\n(Image: Gali 2015 OBC IRF - eps_z shock comparing with and without OBC)\n\nThe legend indicates which color corresponds to which ignore_obc value. Note how the interest rate R hits the effective lower bound in periods 1-3 when OBC is enforced (blue line) but not when OBC is ignored (red line). The dynamics of other variables also change when OBC is enforced. Enforcing the OBC results in a deeper and longer recession. The length of the lower bound period depends on the size of the shock.","category":"section"},{"location":"plot_irf/#Generalized-Impulse-Response-Functions","page":"Impulse Response Functions","title":"Generalized Impulse Response Functions","text":"The generalised_irf argument (default: false, type: Bool), when true, calculates generalized IRFs (GIRFs) instead of standard IRFs. GIRFs are computed by simulating the model with and without the shock, taking the difference, and averaging over multiple draws. GIRFs are particularly insightful for models solved to higher-order or models with occasionally binding constraints (OBC), because these non-linearities make them state-dependent. GIRFs then average out the state dependence and give an average IRF over the ergodic set of the model.\n\nAlternatively, the plot_girf function can be used as a convenient wrapper. This is equivalent to calling plot_irf with generalised_irf = true.\n\nThe following example compares the IRF of the Gali_2015_chapter_3_obc model for a 3-standard-deviation eps_z shock with and without using generalised_irf. First, examine the GIRF:\n\nplot_irf(Gali_2015_chapter_3_obc,\n    generalised_irf = true,\n    shocks = :eps_z,\n    variables = [:Y, :R, :Pi, :C],\n    shock_size = 3)\n\n(Image: Gali 2015 OBC IRF - eps_z shock GIRF)\n\nthen overlay the standard IRF:\n\nplot_irf!(Gali_2015_chapter_3_obc,\n    shocks = :eps_z,\n    variables = [:Y, :R, :Pi, :C],\n    shock_size = 3)\n\n(Image: Gali 2015 OBC IRF - eps_z shock comparing GIRF vs standard)\n\nThe legend indicates which color corresponds to which generalised_irf value. Note how the interest rate R hits the effective lower bound in periods 1-3 when using the standard IRF (red line). This suggests that the GIRF's accepted draws include many cases where the OBC is not binding. This can be confirmed by also overlaying the IRF ignoring the OBC.\n\nplot_irf!(Gali_2015_chapter_3_obc,\n    shocks = :eps_z,\n    variables = [:Y, :R, :Pi, :C],\n    shock_size = 3,\n    ignore_obc = true)\n\n(Image: Gali 2015 OBC IRF - eps_z shock GIRF vs standard vs no OBC)\n\nThe IRF ignoring the OBC shows R falling more, confirming that the GIRF draws include cases where the OBC is binding. Enforcing the OBC results in a deeper and longer recession. The length of the lower bound period depends on the size of the shock.\n\nAnother use case for GIRFs is examining the IRF of a model with a higher-order solution. The following example examines the IRF of the Gali_2015_chapter_3_nonlinear model solved with pruned second-order perturbation for a 1-standard-deviation eps_a shock with and without using generalised_irf. First, examine the GIRF:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    generalised_irf = true,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\n(Image: Gali 2015 IRF - eps_a shock GIRF (pruned 2nd order))\n\nSome lines are quite jittery, highlighting the state-dependent nature of the GIRF and the dominant effect of the randomness of the draws (e.g., N or MC).\n\nNow overlay the standard IRF for the pruned second order solution:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\n(Image: Gali 2015 IRF - eps_a shock GIRF vs standard (pruned 2nd order))\n\nThe comparison reveals that the response of S is highly state-dependent and can go either way depending on the economy's state when the shock occurs. The same applies to W_real, while other variables are less state-dependent, making the GIRF and standard IRF more similar.","category":"section"},{"location":"plot_irf/#Generalized-Impulse-Response-Function-Options","page":"Impulse Response Functions","title":"Generalized Impulse Response Function Options","text":"The generalised_irf_draws (default: 50, type: Int) and generalised_irf_warmup_iterations (default: 100, type: Int) arguments control the number of draws and warmup iterations. Increasing the number of draws improves GIRF accuracy but increases computation time. Warmup iterations ensure that the starting points of individual draws adequately explore the state space and represent the model's ergodic distribution.\n\nStart with the GIRF that had the wiggly lines above:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    generalised_irf = true,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\nthen overlay the GIRF with 1000 draws:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    generalised_irf = true,\n    generalised_irf_draws = 1000,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\nThe lines are now less jittery due to the increased number of draws:\n\n(Image: Gali 2015 IRF - eps_a shock GIRF with 1000 draws)\n\nthen overlay the GIRF with 5000 draws:\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    generalised_irf = true,\n    generalised_irf_draws = 5000,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\nThe lines are even smoother with the further increase in draws:\n\n(Image: Gali 2015 IRF - eps_a shock GIRF with 5000 draws)\n\nTo fully cover the model's ergodic distribution, consider increasing the number of warmup iterations as well. The following example overlays the standard IRF for the pruned second-order solution with the GIRF using 5000 draws and 500 warmup iterations:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    generalised_irf = true,\n    generalised_irf_draws = 5000,\n    generalised_irf_warmup_iterations = 500,\n    shocks = :eps_a,\n    algorithm = :pruned_second_order)\n\n(Image: Gali 2015 IRF - eps_a shock GIRF with 5000 draws and 500 warmup)\n\nWith this configuration, the difference between the GIRF and standard IRF is minimal. This suggests the average IRF (using sufficient amount of draws as well as warmup draws) is similar to the standard IRF but there is substantial state dependence in the model with a second-order pruned solution for a one-standard-deviation eps_a shock.","category":"section"},{"location":"plot_irf/#Plot-Labels","page":"Impulse Response Functions","title":"Plot Labels","text":"The label argument (type: Union{String,Symbol,Real}) controls labels that appear in plots when using the plot_irf! function to overlay multiple IRFs. By default, labels take on the values of the one dimensional input that differs and are sequential numbers in case the input differs along more than one dimension. Furthermore, custom labels can be provided using this argument. Acceptable inputs are a String, Symbol, or a Real.\n\nCustom labels are particularly useful when inputs differ in complex ways (e.g., shock matrices or multiple input changes). For example, let's compare the IRF of the Gali_2015_chapter_3_nonlinear model for a 1 standard deviation eps_a shock with β = 0.99 and τ = 0 to the IRF with β = 0.95 and τ = 0.5 using custom labels String input:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.99, :τ => 0.0),\n    shocks = :eps_a,\n    label = \"Std. params\")\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.95, :τ => 0.5),\n    shocks = :eps_a,\n    label = \"Alt. params\")\n\n(Image: Gali 2015 IRF - eps_a shock with custom labels)\n\nThe legend now displays the custom label names instead of sequential numbers (1 and 2). Additionally, the tables showing input differences and steady states use the custom labels in the first column instead of sequential numbers.\n\nThe same result can be achieved using Symbols (though they are less expressive):\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.99, :τ => 0.0),\n    shocks = :eps_a,\n    label = :standard)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.95, :τ => 0.5),\n    shocks = :eps_a,\n    label = :alternative)\n\nor with Real inputs:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.99, :τ => 0.0),\n    shocks = :eps_a,\n    label = 0.99)\n\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.95, :τ => 0.5),\n    shocks = :eps_a,\n    label = 0.95)","category":"section"},{"location":"plot_irf/#Plot-Type","page":"Impulse Response Functions","title":"Plot Type","text":"The plot_type argument (default: :compare, type: Symbol) determines how IRFs are visualized when multiple scenarios are displayed. Two options are available:\n\n:compare - Displays IRFs as separate lines for comparison across scenarios\n:stack - Stacks IRFs on top of each other to show cumulative effects\n\nThe :stack option is particularly useful when analyzing scenarios composed of multiple shock series, as it shows how different shocks contribute to the overall response. The :compare option is better suited for comparing IRFs across different parameter values or model specifications.","category":"section"},{"location":"plot_irf/#Using-:stack-to-layer-scenarios","page":"Impulse Response Functions","title":"Using :stack to layer scenarios","text":"When analyzing a scenario composed of multiple shocks, :stack visualizes the cumulative impact. For example, plot the combined effect of eps_a and nu shocks:\n\n# First shock in the scenario\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a)\n\n# Add second shock to show cumulative effect\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_nu,\n    plot_type = :stack)\n\n(Image: Gali 2015 IRF - stacked shocks (eps_a and eps_nu))\n\nThe :stack visualization shows how each shock contributes to the total response, with the second shock's effect layered on top of the first, and the solid black line representing the total effect.","category":"section"},{"location":"plot_irf/#Using-:compare-for-scenario-comparisons","page":"Impulse Response Functions","title":"Using :compare for scenario comparisons","text":"When comparing IRFs across different scenarios, :compare displays the responses as separate lines:\n\n# Baseline parameterization\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.99,),\n    shocks = :eps_a)\n\n# Alternative parameterization for comparison\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    parameters = (:β => 0.95,),\n    shocks = :eps_a,\n    plot_type = :compare)\n\n(Image: Gali 2015 IRF - comparing β values)\n\nThe :compare option (the default) makes it easy to see how parameter changes affect the IRF magnitude and persistence.","category":"section"},{"location":"plot_irf/#Plot-Attributes","page":"Impulse Response Functions","title":"Plot Attributes","text":"The plot_attributes argument (default: Dict(), type: Dict) accepts a dictionary of attributes passed on to the plotting function. See the Plots.jl documentation for details.\n\nThe color palette can be customized using the plot_attributes argument. The following example defines a custom color palette (inspired by the European Commission's economic reports) to plot and stack all IRFs for the Gali_2015_chapter_3_nonlinear model. First, define the custom color palette using hex color codes:\n\nec_color_palette =\n[\n    \"#FFD724\",  # \"Sunflower Yellow\"\n    \"#353B73\",  # \"Navy Blue\"\n    \"#2F9AFB\",  # \"Sky Blue\"\n    \"#B8AAA2\",  # \"Taupe Grey\"\n    \"#E75118\",  # \"Vermilion\"\n    \"#6DC7A9\",  # \"Mint Green\"\n    \"#F09874\",  # \"Coral\"\n    \"#907800\"   # \"Olive\"\n]\n\nNext, retrieve all shocks defined in the model:\n\nshocks = get_shocks(Gali_2015_chapter_3_nonlinear)\n# 3-element Vector{String}:\n#  \"eps_a\"\n#  \"eps_nu\"\n#  \"eps_z\"\n\nThen plot the IRF for the first shock:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = shocks[1])\n\nFinally, overlay the IRFs for the remaining shocks using the custom color palette:\n\nfor s in shocks[2:end]\n    plot_irf!(Gali_2015_chapter_3_nonlinear,\n        shocks = s,\n        plot_attributes = Dict(:palette => ec_color_palette),\n        plot_type = :stack)\nend\n\n(Image: Gali 2015 IRF - all shocks with custom color palette)\n\nThe colors of the shocks now follow the custom color palette.\n\nOther attributes such as the font family can also be modified (see here for GR font options):\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    plot_attributes = Dict(:fontfamily => \"computer modern\"))\n\n(Image: Gali 2015 IRF - eps_a shock with custom font)\n\nAll text in the plot now uses the Computer Modern font. Note that font rendering inherits the constraints of the plotting backend (GR in this case)—for example, the superscript ⁺ is not rendered properly for this font.","category":"section"},{"location":"plot_irf/#Plots-Per-Page","page":"Impulse Response Functions","title":"Plots Per Page","text":"The plots_per_page argument (default: 9, type: Int) controls the number of subplots per page. When the number of variables exceeds this value, multiple pages are created. The following example selects 9 variables and sets plots_per_page to 2:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    variables = [:Y, :Pi, :R, :C, :N, :W_real, :MC, :i_ann, :A],\n    shocks = :eps_a,\n    plots_per_page = 2)\n\n(Image: Gali 2015 IRF - eps_a shock (2 plots per page))\n\nThe first page displays the first two variables (sorted alphabetically) with two subplots for each shock. The title indicates the current page and the total number of pages.","category":"section"},{"location":"plot_irf/#Display-Plots","page":"Impulse Response Functions","title":"Display Plots","text":"The show_plots argument (default: true, type: Bool), when true, displays the plots; otherwise, they are only returned as an object.\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    show_plots = false)","category":"section"},{"location":"plot_irf/#Saving-Plots","page":"Impulse Response Functions","title":"Saving Plots","text":"The save_plots argument (default: false, type: Bool), when true, saves the plots to disk; otherwise, they are only displayed and returned as an object.\n\nRelated arguments control the saving behavior:\n\nsave_plots_format (default: :pdf, type: Symbol): output format of saved plots. See input formats compatible with GR for valid formats.\nsave_plots_path (default: \".\", type: String): path where plots are saved. If the path does not exist, it will be created automatically.\nsave_plots_name (default: \"irf\", type: Union{String, Symbol}): prefix prepended to the filename when saving plots.\n\nEach plot is saved as a separate file with a name indicating the prefix, model name, shocks, and a sequential number for multiple plots (e.g., irf__ModelName__shock__1.pdf).\n\nThe following example saves all IRFs for the Gali_2015_chapter_3_nonlinear model as PNG files in the ../plots directory with impulse_response as the filename prefix:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    save_plots = true,\n    save_plots_format = :png,\n    save_plots_path = \"./../plots\",\n    save_plots_name = :impulse_response)\n\nThe plots appear in the specified folder with the specified prefix. Each plot is saved in a separate file with a name reflecting the model, the shock, and a sequential index when the number of variables exceeds the plots per page.","category":"section"},{"location":"plot_irf/#Variable-and-Shock-Renaming-(rename-dictionary)","page":"Impulse Response Functions","title":"Variable and Shock Renaming (rename dictionary)","text":"The rename_dictionary argument (default: Dict(), type: AbstractDict{<:Union{Symbol, String}, <:Union{Symbol, String}}) maps variable or shock symbols to custom display names in plots. This is particularly useful when comparing models with different variable naming conventions, allowing them to be displayed with consistent labels.\n\nFor example, to rename variables for clearer display:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    rename_dictionary = Dict(:Y => \"Output\", :Pi => \"Inflation\", :R => \"Interest Rate\"))\n\n(Image: Gali 2015 IRF - eps_z shock rename dictionary)\n\nThis feature is especially valuable when overlaying IRFs from different models. Consider comparing FS2000 (which uses lowercase variable names like c) with Gali_2015_chapter_3_nonlinear (which uses uppercase like C). The rename_dictionary allows harmonizing these names when plotting them together:\n\n# First model (FS2000) with lowercase variable names\nplot_irf(FS2000,\n    shocks = :e_a,\n    rename_dictionary = Dict(:c => \"Consumption\", :y => \"Output\", :R => \"Interest Rate\"))\n\n# Overlay second model (Gali_2015_chapter_3_nonlinear) with different naming, mapped to same display names\nplot_irf!(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    rename_dictionary = Dict(:C => \"Consumption\", :Y => \"Output\", :R => \"Interest Rate\"))\n\n(Image: FS2000 and Gali 2015 IRF - multiple models with rename dictionary)\n\nBoth models now appear in the plot with consistent, readable labels, making comparison straightforward.\n\nThe rename_dictionary also works with shocks. For example, Gali_2015_chapter_3_nonlinear has shocks eps_a and eps_nu, while FS2000 has e_a and e_m. To compare these with consistent labels:\n\n# Gali model with shocks eps_a and eps_nu\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = [:eps_a, :eps_nu],\n    rename_dictionary = Dict(:eps_a => \"Technology Shock\", :eps_nu => \"Monetary Policy Shock\"))\n\n# FS2000 model with shocks e_a and e_m  \nplot_irf!(FS2000,\n    shocks = [:e_a, :e_m],\n    rename_dictionary = Dict(:e_a => \"Technology Shock\", :e_m => \"Monetary Policy Shock\"))\n\n(Image: FS2000 and Gali 2015 IRF - multiple models with shock rename dictionary)\n\nThe rename_dictionary accepts flexible type combinations for keys and values—both Symbol and String types work interchangeably:\n\n# All of these are valid and equivalent:\nDict(:Y => \"Output\")              # Symbol key, String value\nDict(\"Y\" => \"Output\")             # String key, String value\nDict(:Y => :Output)               # Symbol key, Symbol value\nDict(\"Y\" => :Output)              # String key, Symbol value\n\nThis flexibility is particularly useful for models like Backus_Kehoe_Kydland_1992, which uses String representations of variable and shock names (because of {}):\n\n# Define the Backus model (abbreviated for clarity)\n@model Backus_Kehoe_Kydland_1992 begin\n    for co in [H, F]\n        Y{co}[0] = ((LAMBDA{co}[0] * K{co}[-4]^theta{co} * N{co}[0]^(1-theta{co}))^(-nu{co}) + sigma{co} * Z{co}[-1]^(-nu{co}))^(-1/nu{co})\n        K{co}[0] = (1-delta{co})*K{co}[-1] + S{co}[0]\n        X{co}[0] = for lag in (-4+1):0 phi{co} * S{co}[lag] end\n        A{co}[0] = (1-eta{co}) * A{co}[-1] + N{co}[0]\n        L{co}[0] = 1 - alpha{co} * N{co}[0] - (1-alpha{co})*eta{co} * A{co}[-1]\n        U{co}[0] = (C{co}[0]^mu{co}*L{co}[0]^(1-mu{co}))^gamma{co}\n        psi{co} * mu{co} / C{co}[0]*U{co}[0] = LGM[0]\n        psi{co} * (1-mu{co}) / L{co}[0] * U{co}[0] * (-alpha{co}) = - LGM[0] * (1-theta{co}) / N{co}[0] * (LAMBDA{co}[0] * K{co}[-4]^theta{co}*N{co}[0]^(1-theta{co}))^(-nu{co})*Y{co}[0]^(1+nu{co})\n\n        for lag in 0:(4-1)  \n            beta{co}^lag * LGM[lag]*phi{co}\n        end +\n        for lag in 1:4\n            -beta{co}^lag * LGM[lag] * phi{co} * (1-delta{co})\n        end = beta{co}^4 * LGM[+4] * theta{co} / K{co}[0] * (LAMBDA{co}[+4] * K{co}[0]^theta{co} * N{co}[+4]^(1-theta{co})) ^ (-nu{co})* Y{co}[+4]^(1+nu{co})\n\n        LGM[0] = beta{co} * LGM[+1] * (1+sigma{co} * Z{co}[0]^(-nu{co}-1)*Y{co}[+1]^(1+nu{co}))\n        NX{co}[0] = (Y{co}[0] - (C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1]))/Y{co}[0]\n    end\n\n    (LAMBDA{H}[0]-1) = rho{H}{H}*(LAMBDA{H}[-1]-1) + rho{H}{F}*(LAMBDA{F}[-1]-1) + Z_E{H} * E{H}[x]\n    (LAMBDA{F}[0]-1) = rho{F}{F}*(LAMBDA{F}[-1]-1) + rho{F}{H}*(LAMBDA{H}[-1]-1) + Z_E{F} * E{F}[x]\n\n    for co in [H,F] C{co}[0] + X{co}[0] + Z{co}[0] - Z{co}[-1] end = for co in [H,F] Y{co}[0] end\nend\n\n@parameters Backus_Kehoe_Kydland_1992 begin\n    K_ss = 11\n    K[ss] = K_ss | beta\n    \n    mu      =    0.34\n    gamma   =    -1.0\n    alpha   =    1\n    eta     =    0.5\n    theta   =    0.36\n    nu      =    3\n    sigma   =    0.01\n    delta   =    0.025\n    phi     =    1/4\n    psi     =    0.5\n\n    Z_E = 0.00852\n    \n    rho{H}{H} = 0.906\n    rho{F}{F} = rho{H}{H}\n    rho{H}{F} = 0.088\n    rho{F}{H} = rho{H}{F}\nend\n\n# Backus model example showing String to String mapping\nplot_irf(Backus_Kehoe_Kydland_1992,\n    shocks = \"E{H}\",\n    rename_dictionary = Dict(\"C{H}\" => \"Home Consumption\", \n                             \"C{F}\" => \"Foreign Consumption\",\n                             \"Y{H}\" => \"Home Output\",\n                             \"Y{F}\" => \"Foreign Output\"))\n\n(Image: Backus, Kehoe, Kydland 1992 IRF - E{H} shock with rename dictionary)\n\nVariables or shocks not included in the dictionary retain their default names. The renaming applies to all plot elements including legends, axis labels, and tables.","category":"section"},{"location":"plot_irf/#Verbose-Output","page":"Impulse Response Functions","title":"Verbose Output","text":"The verbose argument (default: false, type: Bool), when true, enables verbose output related to solving the model\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    verbose = true)\n\nThe code outputs information about solving the steady state blocks. When parameters change, the first-order solution is recomputed; otherwise, it uses the cached solution:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    parameters = :β => 0.955,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.95       to 0.955\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 4.3825585462666584e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 5.438959822042073e-16","category":"section"},{"location":"plot_irf/#Numerical-Tolerances","page":"Impulse Response Functions","title":"Numerical Tolerances","text":"The tol argument (default: Tolerances(), type: Tolerances) defines various tolerances for the algorithm used to solve the model. See the Tolerances documentation for more details: ?Tolerances. The tolerances used by the numerical solvers can be adjusted. The Tolerances object allows setting tolerances for the non-stochastic steady state solver (NSSS), Sylvester equations, Lyapunov equation, and quadratic matrix equation (QME). For example, to set tighter tolerances (this example also changes parameters to force recomputation):\n\ncustom_tol = Tolerances(qme_acceptance_tol = 1e-12,\n    sylvester_acceptance_tol = 1e-12)\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    tol = custom_tol,\n    algorithm = :second_order,\n    parameters = :β => 0.9555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.955      to 0.9555\n# New parameters changed the steady state.\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Quadratic matrix equation solver: schur - converged: true in 0 iterations to tolerance: 3.692979383228777e-15\n# Sylvester equation - converged to tol 1.0e-12: true; iterations: 10; reached tol: 6.494758134185766e-17; algorithm: doubling\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n# Block: 1, - Solved using previous solution; residual norm: 0.0\n# Block: 2, - Solved using previous solution; residual norm: 7.021666937153402e-16\n\nThis is useful when higher precision is needed or when the default tolerances are insufficient for convergence. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_irf/#Quadratic-Matrix-Equation-Solver","page":"Impulse Response Functions","title":"Quadratic Matrix Equation Solver","text":"The quadratic_matrix_equation_algorithm argument (default: :schur, type: Symbol) specifies the algorithm to solve quadratic matrix equation (A * X ^ 2 + B * X + C = 0). Available algorithms: :schur, :doubling The quadratic matrix equation solver is used internally when solving the model to first order. Different algorithms are available. The :schur algorithm is generally faster and more reliable, while :doubling can be more precise in some cases (this example also changes parameters to force recomputation):\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    quadratic_matrix_equation_algorithm = :doubling,\n    parameters = :β => 0.95555,\n    verbose = true)\n# Parameter changes: \n#         β       from 0.9555     to 0.95555\n# New parameters changed the steady state.\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver: doubling - converged: true in 8 iterations to tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor most use cases, the default :schur algorithm is recommended. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"plot_irf/#Sylvester-Equation-Solver","page":"Impulse Response Functions","title":"Sylvester Equation Solver","text":"[Default: selector that uses :doubling for smaller problems and switches to :bicgstab for larger problems, Type: Union{Symbol,Vector{Symbol},Tuple{Symbol,Vararg{Symbol}}}]: Algorithm to solve the Sylvester equation (A * X * B + C = X). Available algorithms: :doubling, :bartels_stewart, :bicgstab, :dqgmres, :gmres. The input argument can contain up to two elements in a Vector or Tuple. The first (second) element corresponds to the second (third) order perturbation solution's Sylvester equation. When only one element is provided, it corresponds to the second-order perturbation solution's Sylvester equation. The algorithm to use can be specified for solving Sylvester equations in higher-order solutions. For example, select the :bartels_stewart algorithm for solving the second-order perturbation problem:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :second_order,\n    sylvester_algorithm = :bartels_stewart,\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: -1; reached tol: 6.19336731775721e-17; algorithm: bartels_stewart\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nFor third-order solutions, different algorithms can be specified for the second- and third-order Sylvester equations using a Tuple:\n\nplot_irf(Gali_2015_chapter_3_nonlinear,\n    shocks = :eps_a,\n    algorithm = :third_order,\n    sylvester_algorithm = (:doubling, :bicgstab),\n    verbose = true)\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Quadratic matrix equation solver previous solution has tolerance: 1.517007008035588e-16\n# Sylvester equation - previous solution achieves relative tol of 3.838708060339852e-17\n# Sylvester equation - converged to tol 1.0e-10: true; iterations: 23; reached tol: 8.328904812714592e-17; algorithm: bicgstab\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n# Block: 1, - Solved with newton using previous solution - 0.0 - 0.0 - [4, 4]\n# Block: 2, - Solved with newton using previous solution - 2.220446049250313e-16 - 1.2990825655800334e-16 - [3, 3]\n\nThe choice of algorithm affects both speed and precision: :doubling and :bartels_stewart are generally faster, while :bicgstab, :dqgmres, and :gmres are better for large sparse problems. Use this argument for specific needs or when encountering issues with the default solver.","category":"section"},{"location":"how-to/obc/#Occasionally-Binding-Constraints","page":"Occasionally binding constraints","title":"Occasionally Binding Constraints","text":"Occasionally binding constraints are a form of nonlinearity frequently used to model effects like the zero lower bound on interest rates, or borrowing constraints. Perturbation methods are not able to capture them as they are local approximations. Nonetheless, there are ways to combine the speed of perturbation solutions and the flexibility of occasionally binding constraints. MacroModelling.jl provides a convenient way to write down the constraints and automatically enforces the constraint equation with shocks. More specifically, the constraint equation is enforced for each periods unconditional forecast (default forecast horizon of 40 periods) by constraint equation specific anticipated shocks, while minimising the shock size.\n\nThis guide will demonstrate how to write down models containing occasionally binding constraints (e.g. effective lower bound and borrowing constraint), show some potential problems the user may encounter and how to overcome them, and go through some use cases.\n\nCommon problems that may occur are that no perturbation solution is found, or that the algorithm cannot find a combination of shocks which enforce the constraint equation. The former has to do with the fact that occasionally binding constraints can give rise to more than one steady state but only one is suitable for a perturbation solution. The latter has to do with the dynamics of the model and the fact that a finite amount of shocks is used to enforce the constraint equation.\n\nBeyond the examples outlined in this guide there is a version of Smets and Wouters (2003) with the ELB in the models folder (filename: SW03_obc.jl).","category":"section"},{"location":"how-to/obc/#Example:-Effective-lower-bound-on-interest-rates","page":"Occasionally binding constraints","title":"Example: Effective lower bound on interest rates","text":"","category":"section"},{"location":"how-to/obc/#Writing-a-model-with-occasionally-binding-constraints","page":"Occasionally binding constraints","title":"Writing a model with occasionally binding constraints","text":"Taking the Galı́ (2015), Chapter 3 model containing a Taylor rule and implementing an effective lower bound on interest rates. The Taylor rule in the model: R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]) needs to be modified so that R[0] never goes below an effective lower bound R̄. This can be done using the max operator: R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\n\nThe model definition after the change of the Taylor rule looks like this:\n\nusing MacroModelling\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n\n    R[0] = 1 / Q[0]\n\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n\n    R[0] = Pi[1] * realinterest[0]\n\n    C[0] = Y[0]\n\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n\n    log_y[0] = log(Y[0])\n\n    log_W_real[0] = log(W_real[0])\n\n    log_N[0] = log(N[0])\n\n    pi_ann[0] = 4 * log(Pi[0])\n\n    i_ann[0] = 4 * log(R[0])\n\n    r_real_ann[0] = 4 * log(realinterest[0])\n\n    M_real[0] = Y[0] / R[0] ^ η\n\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\nend\n\nIn the background the system of equations is augmented by a series of anticipated shocks added to the equation containing the constraint (max/min operator). This explains the large number of auxiliary variables and shocks.\n\nNext the parameters are defined including the new parameter defining the effective lower bound (which is set to 1, implementing a zero lower bound):\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n\n    σ = 1\n\n    φ = 5\n\n    ϕᵖⁱ = 1.5\n\n    ϕʸ = 0.125\n\n    θ = 0.75\n\n    ρ_ν = 0.5\n\n    ρ_z = 0.5\n\n    ρ_a = 0.9\n\n    β = 0.99\n\n    η = 3.77\n\n    α = 0.25\n\n    ϵ = 9\n\n    τ = 0\n\n    std_a = .01\n\n    std_z = .05\n\n    std_nu = .0025\nend","category":"section"},{"location":"how-to/obc/#Verify-the-non-stochastic-steady-state","page":"Occasionally binding constraints","title":"Verify the non-stochastic steady state","text":"Let's check out the non-stochastic steady state (NSSS):\n\nSS(Gali_2015_chapter_3_obc)\nSS(Gali_2015_chapter_3_obc)(:R,:)\n\nThere are a few things to note here. First, the NSSS values of the auxiliary variables related to the occasionally binding constraint are shown. Second, the NSSS value of R is 1.010101, and thereby the effective lower bound (ELB) is not binding in the NSSS. If the ELB were not binding, then the NSSS would not be a viable approximation point for perturbation. A perturbation solution can only be found if the effective lower bound is not binding in NSSS. Calling get_solution reveals that there is a stable solution at this NSSS:\n\nget_solution(Gali_2015_chapter_3_obc)\n\nIn case of a model or parameterisation that results in a NSSS where the ELB is binding, it is possible to add a restriction on the NSSS values so that the NSSS with binding ELB is excluded. With the above model, in order to exclude the non-viable NSSS the values of R needs to be restricted to be larger than the effective lower bound. This can be done by adding a constraint on the variable in the @parameter section. The model can be redefined:\n\n@model Gali_2015_chapter_3_obc begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n\n    R[0] = 1 / Q[0]\n\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n\n    R[0] = Pi[1] * realinterest[0]\n\n    C[0] = Y[0]\n\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n\n    log_y[0] = log(Y[0])\n\n    log_W_real[0] = log(W_real[0])\n\n    log_N[0] = log(N[0])\n\n    pi_ann[0] = 4 * log(Pi[0])\n\n    i_ann[0] = 4 * log(R[0])\n\n    r_real_ann[0] = 4 * log(realinterest[0])\n\n    M_real[0] = Y[0] / R[0] ^ η\n\n    R[0] = max(R̄ , 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0]))\nend\n\n@parameters Gali_2015_chapter_3_obc begin\n    R̄ = 1.0\n\n    σ = 1\n\n    φ = 5\n\n    ϕᵖⁱ = 1.5\n\n    ϕʸ = 0.125\n\n    θ = 0.75\n\n    ρ_ν = 0.5\n\n    ρ_z = 0.5\n\n    ρ_a = 0.9\n\n    β = 0.99\n\n    η = 3.77\n\n    α = 0.25\n\n    ϵ = 9\n\n    τ = 0\n\n    std_a = .01\n\n    std_z = .05\n\n    std_nu = .0025\n\n    R > 1.000001\nend\n\nand check the NSSS once more:\n\nSS(Gali_2015_chapter_3_obc)\nSS(Gali_2015_chapter_3_obc)(:R,:)\n\nNow R > R̄ is obtained, so that the constraint is not binding in the NSSS and a stable first order solution can be used:\n\nget_solution(Gali_2015_chapter_3_obc)","category":"section"},{"location":"how-to/obc/#Generate-model-output","page":"Occasionally binding constraints","title":"Generate model output","text":"Having defined the system with an occasionally binding constraint the model can simply be simulated by calling:\n\nimport StatsPlots\nimport Random\nRandom.seed!(20)\nplot_simulations(Gali_2015_chapter_3_obc)\n\n(Image: Simulation_elb)\n\nIn the background an optimisation problem is set up to find the smallest shocks in magnitude which enforce the equation containing the occasionally binding constraint over the unconditional forecast horizon (default 40 periods) at each period of the simulation. The plots show multiple spells of a binding effective lower bound and many other variables are skewed as a result of the nonlinearity. It can happen that it is not possible to find a combination of shocks which enforce the occasionally binding constraint equation. In this case one solution can be to make the horizon larger over which the algorithm tries to enforce the equation. This can be done by setting the parameter at the beginning of the @model section: @model Gali_2015_chapter_3_obc max_obc_horizon = 60 begin ... end.\n\nNext the effective lower bound will be changed to 0.99 and plotted once more:\n\nRandom.seed!(20)\nplot_simulations(Gali_2015_chapter_3_obc, parameters = :R̄ => 0.99)\n\n(Image: Simulation_elb2)\n\nNow, the effect of the effective lower bound becomes less important as it binds less often.\n\nIf the occasionally binding constraint should be ignored simply call:\n\nRandom.seed!(20)\nplot_simulations(Gali_2015_chapter_3_obc, ignore_obc = true)\n\n(Image: Simulation_no_elb)\n\nand the simulation is based on the first order solution approximated around the NSSS, which is the same as the one for the model without the modified Taylor rule.\n\nThe impulse response functions can be plotted for the eps_z shock, while setting the parameter of the occasionally binding constraint back to 1, as follows:\n\nplot_irf(Gali_2015_chapter_3_obc, shocks = :eps_z, parameters = :R̄ => 1.0)\n\n(Image: IRF_elb)\n\nAs can be seen R remains above the effective lower bound in the first period.\n\nNext, the model is simulated using a series of shocks. E.g. three positive shocks to eps_z in periods 5, 10, and 15 in decreasing magnitude:\n\nshcks = zeros(1,15)\nshcks[5] =  3.0\nshcks[10] = 2.0\nshcks[15] = 1.0\n\nsks = KeyedArray(shcks;  Shocks = [:eps_z], Periods = 1:15)  # KeyedArray is provided by the `AxisKeys` package\n\nplot_irf(Gali_2015_chapter_3_obc, \n            shocks = sks, \n            periods = 10)\n\n(Image: Shock_series_elb)\n\nThe effective lower bound is binding after all three shocks but the length of the constraint being binding varies with the shock size and is completely endogenous.\n\nLast but not least, the simulated moments of the model can be obtained (theoretical moments are not available):\n\nRandom.seed!(922)\nsims = get_irf(Gali_2015_chapter_3_obc, \n                parameters = :R̄ => 0.99, \n                periods = 500, \n                shocks = :simulate, \n                levels = true)\n\nThe mean and standard deviation of output can be examined:\n\nimport Statistics\nStatistics.mean(sims(:Y,:,:))\n\nand\n\nStatistics.std(sims(:Y,:,:))\n\nCompare this to the theoretical mean of the model without the occasionally binding constraint:\n\nget_mean(Gali_2015_chapter_3_obc)\nget_mean(Gali_2015_chapter_3_obc)(:Y,:)\n\nand the theoretical standard deviation:\n\nget_std(Gali_2015_chapter_3_obc)\nget_std(Gali_2015_chapter_3_obc)(:Y,:)\n\nThe mean of output is lower in the model with effective lower bound compared to the model without and the standard deviation is higher.","category":"section"},{"location":"how-to/obc/#Example:-Borrowing-constraint","page":"Occasionally binding constraints","title":"Example: Borrowing constraint","text":"","category":"section"},{"location":"how-to/obc/#Model-definition","page":"Occasionally binding constraints","title":"Model definition","text":"Starting with a consumption-saving model containing a borrowing constraint (see [@citet cuba2019likelihood] for details). Output is exogenously given, and households can only borrow up to a fraction of output and decide between saving and consumption. The first order conditions of the model are:\n\nbeginalign*\nY_t + B_t = C_t + R  B_t-1\nlog(Y_t) = rho  log(Y_t-1) + sigma  varepsilon_t\nC_t^-gamma = beta  R  mathbbE_t (C_t+1^-gamma) + lambda_t\n0 = lambda_t  (B_t - mY_t)\nendalign*\n\nin order to write this model down the Karush-Kuhn-Tucker condition (last equation) needs to be expressed using a max (or min) operator, so that it becomes:\n\n0 = max(B_t - mY_t -lambda_t)\n\nThis model containing an occasionally binding constraint can be written in a very convenient way:\n\n@model borrowing_constraint begin\n    Y[0] + B[0] = C[0] + R * B[-1]\n\n    log(Y[0]) = ρ * log(Y[-1]) + σ * ε[x]\n\n    C[0]^(-γ) = β * R * C[1]^(-γ) + λ[0]\n\n    0 = max(B[0] - m * Y[0], -λ[0])\nend\n\nIn the background the system of equations is augmented by a series of anticipated shocks added to the equation containing the constraint (max/min operator). This explains the large number of auxiliary variables and shocks.\n\nNext the parameters are defined as usual:\n\n@parameters borrowing_constraint begin\n    R = 1.05\n    β = 0.945\n    ρ = 0.9\n    σ = 0.05\n    m = 1\n    γ = 1\nend","category":"section"},{"location":"how-to/obc/#Working-with-the-model","page":"Occasionally binding constraints","title":"Working with the model","text":"For the non-stochastic steady state (NSSS) to exist the constraint has to be binding (B[0] = m * Y[0]). This implies a wedge in the Euler equation (λ > 0).\n\nThis can be checked by getting the NSSS:\n\nSS(borrowing_constraint)\n\nA common task is to plot impulse response functions for positive and negative shocks. This should allow understanding the role of the constraint.\n\nFirst, the StatsPlots package needs to be imported and then the positive shock can be plotted.\n\nimport StatsPlots\nplot_irf(borrowing_constraint)\n\n(Image: Positive_shock)\n\nThe constraint is no longer binding in the first five periods because Y and B do not increase by the same amount. They should move by the same amount in the case of a negative shock:\n\nimport StatsPlots\nplot_irf(borrowing_constraint, negative_shock = true)\n\n(Image: Negative_shock)\n\nand indeed in this case they move by the same amount. The difference between a positive and negative shock demonstrates the influence of the occasionally binding constraint.\n\nAnother common exercise is to plot the impulse response functions from a series of shocks. Assuming in period 10 there is a positive shock and in period 30 a negative one, and viewing the results for 50 more periods, this can be done as follows:\n\nshcks = zeros(1,30)\nshcks[10] =  .6\nshcks[30] = -.6\n\nsks = KeyedArray(shcks;  Shocks = [:ε], Periods = 1:30)  # KeyedArray is provided by the `AxisKeys` package\n\nplot_irf(borrowing_constraint, shocks = sks, periods = 50)\n\n(Image: Simulation)\n\nIn this case the difference between the shocks and the impact of the constraint become quite obvious. Comparing this with a version of the model that ignores the occasionally binding constraint, in order to plot the impulse response functions without dynamically enforcing the constraint simply write:\n\nplot_irf(borrowing_constraint, shocks = sks, periods = 50, ignore_obc = true)\n\n(Image: Simulation)\n\nAnother interesting statistic is model moments. As there are no theoretical moments reliance on simulated data is necessary:\n\nRandom.seed!(17339053787832050337)\nsims = get_irf(borrowing_constraint, \n                periods = 300, \n                shocks = :simulate, \n                levels = true)\n\nLet's look at the mean and standard deviation of borrowing:\n\nimport Statistics\nStatistics.mean(sims(:B,:,:))\n\nand\n\nStatistics.std(sims(:B,:,:))\n\nCompare this to the theoretical mean of the model without the occasionally binding constraint:\n\nget_mean(borrowing_constraint)\n\nand the theoretical standard deviation:\n\nget_std(borrowing_constraint)\n\nThe mean and standard deviation of borrowing is lower in the model with occasionally binding constraints compared to the model without.","category":"section"},{"location":"unfinished_docs/how_to/#Use-calibration-equations","page":"-","title":"Use calibration equations","text":"Next we need to add the parameters of the model. The macro @parameters <name of the model> takes care of this:\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    β = 0.95\nend\n\nNo need for line endings. If you want to define a parameter as a function of another parameter you can do this:\n\n@parameters RBC begin\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    beta1 = 1\n    beta2 = .95\n    β | β = beta2/beta1\nend\n\nNote that the parser takes parameters assigned to a numerical value first and then solves for the parameters defined by relationships: β | .... This means also the following will work:\n\n@parameters RBC begin\n    β | β = beta2/beta1\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α = 0.5\n    beta1 = 1\n    beta2 = .95\nend\n\nMore interestingly one can use (non-stochastic) steady state values in the relationships:\n\n@parameters RBC begin\n    β = .95\n    std_z = 0.01\n    ρ = 0.2\n    δ = 0.02\n    α | k[ss] / (4 * q[ss]) = 1.5\nend","category":"section"},{"location":"unfinished_docs/how_to/#Higher-order-perturbation-solutions","page":"-","title":"Higher order perturbation solutions","text":"","category":"section"},{"location":"unfinished_docs/how_to/#How-to-estimate-a-model","page":"-","title":"How to estimate a model","text":"","category":"section"},{"location":"unfinished_docs/how_to/#Interactive-plotting","page":"-","title":"Interactive plotting","text":"","category":"section"},{"location":"tutorials/calibration/#Calibration-/-method-of-moments-Gali-(2015)","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Calibration / method of moments - Gali (2015)","text":"This tutorial is intended to show the workflow to calibrate a model using the method of moments. The tutorial is based on a standard model of monetary policy and will showcase the use of gradient based optimisers and 2nd and 3rd order pruned solutions.","category":"section"},{"location":"tutorials/calibration/#Define-the-model","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Define the model","text":"The first step is always to name the model and write down the equations. For the Galı́ (2015), Chapter 3 this would go as follows:\n\nusing MacroModelling\n\n@model Gali_2015 begin\n    W_real[0] = C[0] ^ σ * N[0] ^ φ\n\n    Q[0] = β * (C[1] / C[0]) ^ (-σ) * Z[1] / Z[0] / Pi[1]\n\n    R[0] = 1 / Q[0]\n\n    Y[0] = A[0] * (N[0] / S[0]) ^ (1 - α)\n\n    R[0] = Pi[1] * realinterest[0]\n\n    R[0] = 1 / β * Pi[0] ^ ϕᵖⁱ * (Y[0] / Y[ss]) ^ ϕʸ * exp(nu[0])\n\n    C[0] = Y[0]\n\n    log(A[0]) = ρ_a * log(A[-1]) + std_a * eps_a[x]\n\n    log(Z[0]) = ρ_z * log(Z[-1]) - std_z * eps_z[x]\n\n    nu[0] = ρ_ν * nu[-1] + std_nu * eps_nu[x]\n\n    MC[0] = W_real[0] / (S[0] * Y[0] * (1 - α) / N[0])\n\n    1 = θ * Pi[0] ^ (ϵ - 1) + (1 - θ) * Pi_star[0] ^ (1 - ϵ)\n\n    S[0] = (1 - θ) * Pi_star[0] ^ (( - ϵ) / (1 - α)) + θ * Pi[0] ^ (ϵ / (1 - α)) * S[-1]\n\n    Pi_star[0] ^ (1 + ϵ * α / (1 - α)) = ϵ * x_aux_1[0] / x_aux_2[0] * (1 - τ) / (ϵ - 1)\n\n    x_aux_1[0] = MC[0] * Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ + α * ϵ / (1 - α)) * x_aux_1[1]\n\n    x_aux_2[0] = Y[0] * Z[0] * C[0] ^ (-σ) + β * θ * Pi[1] ^ (ϵ - 1) * x_aux_2[1]\n\n    log_y[0] = log(Y[0])\n\n    log_W_real[0] = log(W_real[0])\n\n    log_N[0] = log(N[0])\n\n    pi_ann[0] = 4 * log(Pi[0])\n\n    i_ann[0] = 4 * log(R[0])\n\n    r_real_ann[0] = 4 * log(realinterest[0])\n\n    M_real[0] = Y[0] / R[0] ^ η\nend\n\nFirst, the package is loaded and then the @model macro is used to define the model. The first argument after @model is the model name and will be the name of the object in the global environment containing all information regarding the model. The second argument to the macro are the equations, which are written down between begin and end. Equations can contain an equality sign or the expression is assumed to equal 0. Equations cannot span multiple lines (unless the expression is wrapped in brackets) and the timing of endogenous variables are expressed in the square brackets following the variable name (e.g. [-1] for the past period). Exogenous variables (shocks) are followed by a keyword in square brackets indicating them being exogenous (in this case [x]). Note that names can leverage julia's unicode capabilities (e.g. alpha can be written as α).","category":"section"},{"location":"tutorials/calibration/#Define-the-parameters","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Define the parameters","text":"Next the parameters of the model need to be added. The macro @parameters takes care of this:\n\n@parameters Gali_2015 begin\n    σ = 1\n\n    φ = 5\n\n    ϕᵖⁱ = 1.5\n    \n    ϕʸ = 0.125\n\n    θ = 0.75\n\n    ρ_ν = 0.5\n\n    ρ_z = 0.5\n\n    ρ_a = 0.9\n\n    β = 0.99\n\n    η = 3.77\n\n    α = 0.25\n\n    ϵ = 9\n\n    τ = 0\n\n    std_a = .01\n\n    std_z = .05\n\n    std_nu = .0025\nend\n\nThe block defining the parameters above only describes the simple parameter definitions the same way values are assigned (e.g. α = .25).\n\nNote that one parameter definition per line is required.","category":"section"},{"location":"tutorials/calibration/#Linear-solution","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Linear solution","text":"","category":"section"},{"location":"tutorials/calibration/#Inspect-model-moments","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Inspect model moments","text":"Given the equations and parameters, everything is available for the package to generate the theoretical model moments. The mean of the linearised model can be retrieved as follows:\n\nget_mean(Gali_2015)\n\nand the standard deviation like this:\n\nget_standard_deviation(Gali_2015)\n\nAlternatively, std or get_std can be used to achieve the same effect.\n\nAnother interesting output is the autocorrelation of the model variables:\n\nget_autocorrelation(Gali_2015)\n\nor the covariance:\n\nget_covariance(Gali_2015)","category":"section"},{"location":"tutorials/calibration/#Parameter-sensitivities","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Parameter sensitivities","text":"Before calibrating the model, examine how parameter changes affect model moments. MacroModelling.jl provides partial derivatives of model moments with respect to model parameters. This model is medium-sized, and derivatives are shown automatically. In this example, the sensitivity of the mean of all variables with respect to the production function parameter σ can be obtained like this:\n\nget_mean(Gali_2015, parameter_derivatives = :σ)\n\nor for multiple parameters:\n\nget_mean(Gali_2015, parameter_derivatives = [:σ, :α, :β, :ϕᵖⁱ, :φ])\n\nThe same can be done for standard deviation or variance, and all parameters:\n\nget_std(Gali_2015, parameter_derivatives = get_parameters(Gali_2015))\n\nget_variance(Gali_2015, parameter_derivatives = get_parameters(Gali_2015))\n\nThis information can be used to calibrate certain values to targets. For example, assuming higher real wages (:W_real), and lower inflation volatility are desired. Since there are too many variables and parameters to be shown here, only a subset of them is printed:\n\nget_mean(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi])\n\nget_std(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi])\n\nLooking at the sensitivity table it can be seen that lowering the production function parameter :α will increase real wages, but at the same time it will increase inflation volatility. This effect could be compensated by decreasing the standard deviation of the total factor productivity shock :std_a.","category":"section"},{"location":"tutorials/calibration/#Method-of-moments","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Method of moments","text":"Instead of doing this by hand a target can also be set and an optimiser can find the corresponding parameter values. In order to do that targets need to be defined, and an optimisation problem needs to be set up.\n\nThe targets are:\n\nMean of W_real = 0.7\nStandard deviation of Pi = 0.01\n\nFor the optimisation problem the L-BFGS algorithm implemented in Optim.jl is used. This optimisation algorithm is very efficient and gradient based. Note that all model outputs are differentiable with respect to the parameters using automatic and implicit differentiation.\n\nThe package provides functions specialised for the use with gradient based code (e.g. gradient-based optimisers or samplers). For model statistics get_statistics can be used to get the mean of real wages and the standard deviation of inflation like this:\n\nget_statistics(Gali_2015, Gali_2015.parameter_values, parameters = Gali_2015.parameters, mean = [:W_real], standard_deviation = [:Pi])\n\nFirst the model object is passed on, followed by the parameter values and the parameter names the values correspond to. Then the desired outputs are defined: for the mean real wages are wanted and for the standard deviation inflation is wanted. Outputs for variance, covariance, or autocorrelation can also be obtained the same way as for the mean and standard deviation.\n\nNext, a function measuring how close the model is to the target for given values of :α and :std_a can be defined:\n\nfunction distance_to_target(parameter_value_inputs)\n    model_statistics = get_statistics(Gali_2015, parameter_value_inputs, parameters = [:α, :std_a], mean = [:W_real], standard_deviation = [:Pi])\n    targets = [0.7, 0.01]\n    return sum(abs2, vcat(model_statistics[:mean], model_statistics[:standard_deviation]) - targets)\nend\n\nNow the function can be tested with the current parameter values. In case the parameter values are not known they can also be looked up like this:\n\nget_parameters(Gali_2015, values = true)\n\nthis allows testing the distance function:\n\ndistance_to_target([0.25, 0.01])\n\nNext pass it on to an optimiser and find the parameters corresponding to the best fit like this:\n\nusing Optim, LineSearches\nsol = Optim.optimize(distance_to_target,\n                        [0,0], \n                        [1,1], \n                        [0.25, 0.01], \n                        Optim.Fminbox(Optim.LBFGS(linesearch = LineSearches.BackTracking(order = 3))))\n\nThe first argument to the optimisation call is the function defined previously, followed by lower and upper bounds, the starting values, and finally the algorithm. For the algorithm Fminbox has to be added because bounds are present (optional) and the specific line search method is set to speed up convergence (recommended but optional).\n\nThe output shows that the optimisation almost perfectly matches the target and the values of the parameters found by the optimiser are:\n\nsol.minimizer\n\nslightly lower for both parameters (in line with the previous insights from the sensitivities).\n\nCombine the method of moments with estimation by adding the distance to the target as a penalty term to the posterior log-likelihood.","category":"section"},{"location":"tutorials/calibration/#Nonlinear-solutions","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Nonlinear solutions","text":"Up to this point the linearised solution of the model was used. The package also provides nonlinear solutions and can calculate the theoretical model moments for pruned second and third order perturbation solutions. This can be of interest because nonlinear solutions capture volatility effects (at second order) and asymmetries (at third order). Furthermore, the moments of the data are often non-gaussian while linear solutions with gaussian noise can only generate gaussian distributions of model variables. Nonetheless, already pruned second order solutions produce non-gaussian skewness and kurtosis with gaussian noise.\n\nFrom a user perspective little changes other than specifying that the solution algorithm is :pruned_second_order or :pruned_third_order.\n\nFor example the mean for the pruned second order solution can be obtained as follows:\n\nget_mean(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi], algorithm = :pruned_second_order)\n\nNote that the mean of real wages is lower, while inflation is higher. The effect of volatility can be seen with the partial derivatives for the shock standard deviations being non-zero. Larger shocks sizes drive down the mean of real wages while they increase inflation.\n\nThe mean of the variables does not change if pruned third order perturbation is used by construction but the standard deviation does. Consider the standard deviations for the pruned second order solution first:\n\nget_std(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi], algorithm = :pruned_second_order)\n\nfor both inflation and real wages the volatility is higher and the standard deviation of the total factor productivity shock std_a has a much larger impact on the standard deviation of real wages compared to the linear solution.\n\nAt third order the results are:\n\nget_std(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi], algorithm = :pruned_third_order)\n\nstandard deviations of inflation is more than two times as high and for real wages it is also substantially higher. Furthermore, standard deviations of shocks matter even more for the volatility of the endogenous variables.\n\nThese results make it clear that capturing the nonlinear interactions by using nonlinear solutions has important implications for the model moments and by extension the model dynamics.","category":"section"},{"location":"tutorials/calibration/#Method-of-moments-for-nonlinear-solutions","page":"Calibration / method of moments (for higher order perturbation solutions) - Gali (2015)","title":"Method of moments for nonlinear solutions","text":"Matching the theoretical moments of the nonlinear model solution to the data is no more complicated for the user than in the linear solution case (see above).\n\nDefine the target value and function and let an optimiser find the parameters minimising the distance to the target.\n\nKeeping the targets:\n\nMean of W_real = 0.7\nStandard deviation of Pi = 0.01\n\nthe target function needs to specify that a nonlinear solution algorithm is used (e.g. pruned third order):\n\nfunction distance_to_target(parameter_value_inputs)\n    model_statistics = get_statistics(Gali_2015, parameter_value_inputs, algorithm = :pruned_third_order, parameters = [:α, :std_a], mean = [:W_real], standard_deviation = [:Pi])\n    targets = [0.7, 0.01]\n    return sum(abs2, vcat(model_statistics[:mean], model_statistics[:standard_deviation]) - targets)\nend\n\nand then use the same code to optimise as in the linear solution case:\n\nsol = Optim.optimize(distance_to_target,\n                        [0,0], \n                        [1,1], \n                        [0.25, 0.01], \n                        Optim.Fminbox(Optim.LBFGS(linesearch = LineSearches.BackTracking(order = 3))))\n\nthe calculations take substantially longer and the solution does not get as close to the target as for the linear solution case. The parameter values minimising the distance are:\n\nsol.minimizer\n\nlower than for the linear solution case and the theoretical moments given these parameter are:\n\nget_statistics(Gali_2015, sol.minimizer, algorithm = :pruned_third_order, parameters = [:α, :std_a], mean = [:W_real], standard_deviation = [:Pi])\n\nThe solution does not match the standard deviation of inflation very well.\n\nPotentially the partial derivatives change a lot for small changes in parameters and even though the partial derivatives for standard deviation of inflation were large wrt std_a they might be small for values returned from the optimisation. This can be checked with:\n\nget_std(Gali_2015, parameter_derivatives = [:σ, :std_a, :α], variables = [:W_real,:Pi], algorithm = :pruned_third_order, parameters = [:α, :std_a] .=> sol.minimizer)\n\nand indeed it seems also the second derivative is large since the first derivative changed significantly.\n\nAnother parameter to try is σ. It has a positive impact on the mean of real wages and a negative impact on standard deviation of inflation.\n\nThe target function needs to be redefined and optimised. Note that the previous call made a permanent change of parameters (as do all calls where parameters are explicitly set) and now std_a is set to 2.91e-9 and no longer 0.01.\n\nfunction distance_to_target(parameter_value_inputs)\n    model_statistics = get_statistics(Gali_2015, parameter_value_inputs, algorithm = :pruned_third_order, parameters = [:α, :σ], mean = [:W_real], standard_deviation = [:Pi])\n    targets = [0.7, 0.01]\n    return sum(abs2, vcat(model_statistics[:mean], model_statistics[:standard_deviation]) - targets)\nend\n\nsol = Optim.optimize(distance_to_target,\n                        [0,0], \n                        [1,3], \n                        [0.25, 1], \n                        Optim.Fminbox(Optim.LBFGS(linesearch = LineSearches.BackTracking(order = 3))))\n\nsol.minimizer\n\nGiven the new value for std_a and optimising over σ allows matching the target exactly.","category":"section"},{"location":"unfinished_docs/dsl/#DSL","page":"-","title":"DSL","text":"MacroModelling parses models written using a user-friendly syntax:\n\n@model RBC begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * eps_z[x]\nend\n\nThe most important rule is that variables are followed by the timing in square brackets for endogenous variables, e.g. Y[0], exogenous variables are marked by certain keywords (see below), e.g. ϵ[x], and parameters need no further syntax, e.g. α.\n\nA model written with this syntax allows the parser to identify, endogenous and exogenous variables and their timing as well as parameters.\n\nNote that variables in the present (period t or 0) have to be denoted as such: [0]. The parser also takes care of creating auxiliary variables in case the model contains leads or lags of the variables larger than 1:\n\n@model RBC_lead_lag begin\n    1  /  c[0] = (β  /  c[1]) * (α * exp(z[1]) * k[0]^(α - 1) + (1 - δ))\n    c[0] + k[0] = (1 - δ) * k[-1] + q[0]\n    q[0] = exp(z[0]) * k[-1]^α\n    z[0] = ρ * z[-1] + std_z * (eps_z[x-8] + eps_z[x-4] + eps_z[x+4] + eps_z_s[x])\n    c̄⁻[0] = (c[0] + c[-1] + c[-2] + c[-3]) / 4\n    c̄⁺[0] = (c[0] + c[1] + c[2] + c[3]) / 4\nend\n\nThe parser recognises a variable as exogenous if the timing bracket contains one of the keyword/letters (case insensitive): x, ex, exo, exogenous. \n\nValid declarations of exogenous variables: ϵ[x], ϵ[Exo], ϵ[exOgenous]. \n\nInvalid declarations: ϵ[xo], ϵ[exogenously], ϵ[main shock x]\n\nEndogenous and exogenous variables can be in lead or lag, e.g.:  the following describe a lead of 1 period: Y[1], Y[+1], Y[+ 1], eps[x+1], eps[Exo + 1] and the same goes for lags and periods > 1: `k[-2], c[+12], eps[x-4]\n\nInvalid declarations: Y[t-1], Y[t], Y[whatever], eps[x+t+1]\n\nEquations must be within one line and the = sign is optional.\n\nThe parser recognises all functions in julia including those from StatsFuns.jl. Note that the syntax for distributions is the same as in MATLAB, e.g. normcdf. For those familiar with R the following also work: pnorm, dnorm, qnorm, and it also recognises: norminvcdf and norminv.\n\nGiven these rules it is straightforward to write down a model. Once declared using the @model <name of the model> macro, the package creates an object containing all necessary information regarding the equations of the model.","category":"section"},{"location":"unfinished_docs/dsl/#Lead-/-lags-and-auxiliary-variables","page":"-","title":"Lead / lags and auxiliary variables","text":"","category":"section"},{"location":"plotting/#Plotting","page":"Overview","title":"Plotting","text":"MacroModelling.jl integrates a comprehensive plotting toolkit based on StatsPlots.jl. The plotting API is exported alongside the modelling macros, enabling visualization of impulse responses, simulations, conditional forecasts, model estimates, variance decompositions, and policy functions immediately after model definition. All plotting functions are implemented in the StatsPlotsExt extension, which loads automatically when importing or using StatsPlots.","category":"section"},{"location":"plotting/#Available-Plotting-Functions","page":"Overview","title":"Available Plotting Functions","text":"MacroModelling.jl provides several plotting functions for analyzing and visualizing model behavior:\n\nImpulse Response Functions (IRF): Visualize the dynamic response of endogenous variables to exogenous shocks using plot_irf\nPolicy Functions: Plot the relationship between state variables and endogenous variables using plot_solution\nConditional Forecasting: Generate model projections conditional on future paths for endogenous variables or exogenous shocks using plot_conditional_forecast\nConditional Variance Decomposition: Visualize the forecast error variance decomposition (FEVD) showing shock contributions to variable variance using plot_conditional_variance_decomposition (also available as plot_fevd)\nModel Estimates: Display filtered or smoothed estimates of endogenous variables and exogenous shocks, with optional shock decomposition and unconditional forecasts using plot_model_estimates (also available as plot_shock_decomposition)","category":"section"},{"location":"tutorials/estimation/#Estimate-a-simple-model-Schorfheide-(2000)","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Estimate a simple model - Schorfheide (2000)","text":"This tutorial is intended to show the workflow to estimate a model using the No-U-Turn sampler (NUTS). The tutorial works with a benchmark model for estimation and can therefore be compared to results from other software packages (e.g. dynare).","category":"section"},{"location":"tutorials/estimation/#Define-the-model","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Define the model","text":"The first step is always to name the model and write down the equations. For the Schorfheide (2000) model this would go as follows:\n\nusing MacroModelling\n\n@model FS2000 begin\n    dA[0] = exp(gam + z_e_a  *  e_a[x])\n\n    log(m[0]) = (1 - rho) * log(mst)  +  rho * log(m[-1]) + z_e_m  *  e_m[x]\n\n    - P[0] / (c[1] * P[1] * m[0]) + bet * P[1] * (alp * exp( - alp * (gam + log(e[1]))) * k[0] ^ (alp - 1) * n[1] ^ (1 - alp) + (1 - del) * exp( - (gam + log(e[1])))) / (c[2] * P[2] * m[1])=0\n\n    W[0] = l[0] / n[0]\n\n    - (psi / (1 - psi)) * (c[0] * P[0] / (1 - n[0])) + l[0] / n[0] = 0\n\n    R[0] = P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ ( - alp) / W[0]\n\n    1 / (c[0] * P[0]) - bet * P[0] * (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) / (m[0] * l[0] * c[1] * P[1]) = 0\n\n    c[0] + k[0] = exp( - alp * (gam + z_e_a  *  e_a[x])) * k[-1] ^ alp * n[0] ^ (1 - alp) + (1 - del) * exp( - (gam + z_e_a  *  e_a[x])) * k[-1]\n\n    P[0] * c[0] = m[0]\n\n    m[0] - 1 + d[0] = l[0]\n\n    e[0] = exp(z_e_a  *  e_a[x])\n\n    y[0] = k[-1] ^ alp * n[0] ^ (1 - alp) * exp( - alp * (gam + z_e_a  *  e_a[x]))\n\n    gy_obs[0] = dA[0] * y[0] / y[-1]\n\n    gp_obs[0] = (P[0] / P[-1]) * m[-1] / dA[0]\n\n    log_gy_obs[0] = log(gy_obs[0])\n\n    log_gp_obs[0] = log(gp_obs[0])\nend\n\nFirst, the package is loaded and then the @model macro is used to define the model. The first argument after @model is the model name and will be the name of the object in the global environment containing all information regarding the model. The second argument to the macro are the equations, which are written down between begin and end. Equations can contain an equality sign or the expression is assumed to equal 0. Equations cannot span multiple lines (unless the expression is wrapped in brackets) and the timing of endogenous variables are expressed in the square brackets following the variable name (e.g. [-1] for the past period). Exogenous variables (shocks) are followed by a keyword in square brackets indicating them being exogenous (in this case [x]). Note that names can leverage julia's unicode capabilities (e.g. alpha can be written as α).","category":"section"},{"location":"tutorials/estimation/#Define-the-parameters","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Define the parameters","text":"Next the parameters of the model need to be added. The macro @parameters takes care of this:\n\n@parameters FS2000 begin  \n    alp     = 0.356\n    bet     = 0.993\n    gam     = 0.0085\n    mst     = 1.0002\n    rho     = 0.129\n    psi     = 0.65\n    del     = 0.01\n    z_e_a   = 0.035449\n    z_e_m   = 0.008862\nend\n\nThe block defining the parameters above only describes the simple parameter definitions the same way values are assigned (e.g. alp = .356).\n\nNote that one parameter definition per line is required.","category":"section"},{"location":"tutorials/estimation/#Load-data","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Load data","text":"Given the equations and parameters, only the entries in the data which correspond to the observables in the model (need to have the exact same name) are needed to estimate the model. First, the data is loaded from a CSV file (using the CSV and DataFrames packages) and converted to a KeyedArray (provided by the AxisKeys package). Furthermore, the data provided in levels is log transformed, and last but not least only those variables in the data which are observables in the model are selected.\n\nusing CSV, DataFrames, AxisKeys\n\n# load data\ndat = CSV.read(\"../assets/FS2000_data.csv\", DataFrame)\ndata = KeyedArray(Array(dat)',Variable = Symbol.(\"log_\".*names(dat)),Time = 1:size(dat)[1])\ndata = log.(data)\n\n# declare observables\nobservables = sort(Symbol.(\"log_\".*names(dat)))\n\n# subset observables in data\ndata = data(observables,:)","category":"section"},{"location":"tutorials/estimation/#Define-bayesian-model","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Define bayesian model","text":"Next the parameter priors are defined using the Turing package. The @model macro of the Turing package allows defining the prior distributions over the parameters and combining it with the (Kalman filter) loglikelihood of the model and parameters given the data with the help of the get_loglikelihood function. The prior distributions are defined in an array and passed on to the arraydist function inside the @model macro from the Turing package. It is also possible to define the prior distributions inside the macro but especially for reverse mode auto differentiation the arraydist function is substantially faster. When defining the prior distributions the distribution implemented in the Distributions package can be relied upon. Note that the μσ parameter allows handing over the moments (μ and σ) of the distribution as parameters in case of the non-normal distributions (Gamma, Beta, InverseGamma), and upper and lower bounds truncating the distribution can also be defined as third and fourth arguments to the distribution functions. Last but not least, the loglikelihood is defined and added to the posterior loglikelihood with the help of the @addlogprob! macro.\n\nimport Turing\nimport Turing: NUTS, sample, logpdf, replacenames\nimport ADTypes: AutoZygote\nimport Zygote\n\nprior_distributions = [\n    Beta(0.356, 0.02, μσ = true),           # alp\n    Beta(0.993, 0.002, μσ = true),          # bet\n    Normal(0.0085, 0.003),                  # gam\n    Normal(1.0002, 0.007),                  # mst\n    Beta(0.129, 0.223, μσ = true),          # rho\n    Beta(0.65, 0.05, μσ = true),            # psi\n    Beta(0.01, 0.005, μσ = true),           # del\n    InverseGamma(0.035449, Inf, μσ = true), # z_e_a\n    InverseGamma(0.008862, Inf, μσ = true)  # z_e_m\n]\n\nTuring.@model function FS2000_loglikelihood_function(prior_distributions, data, m; verbose = false)\n    parameters ~ Turing.arraydist(prior_distributions)\n\n    Turing.@addlogprob! get_loglikelihood(m, data, parameters)\nend","category":"section"},{"location":"tutorials/estimation/#Sample-from-posterior:-No-U-Turn-Sampler-(NUTS)","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Sample from posterior: No-U-Turn Sampler (NUTS)","text":"The No-U-Turn Sampler (NUTS) is used to obtain the posterior distribution of the parameters. It exploits gradients of the posterior log‑likelihood with respect to model parameters to navigate the parameter space efficiently. NUTS is regarded as robust and fast, and it simplifies tuning by automatically adapting its hyperparameters.\n\nFirst the loglikelihood model is defined with the specific data, and model. Next, 1000 samples are drawn from the model:\n\nFS2000_loglikelihood = FS2000_loglikelihood_function(prior_distributions, data, FS2000)\n\nn_samples = 1000\n\nchain_NUTS = sample(FS2000_loglikelihood, NUTS(), n_samples, progress = false, initial_params = FS2000.parameter_values)","category":"section"},{"location":"tutorials/estimation/#Inspect-posterior","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Inspect posterior","text":"In order to understand the posterior distribution and the sequence of samples they are plotted:\n\nusing StatsPlots\n\nchain_NUTS_rn = replacenames(chain_NUTS, Dict([\"parameters[$i]\" for i in 1:length(FS2000.parameters)] .=> FS2000.parameters))\n\nplot(chain_NUTS_rn);\n\n(Image: NUTS chain)\n\nNext, the posterior loglikelihood is plotted along two parameters dimensions, with the other parameters kept at the posterior mean, and the samples are added to the visualisation. This visualisation allows understanding the curvature of the posterior and puts the samples in context.\n\nusing ComponentArrays, MCMCChains\nimport DynamicPPL: logjoint\n\nparameter_mean = mean(chain_NUTS)\n\npars = ComponentArray([parameter_mean.nt[2]], Axis(:parameters));\n\nlogjoint(FS2000_loglikelihood, pars)\n\nfunction calculate_log_probability(par1, par2, pars_syms, orig_pars, model)\n    orig_pars[1][pars_syms] = [par1, par2]\n    logjoint(model, orig_pars)\nend\n\ngranularity = 32;\n\npar1 = :del;\npar2 = :gam;\n\nparidx1 = indexin([par1], FS2000.parameters)[1];\nparidx2 = indexin([par2], FS2000.parameters)[1];\n\npar_range1 = collect(range(minimum(chain_NUTS[Symbol(\"parameters[$paridx1]\")]), stop = maximum(chain_NUTS[Symbol(\"parameters[$paridx1]\")]), length = granularity));\npar_range2 = collect(range(minimum(chain_NUTS[Symbol(\"parameters[$paridx2]\")]), stop = maximum(chain_NUTS[Symbol(\"parameters[$paridx2]\")]), length = granularity));\n\np = surface(par_range1, par_range2, \n            (x,y) -> calculate_log_probability(x, y, [paridx1, paridx2], pars, FS2000_loglikelihood),\n            camera=(30, 65),\n            colorbar=false,\n            color=:inferno);\n\njoint_loglikelihood = [logjoint(FS2000_loglikelihood, ComponentArray([reduce(hcat, get(chain_NUTS, :parameters)[1])[s,:]], Axis(:parameters))) for s in 1:length(chain_NUTS)];\n\nscatter3d!(vec(collect(chain_NUTS[Symbol(\"parameters[$paridx1]\")])),\n            vec(collect(chain_NUTS[Symbol(\"parameters[$paridx2]\")])),\n            joint_loglikelihood,\n            mc = :viridis, \n            marker_z = collect(1:length(chain_NUTS)), \n            msw = 0,\n            legend = false, \n            colorbar = false, \n            xlabel = string(par1),\n            ylabel = string(par2),\n            zlabel = \"Log probability\",\n            alpha = 0.5);\n\np\n\n(Image: Posterior surface)","category":"section"},{"location":"tutorials/estimation/#Find-posterior-mode","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Find posterior mode","text":"Other than the mean and median of the posterior distribution the mode can also be calculated as follows:\n\nmodeFS2000 = Turing.maximum_a_posteriori(FS2000_loglikelihood, \n                                        adtype = AutoZygote(), \n                                        initial_params = FS2000.parameter_values)","category":"section"},{"location":"tutorials/estimation/#Model-estimates-given-the-data-and-the-model-solution","page":"Estimate a model using gradient based samplers - Schorfheide (2000)","title":"Model estimates given the data and the model solution","text":"Having found the parameters at the posterior mode model estimates of the shocks which explain the data used to estimate it can be retrieved. This can be done with the get_estimated_shocks function:\n\nget_estimated_shocks(FS2000, data, parameters = collect(modeFS2000.values))\n\nAs the first argument the model is passed, followed by the data (in levels), and then the parameters at the posterior mode. The model is solved with this parameterisation and the shocks are calculated using the Kalman smoother.\n\nThe model was estimated on two variables but the model allows examining all variables given the data. Looking at the estimated variables can be done using the get_estimated_variables function:\n\nget_estimated_variables(FS2000, data)\n\nSince the model was already solved with the parameters at the posterior mode there is no need to do so again. The function returns a KeyedArray (from the AxisKeys package) with the values of the variables in levels at each point in time.\n\nAnother useful tool is a historical shock decomposition. It allows understanding the contribution of the shocks for each variable. This can be done using the get_shock_decomposition function:\n\nget_shock_decomposition(FS2000, data)\n\nA 3-dimensional array is returned with variables, shocks, and time periods as dimensions. The shocks dimension also includes the initial value as a residual between the actual value and what was explained by the shocks. This computation also relies on the Kalman smoother.\n\nLast but not least, the model estimates and the shock decomposition can also be plotted. The model estimates plot, using plot_model_estimates:\n\nplot_model_estimates(FS2000, data)\n\n(Image: Model estimates)\n\nshows the variables of the model (blue), data (red), the shock decomposition for each endogenous variable and in the last panel the estimated shocks used to estimate the model.","category":"section"},{"location":"#MacroModelling.jl","page":"Introduction","title":"MacroModelling.jl","text":"","category":"section"},{"location":"#Author:-Thore-Kockerols-(@thorek1)","page":"Introduction","title":"Author: Thore Kockerols (@thorek1)","text":"MacroModelling.jl is a Julia package for developing and solving dynamic stochastic general equilibrium (DSGE) models.\n\nThese kinds of models describe the behaviour of a macroeconomy and are particularly suited for counterfactual analysis (economic policy evaluation) and exploring / quantifying specific mechanisms (academic research). Due to the complexity of these models, efficient numerical tools are required, as analytical solutions are often unavailable. MacroModelling.jl serves as a tool for handling the complexities involved, such as forward-looking expectations, nonlinearity, and high dimensionality.\n\nThe goal of this package is to reduce coding time and speed up model development by providing functions for working with discrete-time DSGE models. The user-friendly syntax, automatic variable declaration, and effective steady state solver facilitate fast prototyping of models. Furthermore, the package allows the user to work with nonlinear model solutions (up to third order (pruned) perturbation) and estimate the model using gradient based samplers (e.g. NUTS, or HMC). Currently, DifferentiableStateSpaceModels.jl is the only other package providing functionality to estimate using gradient based samplers but they use the start-of-period timing convention instead of the end-of-period timing convention used in most other packages. The target audience for the package includes central bankers, regulators, graduate students, and others working in academia with an interest in DSGE modelling.\n\nAs of now the package can:\n\nparse a model written with user friendly syntax (variables are followed by time indices ...[2], [1], [0], [-1], [-2]..., or [x] for shocks)\n(tries to) solve the model only knowing the model equations and parameter values (no steady state file needed)\ncalculate first, second, and third order (pruned) perturbation solutions (see Villemot (2011), Andreasen et al. (2017) and Levintal (2017)) using symbolic derivatives\nhandle occasionally binding constraints for linear and nonlinear solutions\ncalculate (generalised) impulse response functions, simulate the model, or do conditional forecasts for linear and nonlinear solutions\ncalibrate parameters using (non-stochastic) steady state relationships\nmatch model moments (also for pruned higher order solutions)\nestimate the model on data (Kalman filter using first order perturbation; see Durbin and Koopman (2012)) with gradient based samplers (e.g. NUTS, HMC) or estimate nonlinear models using the inversion filter\ndifferentiate (forward AD) the model solution, Kalman filter loglikelihood (forward and reverse-mode AD), model moments, steady state, with respect to the parameters\n\nThe package is not:\n\nguaranteed to find the non-stochastic steady state\nthe fastest package around if there exists already a fast implementation to find the NSSS (e.g. an analytical solution)\n\nThe former has to do with the fact that solving systems of nonlinear equations is hard (an active area of research). Especially in cases where the values of the solution are far apart (have a high standard deviation - e.g. sol = [-46.324, .993457, 23523.3856]), the algorithms have a hard time finding a solution. The recommended way to tackle this is to set bounds in the @parameters part (e.g. r < 0.2), so that the initial points are closer to the final solution (think of steady state interest rates not being higher than 20% - meaning not being higher than 0.2 or 1.2 depending on the definition).\n\nThe latter has to do with the fact that julia code is fast once compiled, and that the package can spend more time finding the non-stochastic steady state. This means that it takes more time from executing the code to define the model and parameters for the first time to seeing the first plots than with most other packages. But, once the functions are compiled and the non-stochastic steady state has been found the user can benefit from the object oriented nature of the package and generate outputs or change parameters very fast.\n\nThe package contains the following models in the models folder:\n\nAguiar and Gopinath (2007) Aguiar_Gopinath_2007.jl\nAscari and Sbordone (2014) Ascari_Sbordone_2014.jl\nBackus, Kehoe, and Kydland (1992) Backus_Kehoe_Kydland_1992.jl\nBaxter and King (1993) Baxter_King_1993.jl\nCaldara et al. (2012) Caldara_et_al_2012.jl\nGali (2015) - Chapter 3 Gali_2015_chapter_3_nonlinear.jl\nGali and Monacelli (2005) - CPI inflation-based Taylor rule Gali_Monacelli_2005_CITR.jl\nGerali, Neri, Sessa, and Signoretti (2010) GNSS_2010.jl\nGhironi and Melitz (2005) Ghironi_Melitz_2005.jl\nIreland (2004) Ireland_2004.jl\nJermann and Quadrini (2012) - RBC JQ_2012_RBC.jl\nNew Area-Wide Model (2008) - Euro Area - US NAWM_EAUS_2008.jl\nQUEST3 (2009)  QUEST3_2009.jl\nSchmitt-Grohé and Uribe (2003) - debt premium SGU_2003_debt_premium.jl\nSchorfheide (2000) FS2000.jl\nSmets and Wouters (2003) SW03.jl\nSmets and Wouters (2007) SW07.jl","category":"section"},{"location":"#Comparison-with-other-packages","page":"Introduction","title":"Comparison with other packages","text":" MacroModelling.jl dynare DSGE.jl dolo.py SolveDSGE.jl DifferentiableStateSpaceModels.jl StateSpaceEcon.jl IRIS RISE NBTOOLBOX gEcon GDSGE Taylor Projection\nHost language julia MATLAB julia Python julia julia julia MATLAB MATLAB MATLAB R MATLAB MATLAB\nNon-stochastic steady state solver symbolic or numerical solver of independent blocks; symbolic removal of variables redundant in steady state; inclusion of calibration equations in problem numerical solver of independent blocks or user-supplied values/functions  numerical solver of independent blocks or user-supplied values/functions numerical solver numerical solver or user supplied values/equations numerical solver of independent blocks or user-supplied values/functions numerical solver of independent blocks or user-supplied values/functions numerical solver of independent blocks or user-supplied values/functions user-supplied steady state file or numerical solver numerical solver; inclusion of calibration equations in problem  \nAutomatic declaration of variables and parameters yes            \nDerivatives wrt parameters yes     yes       \nPerturbation solution order 1, 2, 3 k 1 1, 2, 3 1, 2, 3 1, 2 1 1 1 to 5 1 1  1 to 5\nPruning yes yes    yes   yes    \nAutomatic derivation of first order conditions           yes  \nOccasionally binding constraints yes yes yes yes yes    yes   yes \nGlobal solution    yes yes       yes \nEstimation yes yes yes   yes  yes yes yes yes  \nBalanced growth path  yes yes    yes yes yes yes   \nModel input macro (julia) text file text file text file text file macro (julia) module (julia) text file text file text file text file text file text file\nTiming convention end-of-period end-of-period  end-of-period start-of-period start-of-period end-of-period end-of-period end-of-period end-of-period end-of-period start-of-period start-of-period","category":"section"},{"location":"#Bibliography","page":"Introduction","title":"Bibliography","text":"Andreasen, M. M.; Fernández-Villaverde, J. and Rubio-Ramírez, J. F. (2017). The Pruned State-Space System for Non-Linear DSGE Models: Theory and Empirical Applications. The Review of Economic Studies 85, 1–49, arXiv:https://academic.oup.com/restud/article-pdf/85/1/1/23033725/rdx037.pdf.\n\n\n\nDurbin, J. and Koopman, S. J. (2012). Time Series Analysis by State Space Methods, 2nd edn (Oxford University Press).\n\n\n\nGalı́, J. (2015). Monetary policy, inflation, and the business cycle: an introduction to the new Keynesian framework and its applications (Princeton University Press).\n\n\n\nLevintal, O. (2017). Fifth-Order Perturbation Solution to DSGE models. Journal of Economic Dynamics and Control 80, 1–16.\n\n\n\nSchorfheide, F. (2000). Loss function-based evaluation of DSGE models. Journal of Applied Econometrics 15, 645–670, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.582.\n\n\n\nSmets, F. and Wouters, R. (2003). AN ESTIMATED DYNAMIC STOCHASTIC GENERAL EQUILIBRIUM MODEL OF THE EURO AREA. Journal of the European Economic Association 1, 1123–1175, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1162/154247603770383415.\n\n\n\nVillemot, S. (2011). Solving rational expectations models at first order: what Dynare does (Dynare Working Papers 2, CEPREMAP).\n\n\n\n","category":"section"},{"location":"tutorials/sw03/#Work-with-a-complex-model-Smets-and-Wouters-(2003)","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Work with a complex model - Smets and Wouters (2003)","text":"This tutorial is intended to show more advanced features of the package which come into play with more complex models. The tutorial will walk through the same steps as for the simple RBC model but will use the nonlinear Smets and Wouters (2003) model instead. Prior knowledge of DSGE models and their solution in practical terms (e.g. having used a mod file with dynare) is useful in understanding this tutorial.","category":"section"},{"location":"tutorials/sw03/#Define-the-model","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Define the model","text":"The first step is always to name the model and write down the equations. For the Smets and Wouters (2003) model this would go as follows:\n\nusing MacroModelling\n@model Smets_Wouters_2003 begin\n    -q[0] + beta * ((1 - tau) * q[1] + epsilon_b[1] * (r_k[1] * z[1] - psi^-1 * r_k[ss] * (-1 + exp(psi * (-1 + z[1])))) * (C[1] - h * C[0])^(-sigma_c))\n    -q_f[0] + beta * ((1 - tau) * q_f[1] + epsilon_b[1] * (r_k_f[1] * z_f[1] - psi^-1 * r_k_f[ss] * (-1 + exp(psi * (-1 + z_f[1])))) * (C_f[1] - h * C_f[0])^(-sigma_c))\n    -r_k[0] + alpha * epsilon_a[0] * mc[0] * L[0]^(1 - alpha) * (K[-1] * z[0])^(-1 + alpha)\n    -r_k_f[0] + alpha * epsilon_a[0] * mc_f[0] * L_f[0]^(1 - alpha) * (K_f[-1] * z_f[0])^(-1 + alpha)\n    -G[0] + T[0]\n    -G[0] + G_bar * epsilon_G[0]\n    -G_f[0] + T_f[0]\n    -G_f[0] + G_bar * epsilon_G[0]\n    -L[0] + nu_w[0]^-1 * L_s[0]\n    -L_s_f[0] + L_f[0] * (W_i_f[0] * W_f[0]^-1)^(lambda_w^-1 * (-1 - lambda_w))\n    L_s_f[0] - L_f[0]\n    L_s_f[0] + lambda_w^-1 * L_f[0] * W_f[0]^-1 * (-1 - lambda_w) * (-W_disutil_f[0] + W_i_f[0]) * (W_i_f[0] * W_f[0]^-1)^(-1 + lambda_w^-1 * (-1 - lambda_w))\n    Pi_ws_f[0] - L_s_f[0] * (-W_disutil_f[0] + W_i_f[0])\n    Pi_ps_f[0] - Y_f[0] * (-mc_f[0] + P_j_f[0]) * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p))\n    -Q[0] + epsilon_b[0]^-1 * q[0] * (C[0] - h * C[-1])^(sigma_c)\n    -Q_f[0] + epsilon_b[0]^-1 * q_f[0] * (C_f[0] - h * C_f[-1])^(sigma_c)\n    -W[0] + epsilon_a[0] * mc[0] * (1 - alpha) * L[0]^(-alpha) * (K[-1] * z[0])^alpha\n    -W_f[0] + epsilon_a[0] * mc_f[0] * (1 - alpha) * L_f[0]^(-alpha) * (K_f[-1] * z_f[0])^alpha\n    -Y_f[0] + Y_s_f[0]\n    Y_s[0] - nu_p[0] * Y[0]\n    -Y_s_f[0] + Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p))\n    beta * epsilon_b[1] * (C_f[1] - h * C_f[0])^(-sigma_c) - epsilon_b[0] * R_f[0]^-1 * (C_f[0] - h * C_f[-1])^(-sigma_c)\n    beta * epsilon_b[1] * pi[1]^-1 * (C[1] - h * C[0])^(-sigma_c) - epsilon_b[0] * R[0]^-1 * (C[0] - h * C[-1])^(-sigma_c)\n    Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p)) - lambda_p^-1 * Y_f[0] * (1 + lambda_p) * (-mc_f[0] + P_j_f[0]) * P_j_f[0]^(-1 - lambda_p^-1 * (1 + lambda_p))\n    epsilon_b[0] * W_disutil_f[0] * (C_f[0] - h * C_f[-1])^(-sigma_c) - omega * epsilon_b[0] * epsilon_L[0] * L_s_f[0]^sigma_l\n    -1 + xi_p * (pi[0]^-1 * pi[-1]^gamma_p)^(-lambda_p^-1) + (1 - xi_p) * pi_star[0]^(-lambda_p^-1)\n    -1 + (1 - xi_w) * (w_star[0] * W[0]^-1)^(-lambda_w^-1) + xi_w * (W[-1] * W[0]^-1)^(-lambda_w^-1) * (pi[0]^-1 * pi[-1]^gamma_w)^(-lambda_w^-1)\n    -Phi - Y_s[0] + epsilon_a[0] * L[0]^(1 - alpha) * (K[-1] * z[0])^alpha\n    -Phi - Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p)) + epsilon_a[0] * L_f[0]^(1 - alpha) * (K_f[-1] * z_f[0])^alpha\n    std_eta_b * eta_b[x] - log(epsilon_b[0]) + rho_b * log(epsilon_b[-1])\n    -std_eta_L * eta_L[x] - log(epsilon_L[0]) + rho_L * log(epsilon_L[-1])\n    std_eta_I * eta_I[x] - log(epsilon_I[0]) + rho_I * log(epsilon_I[-1])\n    std_eta_w * eta_w[x] - f_1[0] + f_2[0]\n    std_eta_a * eta_a[x] - log(epsilon_a[0]) + rho_a * log(epsilon_a[-1])\n    std_eta_p * eta_p[x] - g_1[0] + g_2[0] * (1 + lambda_p)\n    std_eta_G * eta_G[x] - log(epsilon_G[0]) + rho_G * log(epsilon_G[-1])\n    -f_1[0] + beta * xi_w * f_1[1] * (w_star[0]^-1 * w_star[1])^(lambda_w^-1) * (pi[1]^-1 * pi[0]^gamma_w)^(-lambda_w^-1) + epsilon_b[0] * w_star[0] * L[0] * (1 + lambda_w)^-1 * (C[0] - h * C[-1])^(-sigma_c) * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w))\n    -f_2[0] + beta * xi_w * f_2[1] * (w_star[0]^-1 * w_star[1])^(lambda_w^-1 * (1 + lambda_w) * (1 + sigma_l)) * (pi[1]^-1 * pi[0]^gamma_w)^(-lambda_w^-1 * (1 + lambda_w) * (1 + sigma_l)) + omega * epsilon_b[0] * epsilon_L[0] * (L[0] * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w)))^(1 + sigma_l)\n    -g_1[0] + beta * xi_p * pi_star[0] * g_1[1] * pi_star[1]^-1 * (pi[1]^-1 * pi[0]^gamma_p)^(-lambda_p^-1) + epsilon_b[0] * pi_star[0] * Y[0] * (C[0] - h * C[-1])^(-sigma_c)\n    -g_2[0] + beta * xi_p * g_2[1] * (pi[1]^-1 * pi[0]^gamma_p)^(-lambda_p^-1 * (1 + lambda_p)) + epsilon_b[0] * mc[0] * Y[0] * (C[0] - h * C[-1])^(-sigma_c)\n    -nu_w[0] + (1 - xi_w) * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w)) + xi_w * nu_w[-1] * (W[-1] * pi[0]^-1 * W[0]^-1 * pi[-1]^gamma_w)^(-lambda_w^-1 * (1 + lambda_w))\n    -nu_p[0] + (1 - xi_p) * pi_star[0]^(-lambda_p^-1 * (1 + lambda_p)) + xi_p * nu_p[-1] * (pi[0]^-1 * pi[-1]^gamma_p)^(-lambda_p^-1 * (1 + lambda_p))\n    -K[0] + K[-1] * (1 - tau) + I[0] * (1 - 0.5 * varphi * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])^2)\n    -K_f[0] + K_f[-1] * (1 - tau) + I_f[0] * (1 - 0.5 * varphi * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])^2)\n    U[0] - beta * U[1] - epsilon_b[0] * ((1 - sigma_c)^-1 * (C[0] - h * C[-1])^(1 - sigma_c) - omega * epsilon_L[0] * (1 + sigma_l)^-1 * L_s[0]^(1 + sigma_l))\n    U_f[0] - beta * U_f[1] - epsilon_b[0] * ((1 - sigma_c)^-1 * (C_f[0] - h * C_f[-1])^(1 - sigma_c) - omega * epsilon_L[0] * (1 + sigma_l)^-1 * L_s_f[0]^(1 + sigma_l))\n    -epsilon_b[0] * (C[0] - h * C[-1])^(-sigma_c) + q[0] * (1 - 0.5 * varphi * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])^2 - varphi * I[-1]^-1 * epsilon_I[0] * I[0] * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])) + beta * varphi * I[0]^-2 * epsilon_I[1] * q[1] * I[1]^2 * (-1 + I[0]^-1 * epsilon_I[1] * I[1])\n    -epsilon_b[0] * (C_f[0] - h * C_f[-1])^(-sigma_c) + q_f[0] * (1 - 0.5 * varphi * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])^2 - varphi * I_f[-1]^-1 * epsilon_I[0] * I_f[0] * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])) + beta * varphi * I_f[0]^-2 * epsilon_I[1] * q_f[1] * I_f[1]^2 * (-1 + I_f[0]^-1 * epsilon_I[1] * I_f[1])\n    std_eta_pi * eta_pi[x] - log(pi_obj[0]) + rho_pi_bar * log(pi_obj[-1]) + log(calibr_pi_obj) * (1 - rho_pi_bar)\n    -C[0] - I[0] - T[0] + Y[0] - psi^-1 * r_k[ss] * K[-1] * (-1 + exp(psi * (-1 + z[0])))\n    -calibr_pi + std_eta_R * eta_R[x] - log(R[ss]^-1 * R[0]) + r_Delta_pi * (-log(pi[ss]^-1 * pi[-1]) + log(pi[ss]^-1 * pi[0])) + r_Delta_y * (-log(Y[ss]^-1 * Y[-1]) + log(Y[ss]^-1 * Y[0]) + log(Y_f[ss]^-1 * Y_f[-1]) - log(Y_f[ss]^-1 * Y_f[0])) + rho * log(R[ss]^-1 * R[-1]) + (1 - rho) * (log(pi_obj[0]) + r_pi * (-log(pi_obj[0]) + log(pi[ss]^-1 * pi[-1])) + r_Y * (log(Y[ss]^-1 * Y[0]) - log(Y_f[ss]^-1 * Y_f[0])))\n    -C_f[0] - I_f[0] + Pi_ws_f[0] - T_f[0] + Y_f[0] + L_s_f[0] * W_disutil_f[0] - L_f[0] * W_f[0] - psi^-1 * r_k_f[ss] * K_f[-1] * (-1 + exp(psi * (-1 + z_f[0])))\n    epsilon_b[0] * (K[-1] * r_k[0] - r_k[ss] * K[-1] * exp(psi * (-1 + z[0]))) * (C[0] - h * C[-1])^(-sigma_c)\n    epsilon_b[0] * (K_f[-1] * r_k_f[0] - r_k_f[ss] * K_f[-1] * exp(psi * (-1 + z_f[0]))) * (C_f[0] - h * C_f[-1])^(-sigma_c)\nend\n\nFirst, the package is loaded and then the @model macro is used to define the model. The first argument after @model is the model name and will be the name of the object in the global environment containing all information regarding the model. The second argument to the macro are the equations, which are written down between begin and end. Equations can contain an equality sign or the expression is assumed to equal 0. Equations cannot span multiple lines (unless the expression is wrapped in brackets) and the timing of endogenous variables are expressed in the square brackets following the variable name (e.g. [-1] for the past period). Exogenous variables (shocks) are followed by a keyword in square brackets indicating them being exogenous (in this case [x]). In this example there are also variables in the non-stochastic steady state denoted by [ss]. Note that names can leverage julia's unicode capabilities (alpha can be written as α).","category":"section"},{"location":"tutorials/sw03/#Define-the-parameters","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Define the parameters","text":"Next the parameters of the model need to be added. The macro @parameters takes care of this:\n\n@parameters Smets_Wouters_2003 begin  \n    lambda_p = .368\n    G_bar = .362\n    lambda_w = 0.5\n    Phi = .819\n\n    alpha = 0.3\n    beta = 0.99\n    gamma_w = 0.763\n    gamma_p = 0.469\n    h = 0.573\n    omega = 1\n    psi = 0.169\n\n    r_pi = 1.684\n    r_Y = 0.099\n    r_Delta_pi = 0.14\n    r_Delta_y = 0.159\n\n    sigma_c = 1.353\n    sigma_l = 2.4\n    tau = 0.025\n    varphi = 6.771\n    xi_w = 0.737\n    xi_p = 0.908\n\n    rho = 0.961\n    rho_b = 0.855\n    rho_L = 0.889\n    rho_I = 0.927\n    rho_a = 0.823\n    rho_G = 0.949\n    rho_pi_bar = 0.924\n\n    std_eta_b = 0.336\n    std_eta_L = 3.52\n    std_eta_I = 0.085\n    std_eta_a = 0.598\n    std_eta_w = 0.6853261\n    std_eta_p = 0.7896512\n    std_eta_G = 0.325\n    std_eta_R = 0.081\n    std_eta_pi = 0.017\n\n    calibr_pi_obj | 1 = pi_obj[ss]\n    calibr_pi | pi[ss] = pi_obj[ss]\nend\n\nThe block defining the parameters above has two different inputs.\n\nFirst, there are simple parameter definition the same way values are assigned (e.g. Phi = .819).\n\nSecond, there are calibration equations where the value of a parameter is treated as unknown (e.g. calibr_pi_obj) and an additional equation is required to hold (e.g. 1 = pi_obj[ss]). The additional equation can contain variables in SS or parameters. Putting it together a calibration equation is defined by the unknown parameter, and the calibration equation, separated by | (e.g. calibr_pi_obj | 1 = pi_obj[ss] and also 1 = pi_obj[ss] | calibr_pi_obj).\n\nNote that one parameter definition per line is required.\n\nGiven the equations and parameters, the package will first attempt to solve the system of nonlinear equations symbolically (including possible calibration equations). If an analytical solution is not possible, numerical solution methods are used to try and solve it. There is no guarantee that a solution can be found, but it is highly likely, given that a solution exists. The problem setup tries to incorporate parts of the structure of the problem, e.g. bounds on variables: if one equation contains log(k) it must be that k > 0. Nonetheless, the user can also provide useful information such as variable bounds or initial guesses. Bounds can be set by adding another expression to the parameter block e.g.: c > 0. Large values are typically a problem for numerical solvers. Therefore, providing a guess for these values will increase the speed of the solver. Guesses can be provided as a Dict after the model name and before the parameter definitions block, e.g.: @parameters Smets_Wouters_2003 guess = Dict(k => 10) begin ... end.","category":"section"},{"location":"tutorials/sw03/#Delayed-parameter-definition","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Delayed parameter definition","text":"Not all parameters need to be defined in the @parameters macro. Calibration equations (using the | syntax) and parameters defined as functions of other parameters must be declared here, but simple parameter value assignments (e.g., α = 0.5) can be deferred and provided later by passing them to any function that accepts the parameters argument (e.g., get_irf, get_steady_state, simulate).\n\nParameter ordering: When some parameters are not defined upfront, the parameter vector is ordered as follows: declared parameters come first (in their declaration order), followed by missing parameters (in alphabetical order). This matters when passing parameter values by position rather than by name.\n\nThe example above with delayed parameter definition would work as follows. The model is defined as before:\n\nusing MacroModelling\n@model Smets_Wouters_2003_incomplete begin\n    -q[0] + beta * ((1 - tau) * q[1] + epsilon_b[1] * (r_k[1] * z[1] - psi^-1 * r_k[ss] * (-1 + exp(psi * (-1 + z[1])))) * (C[1] - h * C[0])^(-sigma_c))\n    -q_f[0] + beta * ((1 - tau) * q_f[1] + epsilon_b[1] * (r_k_f[1] * z_f[1] - psi^-1 * r_k_f[ss] * (-1 + exp(psi * (-1 + z_f[1])))) * (C_f[1] - h * C_f[0])^(-sigma_c))\n    -r_k[0] + alpha * epsilon_a[0] * mc[0] * L[0]^(1 - alpha) * (K[-1] * z[0])^(-1 + alpha)\n    -r_k_f[0] + alpha * epsilon_a[0] * mc_f[0] * L_f[0]^(1 - alpha) * (K_f[-1] * z_f[0])^(-1 + alpha)\n    -G[0] + T[0]\n    -G[0] + G_bar * epsilon_G[0]\n    -G_f[0] + T_f[0]\n    -G_f[0] + G_bar * epsilon_G[0]\n    -L[0] + nu_w[0]^-1 * L_s[0]\n    -L_s_f[0] + L_f[0] * (W_i_f[0] * W_f[0]^-1)^(lambda_w^-1 * (-1 - lambda_w))\n    L_s_f[0] - L_f[0]\n    L_s_f[0] + lambda_w^-1 * L_f[0] * W_f[0]^-1 * (-1 - lambda_w) * (-W_disutil_f[0] + W_i_f[0]) * (W_i_f[0] * W_f[0]^-1)^(-1 + lambda_w^-1 * (-1 - lambda_w))\n    Pi_ws_f[0] - L_s_f[0] * (-W_disutil_f[0] + W_i_f[0])\n    Pi_ps_f[0] - Y_f[0] * (-mc_f[0] + P_j_f[0]) * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p))\n    -Q[0] + epsilon_b[0]^-1 * q[0] * (C[0] - h * C[-1])^(sigma_c)\n    -Q_f[0] + epsilon_b[0]^-1 * q_f[0] * (C_f[0] - h * C_f[-1])^(sigma_c)\n    -W[0] + epsilon_a[0] * mc[0] * (1 - alpha) * L[0]^(-alpha) * (K[-1] * z[0])^alpha\n    -W_f[0] + epsilon_a[0] * mc_f[0] * (1 - alpha) * L_f[0]^(-alpha) * (K_f[-1] * z_f[0])^alpha\n    -Y_f[0] + Y_s_f[0]\n    Y_s[0] - nu_p[0] * Y[0]\n    -Y_s_f[0] + Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p))\n    beta * epsilon_b[1] * (C_f[1] - h * C_f[0])^(-sigma_c) - epsilon_b[0] * R_f[0]^-1 * (C_f[0] - h * C_f[-1])^(-sigma_c)\n    beta * epsilon_b[1] * pi[1]^-1 * (C[1] - h * C[0])^(-sigma_c) - epsilon_b[0] * R[0]^-1 * (C[0] - h * C[-1])^(-sigma_c)\n    Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p)) - lambda_p^-1 * Y_f[0] * (1 + lambda_p) * (-mc_f[0] + P_j_f[0]) * P_j_f[0]^(-1 - lambda_p^-1 * (1 + lambda_p))\n    epsilon_b[0] * W_disutil_f[0] * (C_f[0] - h * C_f[-1])^(-sigma_c) - omega * epsilon_b[0] * epsilon_L[0] * L_s_f[0]^sigma_l\n    -1 + xi_p * (pi[0]^-1 * pi[-1]^gamma_p)^(-lambda_p^-1) + (1 - xi_p) * pi_star[0]^(-lambda_p^-1)\n    -1 + (1 - xi_w) * (w_star[0] * W[0]^-1)^(-lambda_w^-1) + xi_w * (W[-1] * W[0]^-1)^(-lambda_w^-1) * (pi[0]^-1 * pi[-1]^gamma_w)^(-lambda_w^-1)\n    -Phi - Y_s[0] + epsilon_a[0] * L[0]^(1 - alpha) * (K[-1] * z[0])^alpha\n    -Phi - Y_f[0] * P_j_f[0]^(-lambda_p^-1 * (1 + lambda_p)) + epsilon_a[0] * L_f[0]^(1 - alpha) * (K_f[-1] * z_f[0])^alpha\n    std_eta_b * eta_b[x] - log(epsilon_b[0]) + rho_b * log(epsilon_b[-1])\n    -std_eta_L * eta_L[x] - log(epsilon_L[0]) + rho_L * log(epsilon_L[-1])\n    std_eta_I * eta_I[x] - log(epsilon_I[0]) + rho_I * log(epsilon_I[-1])\n    std_eta_w * eta_w[x] - f_1[0] + f_2[0]\n    std_eta_a * eta_a[x] - log(epsilon_a[0]) + rho_a * log(epsilon_a[-1])\n    std_eta_p * eta_p[x] - g_1[0] + g_2[0] * (1 + lambda_p)\n    std_eta_G * eta_G[x] - log(epsilon_G[0]) + rho_G * log(epsilon_G[-1])\n    -f_1[0] + beta * xi_w * f_1[1] * (w_star[0]^-1 * w_star[1])^(lambda_w^-1) * (pi[1]^-1 * pi[0]^gamma_w)^(-lambda_w^-1) + epsilon_b[0] * w_star[0] * L[0] * (1 + lambda_w)^-1 * (C[0] - h * C[-1])^(-sigma_c) * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w))\n    -f_2[0] + beta * xi_w * f_2[1] * (w_star[0]^-1 * w_star[1])^(lambda_w^-1 * (1 + lambda_w) * (1 + sigma_l)) * (pi[1]^-1 * pi[0]^gamma_w)^(-lambda_w^-1 * (1 + lambda_w) * (1 + sigma_l)) + omega * epsilon_b[0] * epsilon_L[0] * (L[0] * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w)))^(1 + sigma_l)\n    -g_1[0] + beta * xi_p * pi_star[0] * g_1[1] * pi_star[1]^-1 * (pi[1]^-1 * pi[0]^gamma_p)^(-lambda_p^-1) + epsilon_b[0] * pi_star[0] * Y[0] * (C[0] - h * C[-1])^(-sigma_c)\n    -g_2[0] + beta * xi_p * g_2[1] * (pi[1]^-1 * pi[0]^gamma_p)^(-lambda_p^-1 * (1 + lambda_p)) + epsilon_b[0] * mc[0] * Y[0] * (C[0] - h * C[-1])^(-sigma_c)\n    -nu_w[0] + (1 - xi_w) * (w_star[0] * W[0]^-1)^(-lambda_w^-1 * (1 + lambda_w)) + xi_w * nu_w[-1] * (W[-1] * pi[0]^-1 * W[0]^-1 * pi[-1]^gamma_w)^(-lambda_w^-1 * (1 + lambda_w))\n    -nu_p[0] + (1 - xi_p) * pi_star[0]^(-lambda_p^-1 * (1 + lambda_p)) + xi_p * nu_p[-1] * (pi[0]^-1 * pi[-1]^gamma_p)^(-lambda_p^-1 * (1 + lambda_p))\n    -K[0] + K[-1] * (1 - tau) + I[0] * (1 - 0.5 * varphi * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])^2)\n    -K_f[0] + K_f[-1] * (1 - tau) + I_f[0] * (1 - 0.5 * varphi * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])^2)\n    U[0] - beta * U[1] - epsilon_b[0] * ((1 - sigma_c)^-1 * (C[0] - h * C[-1])^(1 - sigma_c) - omega * epsilon_L[0] * (1 + sigma_l)^-1 * L_s[0]^(1 + sigma_l))\n    U_f[0] - beta * U_f[1] - epsilon_b[0] * ((1 - sigma_c)^-1 * (C_f[0] - h * C_f[-1])^(1 - sigma_c) - omega * epsilon_L[0] * (1 + sigma_l)^-1 * L_s_f[0]^(1 + sigma_l))\n    -epsilon_b[0] * (C[0] - h * C[-1])^(-sigma_c) + q[0] * (1 - 0.5 * varphi * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])^2 - varphi * I[-1]^-1 * epsilon_I[0] * I[0] * (-1 + I[-1]^-1 * epsilon_I[0] * I[0])) + beta * varphi * I[0]^-2 * epsilon_I[1] * q[1] * I[1]^2 * (-1 + I[0]^-1 * epsilon_I[1] * I[1])\n    -epsilon_b[0] * (C_f[0] - h * C_f[-1])^(-sigma_c) + q_f[0] * (1 - 0.5 * varphi * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])^2 - varphi * I_f[-1]^-1 * epsilon_I[0] * I_f[0] * (-1 + I_f[-1]^-1 * epsilon_I[0] * I_f[0])) + beta * varphi * I_f[0]^-2 * epsilon_I[1] * q_f[1] * I_f[1]^2 * (-1 + I_f[0]^-1 * epsilon_I[1] * I_f[1])\n    std_eta_pi * eta_pi[x] - log(pi_obj[0]) + rho_pi_bar * log(pi_obj[-1]) + log(calibr_pi_obj) * (1 - rho_pi_bar)\n    -C[0] - I[0] - T[0] + Y[0] - psi^-1 * r_k[ss] * K[-1] * (-1 + exp(psi * (-1 + z[0])))\n    -calibr_pi + std_eta_R * eta_R[x] - log(R[ss]^-1 * R[0]) + r_Delta_pi * (-log(pi[ss]^-1 * pi[-1]) + log(pi[ss]^-1 * pi[0])) + r_Delta_y * (-log(Y[ss]^-1 * Y[-1]) + log(Y[ss]^-1 * Y[0]) + log(Y_f[ss]^-1 * Y_f[-1]) - log(Y_f[ss]^-1 * Y_f[0])) + rho * log(R[ss]^-1 * R[-1]) + (1 - rho) * (log(pi_obj[0]) + r_pi * (-log(pi_obj[0]) + log(pi[ss]^-1 * pi[-1])) + r_Y * (log(Y[ss]^-1 * Y[0]) - log(Y_f[ss]^-1 * Y_f[0])))\n    -C_f[0] - I_f[0] + Pi_ws_f[0] - T_f[0] + Y_f[0] + L_s_f[0] * W_disutil_f[0] - L_f[0] * W_f[0] - psi^-1 * r_k_f[ss] * K_f[-1] * (-1 + exp(psi * (-1 + z_f[0])))\n    epsilon_b[0] * (K[-1] * r_k[0] - r_k[ss] * K[-1] * exp(psi * (-1 + z[0]))) * (C[0] - h * C[-1])^(-sigma_c)\n    epsilon_b[0] * (K_f[-1] * r_k_f[0] - r_k_f[ss] * K_f[-1] * exp(psi * (-1 + z_f[0]))) * (C_f[0] - h * C_f[-1])^(-sigma_c)\nend\n\nbut in the parameter definition only the calibration equations and parameters defined as functions of other parameters are defined, so in this case we have two calibration equations:\n\n@parameters Smets_Wouters_2003_incomplete begin\n    calibr_pi_obj | 1 = pi_obj[ss]\n    calibr_pi | pi[ss] = pi_obj[ss]\nend\n\nthe package warns that the model has been set up with incomplete parameter definitions and provides the missing parameters.\n\nWe can then provide the missing parameters when calling functions that accept the parameters argument, for example to retrieve IRFs:\n\nparams = [\n    :lambda_p   => .368,\n    :G_bar      => .362,\n    :lambda_w   => 0.5,\n    :Phi        => .819,\n    :alpha      => 0.3,\n    :beta       => 0.99,\n    :gamma_w    => 0.763,\n    :gamma_p    => 0.469,\n    :h          => 0.573,\n    :omega      => 1,\n    :psi        => 0.169,\n    :r_pi       => 1.684,\n    :r_Y        => 0.099,\n    :r_Delta_pi => 0.14,\n    :r_Delta_y  => 0.159,\n    :sigma_c    => 1.353,\n    :sigma_l    => 2.4,\n    :tau        => 0.025,\n    :varphi     => 6.771,\n    :xi_w       => 0.737,\n    :xi_p       => 0.908,\n    :rho        => 0.961,\n    :rho_b      => 0.855,\n    :rho_L      => 0.889,\n    :rho_I      => 0.927,\n    :rho_a      => 0.823,\n    :rho_G      => 0.949,\n    :rho_pi_bar => 0.924,\n    :std_eta_b  => 0.336,\n    :std_eta_L  => 3.52,\n    :std_eta_I  => 0.085,\n    :std_eta_a  => 0.598,\n    :std_eta_w  => 0.6853261,\n    :std_eta_p  => 0.7896512,\n    :std_eta_G  => 0.325,\n    :std_eta_R  => 0.081,\n    :std_eta_pi => 0.017,\n]\n\nget_irf(Smets_Wouters_2003_incomplete, parameters = params)\n\nNote that only now that all parameters have been defined the package can attempt to solve the model. The steady state problem and derivatives are taken only once all missing parameters have been provided, as the order of the parameters follows declaration order. This functionality effectively allows to load parameter values from an external source (e.g. a CSV file) and pass them to the model without having to redefine the model.","category":"section"},{"location":"tutorials/sw03/#Plot-impulse-response-functions-(IRFs)","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Plot impulse response functions (IRFs)","text":"A useful output to analyse are IRFs for the exogenous shocks. Calling plot_irf (different names for the same function are also supported: plot_irfs, or plot_IRF) will take care of this. Note that the StatsPlots package needs to be imported once before the first plot. In the background the package solves (numerically in this complex case) for the non-stochastic steady state (SS) and calculates the first order perturbation solution.\n\nimport StatsPlots\nplot_irf(Smets_Wouters_2003)\n\n(Image: RBC IRF)\n\nWhen the model is solved the first time (in this case by calling plot_irf), the package breaks down the steady state problem into independent blocks and first attempts to solve them symbolically and if that fails numerically.\n\nThe plots show the responses of the endogenous variables to a one standard deviation positive (indicated by Shock⁺ in chart title) unanticipated shock. Therefore there are as many subplots as there are combinations of shocks and endogenous variables (which are impacted by the shock). Plots are composed of up to 9 subplots and the plot title shows the model name followed by the name of the shock and which plot is shown out of the plots for this shock (e.g. (1/3) means the first out of three plots for this shock). Subplots show the sorted endogenous variables with the left y-axis showing the level of the respective variable and the right y-axis showing the percent deviation from the SS (if variable is strictly positive). The horizontal black line marks the SS.","category":"section"},{"location":"tutorials/sw03/#Explore-other-parameter-values","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Explore other parameter values","text":"Playing around with the model can be especially insightful in the early phase of model development. The package tries to facilitate this process to the extent possible. Typically different parameter values are tried to see how the IRFs change. This can be done by using the parameters argument of the plot_irf function. Pass a Pair with the Symbol of the parameter (: in front of the parameter name) that should change and its new value to the parameter argument (e.g. :alpha => 0.305). Furthermore, the example focuses on certain shocks and variables. The eta_R shock is selected by passing it as a Symbol to the shocks argument. The variables plotted are U, Y, I, R, and C, achieved by passing the Vector of Symbols to the variables argument of the plot_irf function:\n\nplot_irf(Smets_Wouters_2003, \n         parameters = :alpha => 0.305, \n         variables = [:U,:Y,:I,:R,:C], \n         shocks = :eta_R)\n\n(Image: IRF plot)\n\nFirst, the package finds the new steady state, solves the model dynamics around it and saves the new parameters and solution in the model object. Second, note that with the parameters the IRFs changed (e.g. compare the y-axis values for U). Updating the plot for new parameters is significantly faster than calling it the first time. This is because the first call triggers compilations of the model functions, and once compiled the user benefits from the performance of the specialised compiled code. Furthermore, finding the SS from a valid SS as a starting point is faster.","category":"section"},{"location":"tutorials/sw03/#Plot-model-simulation","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Plot model simulation","text":"Another insightful output is simulations of the model. The plot_simulations function can be used here. Again only a subset of the variables will be examined and specified in the variables argument. Note that the StatsPlots package needs to be imported once before the first plot. To the same effect the plot_irf function can be used and in the shocks argument :simulate is specified to simulate the model and the periods argument set to 100.\n\nplot_simulations(Smets_Wouters_2003, variables = [:U,:Y,:I,:R,:C])\n\n(Image: Simulate Smets_Wouters_2003)\n\nThe plots show the models endogenous variables in response to random draws for all exogenous shocks over 100 periods.","category":"section"},{"location":"tutorials/sw03/#Plot-specific-series-of-shocks","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Plot specific series of shocks","text":"Sometimes a specific series of shocks is of interest and the corresponding responses of the endogenous variables can be examined by passing a Matrix or a KeyedArray (the KeyedArray type is provided by the AxisKeys package) of shock series to the shocks argument of the plot_irf function. For example, consider a positive 1 standard deviation shock to eta_b in period 2 and a negative 1 standard deviation shock to eta_w in period 12. This can be implemented as follows:\n\nusing AxisKeys\nshock_series = KeyedArray(zeros(2,12), Shocks = [:eta_b, :eta_w], Periods = 1:12)\nshock_series[1,2] = 1\nshock_series[2,12] = -1\nplot_irf(Smets_Wouters_2003, shocks = shock_series, variables = [:W,:r_k,:w_star,:R])\n\n(Image: Series of shocks RBC)\n\nFirst, the KeyedArray (provided by the AxisKeys package) containing the series of shocks is constructed and passed to the shocks argument. The plot shows the paths of the selected variables for the two shocks hitting the economy in periods 2 and 12 and 40 quarters thereafter.","category":"section"},{"location":"tutorials/sw03/#Model-statistics","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Model statistics","text":"","category":"section"},{"location":"tutorials/sw03/#Steady-state","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Steady state","text":"The package solves for the SS automatically and the SS values can be seen in the plots. To see the SS values and the derivatives of the SS with respect to the model parameters get_steady_state can be called. The model has 39 parameters and 54 variables. Since not all derivatives for all parameters are of interest a subset is selected. This can be done by passing on a Vector of Symbols of the parameters to the parameter_derivatives argument:\n\nget_steady_state(Smets_Wouters_2003, parameter_derivatives = [:alpha,:beta])\n\nThe first column of the returned matrix shows the SS while the second to last columns show the derivatives of the SS values (indicated in the rows) with respect to the parameters (indicated in the columns). For example, the derivative of C with respect to beta is 14.4994. This means that if beta is increased by 1, C would increase by 14.4994 approximately. How this plays out can be seen by changing beta from 0.99 to 0.991 (a change of +0.001):\n\nget_steady_state(Smets_Wouters_2003, \n                 parameter_derivatives = [:alpha,:G_bar], \n                 parameters = :beta => .991)\n\nNote that get_steady_state like all other get functions has the parameters argument. Hence, for whatever output is being examined the parameters of the model can be changed.\n\nThe new value of beta changed the SS as expected and C increased by 0.01465. The elasticity (0.01465/0.001) comes close to the partial derivative previously calculated. The derivatives help understanding the effect of parameter changes on the steady state and make for easier navigation of the parameter space.","category":"section"},{"location":"tutorials/sw03/#Standard-deviations","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Standard deviations","text":"Next to the SS the model implied standard deviations of the model can also be displayed. get_standard_deviation takes care of this. Additionally the parameter values will be set to what they were in the beginning by passing on a Tuple of Pairs containing the Symbols of the parameters to be changed and their new (initial) values (e.g. (:alpha => 0.3, :beta => .99)).\n\nget_standard_deviation(Smets_Wouters_2003, \n                       parameter_derivatives = [:alpha,:beta], \n                       parameters = (:alpha => 0.3, :beta => .99))\n\nThe function returns the model implied standard deviations of the model variables and their derivatives with respect to the model parameters. For example, the derivative of the standard deviation of q with resect to alpha is -19.0184. In other words, the standard deviation of q decreases with increasing alpha.","category":"section"},{"location":"tutorials/sw03/#Correlations","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Correlations","text":"Another useful statistic is the model implied correlation of variables. get_correlation is used for this:\n\nget_correlation(Smets_Wouters_2003)","category":"section"},{"location":"tutorials/sw03/#Autocorrelations","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Autocorrelations","text":"Next, the model implied autocorrelations of model variables can be examined using the get_autocorrelation function:\n\nget_autocorrelation(Smets_Wouters_2003)","category":"section"},{"location":"tutorials/sw03/#Variance-decomposition","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Variance decomposition","text":"The model implied contribution of each shock to the variance of the model variables can be calculate by using the  get_variance_decomposition function:\n\nget_variance_decomposition(Smets_Wouters_2003)","category":"section"},{"location":"tutorials/sw03/#Conditional-variance-decomposition","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Conditional variance decomposition","text":"Last but not least, the model implied contribution of each shock per period to the variance of the model variables (also called forecast error variance decomposition) can be examined by using the  get_conditional_variance_decomposition function:\n\nget_conditional_variance_decomposition(Smets_Wouters_2003)","category":"section"},{"location":"tutorials/sw03/#Plot-conditional-variance-decomposition","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Plot conditional variance decomposition","text":"Especially for the conditional variance decomposition it is convenient to look at a plot instead of the raw numbers. This can be done using the plot_conditional_variance_decomposition function. Note that the StatsPlots package needs to be imported once before the first plot.\n\nplot_conditional_variance_decomposition(Smets_Wouters_2003, variables = [:U,:Y,:I,:R,:C])\n\n(Image: FEVD Smets_Wouters_2003)","category":"section"},{"location":"tutorials/sw03/#Model-solution","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Model solution","text":"A further insightful output are the policy and transition functions of the first order perturbation solution. To retrieve the solution the function get_solution can be called:\n\nget_solution(Smets_Wouters_2003)\n\nThe solution provides information about how past states and present shocks impact present variables. The first row contains the SS for the variables denoted in the columns. The second to last rows contain the past states, with the time index ₍₋₁₎, and present shocks, with exogenous variables denoted by ₍ₓ₎. For example, the immediate impact of a shock to eta_w on z is 0.00222469.\n\nThere is also the possibility to visually inspect the solution using the plot_solution function. Note that the StatsPlots package needs to be imported once before the first plot.\n\nplot_solution(Smets_Wouters_2003, :pi, variables = [:C,:I,:K,:L,:W,:R])\n\n(Image: Smets_Wouters_2003 solution)\n\nThe chart shows the first order perturbation solution mapping from the past state pi to the present variables C, I, K, L, W, and R. The state variable covers a range of two standard deviations around the non-stochastic steady state and all other states remain in the non-stochastic steady state.","category":"section"},{"location":"tutorials/sw03/#Obtain-array-of-IRFs-or-model-simulations","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Obtain array of IRFs or model simulations","text":"Last but not least the user might want to obtain simulated time series of the model or IRFs without plotting them. For IRFs this is possible by calling get_irf:\n\nget_irf(Smets_Wouters_2003)\n\nwhich returns a 3-dimensional KeyedArray (provided by the AxisKeys package) with variables  (absolute deviations from the relevant steady state by default) in rows, the period in columns, and the shocks as the third dimension.\n\nFor simulations this is possible by calling simulate:\n\nsimulate(Smets_Wouters_2003)\n\nwhich returns the simulated data in levels in a 3-dimensional KeyedArray (provided by the AxisKeys package) of the same structure as for the IRFs.","category":"section"},{"location":"tutorials/sw03/#Conditional-forecasts","page":"Work with a more complex model - Smets and Wouters (2003)","title":"Conditional forecasts","text":"Conditional forecasting is a useful tool to incorporate for example forecasts into a model and then add shocks on top.\n\nFor example there might be interest in the model dynamics given a path for Y and pi for the first 4 quarters and the next quarter a negative shock to eta_w arrives. Furthermore, only a subset of shocks should be used to match the conditions on the endogenous variables for the first two periods. This can be implemented using the get_conditional_forecast function and visualised with the plot_conditional_forecast function.\n\nFirst, define the conditions on the endogenous variables as deviations from the non-stochastic steady state (Y and pi in this case) using a KeyedArray from the AxisKeys package (check get_conditional_forecast for other ways to define the conditions):\n\nusing AxisKeys\nconditions = KeyedArray(Matrix{Union{Nothing,Float64}}(undef,2,4),Variables = [:Y, :pi], Periods = 1:4)\nconditions[1,1:4] .= [-.01,0,.01,.02];\nconditions[2,1:4] .= [.01,0,-.01,-.02];\n\nNote that all other endogenous variables not part of the KeyedArray (provided by the AxisKeys package) are also not conditioned on.\n\nNext, define the conditions on the shocks using a Matrix (check get_conditional_forecast for other ways to define the conditions on the shocks):\n\nshocks = Matrix{Union{Nothing,Float64}}(undef,9,5)\nshocks[[1:3...,5,9],1:2] .= 0;\nshocks[9,5] = -1;\n\nThe above shock Matrix means that for the first two periods shocks 1, 2, 3, 5, and 9 are fixed at zero and in the fifth period there is a negative shock of eta_w (the 9th shock).\n\nFinally the conditional forecast can be obtained:\n\nget_conditional_forecast(Smets_Wouters_2003, conditions, shocks = shocks, variables = [:Y,:pi,:W], conditions_in_levels = false)\n\nThe function returns a KeyedArray (provided by the AxisKeys package) with the values of the endogenous variables and shocks matching the conditions exactly.\n\nThe conditional forecast can also be plotted. Note that the StatsPlots package needs to be imported once before the first plot.\n\nplot_conditional_forecast(Smets_Wouters_2003,conditions, shocks = shocks, plots_per_page = 6,variables = [:Y,:pi,:W],conditions_in_levels = false)\n\n(Image: Smets_Wouters_2003 conditional forecast 1)\n\n(Image: Smets_Wouters_2003 conditional forecast 2)\n\nand conditions_in_levels = false needs to be set since the conditions are defined in deviations.\n\nNote that the stars indicate the values the model is conditioned on.","category":"section"}]
}
